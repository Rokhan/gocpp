// generated by GoCpp from file '$(ImportDir)/runtime/mpagealloc.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/mpagealloc.h"
#include "gocpp/support.h"

#include "golang/internal/abi/type.h"
#include "golang/internal/cpu/cpu.h"
#include "golang/runtime/internal/atomic/types.h"
#include "golang/runtime/internal/sys/nih.h"
#include "golang/runtime/lock_sema.h"
#include "golang/runtime/lockrank_off.h"
#include "golang/runtime/malloc.h"
#include "golang/runtime/mbitmap_allocheaders.h"
#include "golang/runtime/mcache.h"
#include "golang/runtime/mcentral.h"
#include "golang/runtime/mcheckmark.h"
#include "golang/runtime/mem.h"
#include "golang/runtime/mfixalloc.h"
#include "golang/runtime/mgcscavenge.h"
#include "golang/runtime/mheap.h"
#include "golang/runtime/mpagealloc_64bit.h"
#include "golang/runtime/mpallocbits.h"
#include "golang/runtime/mranges.h"
#include "golang/runtime/mspanset.h"
#include "golang/runtime/mstats.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/print.h"
#include "golang/runtime/runtime2.h"
#include "golang/runtime/stubs.h"
#include "golang/unsafe/unsafe.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
    }

    // The size of a bitmap chunk, i.e. the amount of bits (that is, pages) to consider
    // in the bitmap at once.
    // The number of radix bits for each level.
    //
    // The value of 3 is chosen such that the block of summaries we need to scan at
    // each level fits in 64 bytes (2^3 summaries * 8 bytes per summary), which is
    // close to the L1 cache line width on many systems. Also, a value of 3 fits 4 tree
    // levels perfectly into the 21-bit pallocBits summary field at the root level.
    //
    // The following equation explains how each of the constants relate:
    // summaryL0Bits + (summaryLevels-1)*summaryLevelBits + logPallocChunkBytes = heapAddrBits
    //
    // summaryLevels is an architecture-dependent value defined in mpagealloc_*.go.
    // pallocChunksL2Bits is the number of bits of the chunk index number
    // covered by the second level of the chunks map.
    //
    // See (*pageAlloc).chunks for more details. Update the documentation
    // there should this change.
    // maxSearchAddr returns the maximum searchAddr value, which indicates
    // that the heap has no free space.
    //
    // This function exists just to make it clear that this is the maximum address
    // for the page allocator's search space. See maxOffAddr for details.
    //
    // It's a function (rather than a variable) because it needs to be
    // usable before package runtime's dynamic initialization is complete.
    // See #51913 for details.
    struct offAddr maxSearchAddr()
    {
        return maxOffAddr;
    }

    // Global chunk index.
    //
    // Represents an index into the leaf level of the radix tree.
    // Similar to arenaIndex, except instead of arenas, it divides the address
    // space into chunks.
    // chunkIndex returns the global index of the palloc chunk containing the
    // pointer p.
    runtime::chunkIdx chunkIndex(uintptr_t p)
    {
        return chunkIdx((p - arenaBaseOffset) / pallocChunkBytes);
    }

    // chunkBase returns the base address of the palloc chunk at index ci.
    uintptr_t chunkBase(golang::runtime::chunkIdx ci)
    {
        return uintptr_t(ci) * pallocChunkBytes + arenaBaseOffset;
    }

    // chunkPageIndex computes the index of the page that contains p,
    // relative to the chunk which contains p.
    unsigned int chunkPageIndex(uintptr_t p)
    {
        return (unsigned int)(p % pallocChunkBytes / pageSize);
    }

    // l1 returns the index into the first level of (*pageAlloc).chunks.
    unsigned int rec::l1(golang::runtime::chunkIdx i)
    {
        if(pallocChunksL1Bits == 0)
        {
            return 0;
        }
        else
        {
            return (unsigned int)(i) >> pallocChunksL1Shift;
        }
    }

    // l2 returns the index into the second level of (*pageAlloc).chunks.
    unsigned int rec::l2(golang::runtime::chunkIdx i)
    {
        if(pallocChunksL1Bits == 0)
        {
            return (unsigned int)(i);
        }
        else
        {
            return (unsigned int)(i) & ((1 << pallocChunksL2Bits) - 1);
        }
    }

    // offAddrToLevelIndex converts an address in the offset address space
    // to the index into summary[level] containing addr.
    int offAddrToLevelIndex(int level, struct offAddr addr)
    {
        return int((addr.a - arenaBaseOffset) >> levelShift[level]);
    }

    // levelIndexToOffAddr converts an index into summary[level] into
    // the corresponding address in the offset address space.
    struct offAddr levelIndexToOffAddr(int level, int idx)
    {
        return offAddr {(uintptr_t(idx) << levelShift[level]) + arenaBaseOffset};
    }

    // addrsToSummaryRange converts base and limit pointers into a range
    // of entries for the given summary level.
    //
    // The returned range is inclusive on the lower bound and exclusive on
    // the upper bound.
    std::tuple<int, int> addrsToSummaryRange(int level, uintptr_t base, uintptr_t limit)
    {
        int lo;
        int hi;
        lo = int((base - arenaBaseOffset) >> levelShift[level]);
        hi = int(((limit - 1) - arenaBaseOffset) >> levelShift[level]) + 1;
        return {lo, hi};
    }

    // blockAlignSummaryRange aligns indices into the given level to that
    // level's block width (1 << levelBits[level]). It assumes lo is inclusive
    // and hi is exclusive, and so aligns them down and up respectively.
    std::tuple<int, int> blockAlignSummaryRange(int level, int lo, int hi)
    {
        auto e = uintptr_t(1) << levelBits[level];
        return {int(alignDown(uintptr_t(lo), e)), int(alignUp(uintptr_t(hi), e))};
    }

    
    template<typename T> requires gocpp::GoStruct<T>
    gocpp_id_0::operator T()
    {
        T result;
        result.index = this->index;
        result.releasedBg = this->releasedBg;
        result.releasedEager = this->releasedEager;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gocpp_id_0::operator==(const T& ref) const
    {
        if (index != ref.index) return false;
        if (releasedBg != ref.releasedBg) return false;
        if (releasedEager != ref.releasedEager) return false;
        return true;
    }

    std::ostream& gocpp_id_0::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << index;
        os << " " << releasedBg;
        os << " " << releasedEager;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gocpp_id_0& value)
    {
        return value.PrintTo(os);
    }


    
    template<typename T> requires gocpp::GoStruct<T>
    pageAlloc::operator T()
    {
        T result;
        result.summary = this->summary;
        result.chunks = this->chunks;
        result.searchAddr = this->searchAddr;
        result.start = this->start;
        result.end = this->end;
        result.inUse = this->inUse;
        result.scav = this->scav;
        result.mheapLock = this->mheapLock;
        result.sysStat = this->sysStat;
        result.summaryMappedReady = this->summaryMappedReady;
        result.chunkHugePages = this->chunkHugePages;
        result.test = this->test;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool pageAlloc::operator==(const T& ref) const
    {
        if (summary != ref.summary) return false;
        if (chunks != ref.chunks) return false;
        if (searchAddr != ref.searchAddr) return false;
        if (start != ref.start) return false;
        if (end != ref.end) return false;
        if (inUse != ref.inUse) return false;
        if (scav != ref.scav) return false;
        if (mheapLock != ref.mheapLock) return false;
        if (sysStat != ref.sysStat) return false;
        if (summaryMappedReady != ref.summaryMappedReady) return false;
        if (chunkHugePages != ref.chunkHugePages) return false;
        if (test != ref.test) return false;
        return true;
    }

    std::ostream& pageAlloc::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << summary;
        os << " " << chunks;
        os << " " << searchAddr;
        os << " " << start;
        os << " " << end;
        os << " " << inUse;
        os << " " << scav;
        os << " " << mheapLock;
        os << " " << sysStat;
        os << " " << summaryMappedReady;
        os << " " << chunkHugePages;
        os << " " << test;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct pageAlloc& value)
    {
        return value.PrintTo(os);
    }

    void rec::init(golang::runtime::pageAlloc* p, struct mutex* mheapLock, golang::runtime::sysMemStat* sysStat, bool test)
    {
        if(levelLogPages[0] > logMaxPackedValue)
        {
            print("runtime: root level max pages = "_s, 1 << levelLogPages[0], "\n"_s);
            print("runtime: summary max pages = "_s, maxPackedValue, "\n"_s);
            go_throw("root level max pages doesn't fit in summary"_s);
        }
        p->sysStat = sysStat;
        rec::init(gocpp::recv(p->inUse), sysStat);
        rec::sysInit(gocpp::recv(p), test);
        p->searchAddr = maxSearchAddr();
        p->mheapLock = mheapLock;
        p->summaryMappedReady += rec::init(gocpp::recv(p->scav.index), test, sysStat);
        p->test = test;
    }

    // tryChunkOf returns the bitmap data for the given chunk.
    //
    // Returns nil if the chunk data has not been mapped.
    struct pallocData* rec::tryChunkOf(golang::runtime::pageAlloc* p, golang::runtime::chunkIdx ci)
    {
        auto l2 = p->chunks[rec::l1(gocpp::recv(ci))];
        if(l2 == nullptr)
        {
            return nullptr;
        }
        return & l2[rec::l2(gocpp::recv(ci))];
    }

    // chunkOf returns the chunk at the given chunk index.
    //
    // The chunk index must be valid or this method may throw.
    struct pallocData* rec::chunkOf(golang::runtime::pageAlloc* p, golang::runtime::chunkIdx ci)
    {
        return & p->chunks[rec::l1(gocpp::recv(ci))][rec::l2(gocpp::recv(ci))];
    }

    // grow sets up the metadata for the address range [base, base+size).
    // It may allocate metadata, in which case *p.sysStat will be updated.
    //
    // p.mheapLock must be held.
    void rec::grow(golang::runtime::pageAlloc* p, uintptr_t base, uintptr_t size)
    {
        assertLockHeld(p->mheapLock);
        auto limit = alignUp(base + size, pallocChunkBytes);
        base = alignDown(base, pallocChunkBytes);
        rec::sysGrow(gocpp::recv(p), base, limit);
        p->summaryMappedReady += rec::grow(gocpp::recv(p->scav.index), base, limit, p->sysStat);
        auto firstGrowth = p->start == 0;
        auto [start, end] = std::tuple{chunkIndex(base), chunkIndex(limit)};
        if(firstGrowth || start < p->start)
        {
            p->start = start;
        }
        if(end > p->end)
        {
            p->end = end;
        }
        rec::add(gocpp::recv(p->inUse), makeAddrRange(base, limit));
        if(auto b = (offAddr {base}); rec::lessThan(gocpp::recv(b), p->searchAddr))
        {
            p->searchAddr = b;
        }
        for(auto c = chunkIndex(base); c < chunkIndex(limit); c++)
        {
            if(p->chunks[rec::l1(gocpp::recv(c))] == nullptr)
            {
                // Create the necessary l2 entry.
                auto l2Size = gocpp::Sizeof<gocpp::array<runtime::pallocData, 8192>>();
                auto r = sysAlloc(l2Size, p->sysStat);
                if(r == nullptr)
                {
                    go_throw("pageAlloc: out of memory"_s);
                }
                if(! p->test)
                {
                    if(p->chunkHugePages)
                    {
                        sysHugePage(r, l2Size);
                    }
                    else
                    {
                        sysNoHugePage(r, l2Size);
                    }
                }
                *(uintptr_t*)(unsafe::Pointer(& p->chunks[rec::l1(gocpp::recv(c))])) = uintptr_t(r);
            }
            rec::setRange(gocpp::recv(rec::chunkOf(gocpp::recv(p), c)->scavenged), 0, pallocChunkPages);
        }
        rec::update(gocpp::recv(p), base, size / pageSize, true, false);
    }

    // enableChunkHugePages enables huge pages for the chunk bitmap mappings (disabled by default).
    //
    // This function is idempotent.
    //
    // A note on latency: for sufficiently small heaps (<10s of GiB) this function will take constant
    // time, but may take time proportional to the size of the mapped heap beyond that.
    //
    // The heap lock must not be held over this operation, since it will briefly acquire
    // the heap lock.
    //
    // Must be called on the system stack because it acquires the heap lock.
    //
    //go:systemstack
    void rec::enableChunkHugePages(golang::runtime::pageAlloc* p)
    {
        lock(& mheap_.lock);
        if(p->chunkHugePages)
        {
            unlock(& mheap_.lock);
            return;
        }
        p->chunkHugePages = true;
        addrRanges inUse = {};
        inUse.sysStat = p->sysStat;
        rec::cloneInto(gocpp::recv(p->inUse), & inUse);
        unlock(& mheap_.lock);
        for(auto [gocpp_ignored, r] : p->inUse.ranges)
        {
            for(auto i = rec::l1(gocpp::recv(chunkIndex(rec::addr(gocpp::recv(r.base))))); i < rec::l1(gocpp::recv(chunkIndex(rec::addr(gocpp::recv(r.limit)) - 1))); i++)
            {
                sysHugePage(unsafe::Pointer(p->chunks[i]), gocpp::Sizeof<gocpp::array<runtime::pallocData, 8192>>());
            }
        }
    }

    // update updates heap metadata. It must be called each time the bitmap
    // is updated.
    //
    // If contig is true, update does some optimizations assuming that there was
    // a contiguous allocation or free between addr and addr+npages. alloc indicates
    // whether the operation performed was an allocation or a free.
    //
    // p.mheapLock must be held.
    void rec::update(golang::runtime::pageAlloc* p, uintptr_t base, uintptr_t npages, bool contig, bool alloc)
    {
        assertLockHeld(p->mheapLock);
        auto limit = base + npages * pageSize - 1;
        auto [sc, ec] = std::tuple{chunkIndex(base), chunkIndex(limit)};
        if(sc == ec)
        {
            auto x = p->summary[len(p->summary) - 1][sc];
            auto y = rec::summarize(gocpp::recv(rec::chunkOf(gocpp::recv(p), sc)));
            if(x == y)
            {
                return;
            }
            p->summary[len(p->summary) - 1][sc] = y;
        }
        else
        if(contig)
        {
            auto summary = p->summary[len(p->summary) - 1];
            summary[sc] = rec::summarize(gocpp::recv(rec::chunkOf(gocpp::recv(p), sc)));
            auto whole = p->summary[len(p->summary) - 1].make_slice(sc + 1, ec);
            if(alloc)
            {
                for(auto [i, gocpp_ignored] : whole)
                {
                    whole[i] = 0;
                }
            }
            else
            {
                for(auto [i, gocpp_ignored] : whole)
                {
                    whole[i] = freeChunkSum;
                }
            }
            summary[ec] = rec::summarize(gocpp::recv(rec::chunkOf(gocpp::recv(p), ec)));
        }
        else
        {
            auto summary = p->summary[len(p->summary) - 1];
            for(auto c = sc; c <= ec; c++)
            {
                summary[c] = rec::summarize(gocpp::recv(rec::chunkOf(gocpp::recv(p), c)));
            }
        }
        auto changed = true;
        for(auto l = len(p->summary) - 2; l >= 0 && changed; l--)
        {
            changed = false;
            auto logEntriesPerBlock = levelBits[l + 1];
            auto logMaxPages = levelLogPages[l + 1];
            auto [lo, hi] = addrsToSummaryRange(l, base, limit + 1);
            for(auto i = lo; i < hi; i++)
            {
                auto children = p->summary[l + 1].make_slice(i << logEntriesPerBlock, (i + 1) << logEntriesPerBlock);
                auto sum = mergeSummaries(children, logMaxPages);
                auto old = p->summary[l][i];
                if(old != sum)
                {
                    changed = true;
                    p->summary[l][i] = sum;
                }
            }
        }
    }

    // allocRange marks the range of memory [base, base+npages*pageSize) as
    // allocated. It also updates the summaries to reflect the newly-updated
    // bitmap.
    //
    // Returns the amount of scavenged memory in bytes present in the
    // allocated range.
    //
    // p.mheapLock must be held.
    uintptr_t rec::allocRange(golang::runtime::pageAlloc* p, uintptr_t base, uintptr_t npages)
    {
        assertLockHeld(p->mheapLock);
        auto limit = base + npages * pageSize - 1;
        auto [sc, ec] = std::tuple{chunkIndex(base), chunkIndex(limit)};
        auto [si, ei] = std::tuple{chunkPageIndex(base), chunkPageIndex(limit)};
        auto scav = (unsigned int)(0);
        if(sc == ec)
        {
            auto chunk = rec::chunkOf(gocpp::recv(p), sc);
            scav += rec::popcntRange(gocpp::recv(chunk->scavenged), si, ei + 1 - si);
            rec::allocRange(gocpp::recv(chunk), si, ei + 1 - si);
            rec::alloc(gocpp::recv(p->scav.index), sc, ei + 1 - si);
        }
        else
        {
            auto chunk = rec::chunkOf(gocpp::recv(p), sc);
            scav += rec::popcntRange(gocpp::recv(chunk->scavenged), si, pallocChunkPages - si);
            rec::allocRange(gocpp::recv(chunk), si, pallocChunkPages - si);
            rec::alloc(gocpp::recv(p->scav.index), sc, pallocChunkPages - si);
            for(auto c = sc + 1; c < ec; c++)
            {
                auto chunk = rec::chunkOf(gocpp::recv(p), c);
                scav += rec::popcntRange(gocpp::recv(chunk->scavenged), 0, pallocChunkPages);
                rec::allocAll(gocpp::recv(chunk));
                rec::alloc(gocpp::recv(p->scav.index), c, pallocChunkPages);
            }
            chunk = rec::chunkOf(gocpp::recv(p), ec);
            scav += rec::popcntRange(gocpp::recv(chunk->scavenged), 0, ei + 1);
            rec::allocRange(gocpp::recv(chunk), 0, ei + 1);
            rec::alloc(gocpp::recv(p->scav.index), ec, ei + 1);
        }
        rec::update(gocpp::recv(p), base, npages, true, true);
        return uintptr_t(scav) * pageSize;
    }

    // findMappedAddr returns the smallest mapped offAddr that is
    // >= addr. That is, if addr refers to mapped memory, then it is
    // returned. If addr is higher than any mapped region, then
    // it returns maxOffAddr.
    //
    // p.mheapLock must be held.
    struct offAddr rec::findMappedAddr(golang::runtime::pageAlloc* p, struct offAddr addr)
    {
        assertLockHeld(p->mheapLock);
        auto ai = arenaIndex(rec::addr(gocpp::recv(addr)));
        if(p->test || mheap_.arenas[rec::l1(gocpp::recv(ai))] == nullptr || mheap_.arenas[rec::l1(gocpp::recv(ai))][rec::l2(gocpp::recv(ai))] == nullptr)
        {
            auto [vAddr, ok] = rec::findAddrGreaterEqual(gocpp::recv(p->inUse), rec::addr(gocpp::recv(addr)));
            if(ok)
            {
                return offAddr {vAddr};
            }
            else
            {
                return maxOffAddr;
            }
        }
        return addr;
    }

    struct gocpp_id_1
        {
            offAddr base;
            offAddr bound;

            using isGoStruct = void;

            template<typename T> requires gocpp::GoStruct<T>
            operator T()
            {
                T result;
                result.base = this->base;
                result.bound = this->bound;
                return result;
            }

            template<typename T> requires gocpp::GoStruct<T>
            bool operator==(const T& ref) const
            {
                if (base != ref.base) return false;
                if (bound != ref.bound) return false;
                return true;
            }

            std::ostream& PrintTo(std::ostream& os) const
            {
                os << '{';
                os << "" << base;
                os << " " << bound;
                os << '}';
                return os;
            }
        };

        std::ostream& operator<<(std::ostream& os, const struct gocpp_id_1& value)
        {
            return value.PrintTo(os);
        }


    // find searches for the first (address-ordered) contiguous free region of
    // npages in size and returns a base address for that region.
    //
    // It uses p.searchAddr to prune its search and assumes that no palloc chunks
    // below chunkIndex(p.searchAddr) contain any free memory at all.
    //
    // find also computes and returns a candidate p.searchAddr, which may or
    // may not prune more of the address space than p.searchAddr already does.
    // This candidate is always a valid p.searchAddr.
    //
    // find represents the slow path and the full radix tree search.
    //
    // Returns a base address of 0 on failure, in which case the candidate
    // searchAddr returned is invalid and must be ignored.
    //
    // p.mheapLock must be held.
    std::tuple<uintptr_t, struct offAddr> rec::find(golang::runtime::pageAlloc* p, uintptr_t npages)
    {
        assertLockHeld(p->mheapLock);
        auto i = 0;
        auto firstFree = gocpp::Init<gocpp_id_1>([=](auto& x) {
            x.base = minOffAddr;
            x.bound = maxOffAddr;
        });
        auto foundFree = [=](struct offAddr addr, uintptr_t size) mutable -> void
        {
            if(rec::lessEqual(gocpp::recv(firstFree.base), addr) && rec::lessEqual(gocpp::recv(rec::add(gocpp::recv(addr), size - 1)), firstFree.bound))
            {
                firstFree.base = addr;
                firstFree.bound = rec::add(gocpp::recv(addr), size - 1);
            }
            else
            if(! (rec::lessThan(gocpp::recv(rec::add(gocpp::recv(addr), size - 1)), firstFree.base) || rec::lessThan(gocpp::recv(firstFree.bound), addr)))
            {
                print("runtime: addr = "_s, hex(rec::addr(gocpp::recv(addr))), ", size = "_s, size, "\n"_s);
                print("runtime: base = "_s, hex(rec::addr(gocpp::recv(firstFree.base))), ", bound = "_s, hex(rec::addr(gocpp::recv(firstFree.bound))), "\n"_s);
                go_throw("range partially overlaps"_s);
            }
        };
        auto lastSum = packPallocSum(0, 0, 0);
        auto lastSumIdx = - 1;
        nextLevel:
        for(auto l = 0; l < len(p->summary); l++)
        {
            auto entriesPerBlock = 1 << levelBits[l];
            auto logMaxPages = levelLogPages[l];
            i <<= levelBits[l];
            auto entries = p->summary[l].make_slice(i, i + entriesPerBlock);
            auto j0 = 0;
            if(auto searchIdx = offAddrToLevelIndex(l, p->searchAddr); searchIdx &^ (entriesPerBlock - 1) == i)
            {
                j0 = searchIdx & (entriesPerBlock - 1);
            }
            // Run over the level entries looking for
            // a contiguous run of at least npages either
            // within an entry or across entries.
            //
            // base contains the page index (relative to
            // the first entry's first page) of the currently
            // considered run of consecutive pages.
            //
            // size contains the size of the currently considered
            // run of consecutive pages.
            unsigned int base = {};
            unsigned int size = {};
            for(auto j = j0; j < len(entries); j++)
            {
                auto sum = entries[j];
                if(sum == 0)
                {
                    size = 0;
                    continue;
                }
                foundFree(levelIndexToOffAddr(l, i + j), (uintptr_t(1) << logMaxPages) * pageSize);
                auto s = rec::start(gocpp::recv(sum));
                if(size + s >= (unsigned int)(npages))
                {
                    if(size == 0)
                    {
                        base = (unsigned int)(j) << logMaxPages;
                    }
                    size += s;
                    break;
                }
                if(rec::max(gocpp::recv(sum)) >= (unsigned int)(npages))
                {
                    i += j;
                    lastSumIdx = i;
                    lastSum = sum;
                    goto nextLevel_continue;
                }
                if(size == 0 || s < (1 << logMaxPages))
                {
                    size = rec::end(gocpp::recv(sum));
                    base = ((unsigned int)(j + 1) << logMaxPages) - size;
                    continue;
                }
                size += 1 << logMaxPages;
            }
            if(size >= (unsigned int)(npages))
            {
                auto addr = rec::addr(gocpp::recv(rec::add(gocpp::recv(levelIndexToOffAddr(l, i)), uintptr_t(base) * pageSize)));
                return {addr, rec::findMappedAddr(gocpp::recv(p), firstFree.base)};
            }
            if(l == 0)
            {
                return {0, maxSearchAddr()};
            }
            print("runtime: summary["_s, l - 1, "]["_s, lastSumIdx, "] = "_s, rec::start(gocpp::recv(lastSum)), ", "_s, rec::max(gocpp::recv(lastSum)), ", "_s, rec::end(gocpp::recv(lastSum)), "\n"_s);
            print("runtime: level = "_s, l, ", npages = "_s, npages, ", j0 = "_s, j0, "\n"_s);
            print("runtime: p.searchAddr = "_s, hex(rec::addr(gocpp::recv(p->searchAddr))), ", i = "_s, i, "\n"_s);
            print("runtime: levelShift[level] = "_s, levelShift[l], ", levelBits[level] = "_s, levelBits[l], "\n"_s);
            for(auto j = 0; j < len(entries); j++)
            {
                auto sum = entries[j];
                print("runtime: summary["_s, l, "]["_s, i + j, "] = ("_s, rec::start(gocpp::recv(sum)), ", "_s, rec::max(gocpp::recv(sum)), ", "_s, rec::end(gocpp::recv(sum)), ")\n"_s);
            }
            go_throw("bad summary data"_s);
            if(false) {
            nextLevel_continue:
                continue;
            nextLevel_break:
                break;
            }
        }
        auto ci = chunkIdx(i);
        auto [j, searchIdx] = rec::find(gocpp::recv(rec::chunkOf(gocpp::recv(p), ci)), npages, 0);
        if(j == ~ (unsigned int)(0))
        {
            auto sum = p->summary[len(p->summary) - 1][i];
            print("runtime: summary["_s, len(p->summary) - 1, "]["_s, i, "] = ("_s, rec::start(gocpp::recv(sum)), ", "_s, rec::max(gocpp::recv(sum)), ", "_s, rec::end(gocpp::recv(sum)), ")\n"_s);
            print("runtime: npages = "_s, npages, "\n"_s);
            go_throw("bad summary data"_s);
        }
        auto addr = chunkBase(ci) + uintptr_t(j) * pageSize;
        auto searchAddr = chunkBase(ci) + uintptr_t(searchIdx) * pageSize;
        foundFree(offAddr {searchAddr}, chunkBase(ci + 1) - searchAddr);
        return {addr, rec::findMappedAddr(gocpp::recv(p), firstFree.base)};
    }

    // alloc allocates npages worth of memory from the page heap, returning the base
    // address for the allocation and the amount of scavenged memory in bytes
    // contained in the region [base address, base address + npages*pageSize).
    //
    // Returns a 0 base address on failure, in which case other returned values
    // should be ignored.
    //
    // p.mheapLock must be held.
    //
    // Must run on the system stack because p.mheapLock must be held.
    //
    //go:systemstack
    std::tuple<uintptr_t, uintptr_t> rec::alloc(golang::runtime::pageAlloc* p, uintptr_t npages)
    {
        uintptr_t addr;
        uintptr_t scav;
        assertLockHeld(p->mheapLock);
        if(chunkIndex(rec::addr(gocpp::recv(p->searchAddr))) >= p->end)
        {
            return {0, 0};
        }
        auto searchAddr = minOffAddr;
        if(pallocChunkPages - chunkPageIndex(rec::addr(gocpp::recv(p->searchAddr))) >= (unsigned int)(npages))
        {
            auto i = chunkIndex(rec::addr(gocpp::recv(p->searchAddr)));
            if(auto max = rec::max(gocpp::recv(p->summary[len(p->summary) - 1][i])); max >= (unsigned int)(npages))
            {
                auto [j, searchIdx] = rec::find(gocpp::recv(rec::chunkOf(gocpp::recv(p), i)), npages, chunkPageIndex(rec::addr(gocpp::recv(p->searchAddr))));
                if(j == ~ (unsigned int)(0))
                {
                    print("runtime: max = "_s, max, ", npages = "_s, npages, "\n"_s);
                    print("runtime: searchIdx = "_s, chunkPageIndex(rec::addr(gocpp::recv(p->searchAddr))), ", p.searchAddr = "_s, hex(rec::addr(gocpp::recv(p->searchAddr))), "\n"_s);
                    go_throw("bad summary data"_s);
                }
                addr = chunkBase(i) + uintptr_t(j) * pageSize;
                searchAddr = offAddr {chunkBase(i) + uintptr_t(searchIdx) * pageSize};
                goto Found;
            }
        }
        std::tie(addr, searchAddr) = rec::find(gocpp::recv(p), npages);
        if(addr == 0)
        {
            if(npages == 1)
            {
                p->searchAddr = maxSearchAddr();
            }
            return {0, 0};
        }
        Found:
        scav = rec::allocRange(gocpp::recv(p), addr, npages);
        if(rec::lessThan(gocpp::recv(p->searchAddr), searchAddr))
        {
            p->searchAddr = searchAddr;
        }
        return {addr, scav};
    }

    // free returns npages worth of memory starting at base back to the page heap.
    //
    // p.mheapLock must be held.
    //
    // Must run on the system stack because p.mheapLock must be held.
    //
    //go:systemstack
    void rec::free(golang::runtime::pageAlloc* p, uintptr_t base, uintptr_t npages)
    {
        assertLockHeld(p->mheapLock);
        if(auto b = (offAddr {base}); rec::lessThan(gocpp::recv(b), p->searchAddr))
        {
            p->searchAddr = b;
        }
        auto limit = base + npages * pageSize - 1;
        if(npages == 1)
        {
            auto i = chunkIndex(base);
            auto pi = chunkPageIndex(base);
            rec::free1(gocpp::recv(rec::chunkOf(gocpp::recv(p), i)), pi);
            rec::free(gocpp::recv(p->scav.index), i, pi, 1);
        }
        else
        {
            auto [sc, ec] = std::tuple{chunkIndex(base), chunkIndex(limit)};
            auto [si, ei] = std::tuple{chunkPageIndex(base), chunkPageIndex(limit)};
            if(sc == ec)
            {
                rec::free(gocpp::recv(rec::chunkOf(gocpp::recv(p), sc)), si, ei + 1 - si);
                rec::free(gocpp::recv(p->scav.index), sc, si, ei + 1 - si);
            }
            else
            {
                rec::free(gocpp::recv(rec::chunkOf(gocpp::recv(p), sc)), si, pallocChunkPages - si);
                rec::free(gocpp::recv(p->scav.index), sc, si, pallocChunkPages - si);
                for(auto c = sc + 1; c < ec; c++)
                {
                    rec::freeAll(gocpp::recv(rec::chunkOf(gocpp::recv(p), c)));
                    rec::free(gocpp::recv(p->scav.index), c, 0, pallocChunkPages);
                }
                rec::free(gocpp::recv(rec::chunkOf(gocpp::recv(p), ec)), 0, ei + 1);
                rec::free(gocpp::recv(p->scav.index), ec, 0, ei + 1);
            }
        }
        rec::update(gocpp::recv(p), base, npages, true, false);
    }

    // maxPackedValue is the maximum value that any of the three fields in
    // the pallocSum may take on.
    // pallocSum is a packed summary type which packs three numbers: start, max,
    // and end into a single 8-byte value. Each of these values are a summary of
    // a bitmap and are thus counts, each of which may have a maximum value of
    // 2^21 - 1, or all three may be equal to 2^21. The latter case is represented
    // by just setting the 64th bit.
    // packPallocSum takes a start, max, and end value and produces a pallocSum.
    runtime::pallocSum packPallocSum(unsigned int start, unsigned int max, unsigned int end)
    {
        if(max == maxPackedValue)
        {
            return pallocSum(uint64_t(1 << 63));
        }
        return pallocSum((uint64_t(start) & (maxPackedValue - 1)) | ((uint64_t(max) & (maxPackedValue - 1)) << logMaxPackedValue) | ((uint64_t(end) & (maxPackedValue - 1)) << (2 * logMaxPackedValue)));
    }

    // start extracts the start value from a packed sum.
    unsigned int rec::start(golang::runtime::pallocSum p)
    {
        if(uint64_t(p) & uint64_t(1 << 63) != 0)
        {
            return maxPackedValue;
        }
        return (unsigned int)(uint64_t(p) & (maxPackedValue - 1));
    }

    // max extracts the max value from a packed sum.
    unsigned int rec::max(golang::runtime::pallocSum p)
    {
        if(uint64_t(p) & uint64_t(1 << 63) != 0)
        {
            return maxPackedValue;
        }
        return (unsigned int)((uint64_t(p) >> logMaxPackedValue) & (maxPackedValue - 1));
    }

    // end extracts the end value from a packed sum.
    unsigned int rec::end(golang::runtime::pallocSum p)
    {
        if(uint64_t(p) & uint64_t(1 << 63) != 0)
        {
            return maxPackedValue;
        }
        return (unsigned int)((uint64_t(p) >> (2 * logMaxPackedValue)) & (maxPackedValue - 1));
    }

    // unpack unpacks all three values from the summary.
    std::tuple<unsigned int, unsigned int, unsigned int> rec::unpack(golang::runtime::pallocSum p)
    {
        if(uint64_t(p) & uint64_t(1 << 63) != 0)
        {
            return {maxPackedValue, maxPackedValue, maxPackedValue};
        }
        return {(unsigned int)(uint64_t(p) & (maxPackedValue - 1)), (unsigned int)((uint64_t(p) >> logMaxPackedValue) & (maxPackedValue - 1)), (unsigned int)((uint64_t(p) >> (2 * logMaxPackedValue)) & (maxPackedValue - 1))};
    }

    // mergeSummaries merges consecutive summaries which may each represent at
    // most 1 << logMaxPagesPerSum pages each together into one.
    runtime::pallocSum mergeSummaries(gocpp::slice<golang::runtime::pallocSum> sums, unsigned int logMaxPagesPerSum)
    {
        auto [start, most, end] = rec::unpack(gocpp::recv(sums[0]));
        for(auto i = 1; i < len(sums); i++)
        {
            auto [si, mi, ei] = rec::unpack(gocpp::recv(sums[i]));
            if(start == ((unsigned int)(i) << logMaxPagesPerSum))
            {
                start += si;
            }
            most = gocpp::max(most, end + si, mi);
            if(ei == (1 << logMaxPagesPerSum))
            {
                end += 1 << logMaxPagesPerSum;
            }
            else
            {
                end = ei;
            }
        }
        return packPallocSum(start, most, end);
    }

}

