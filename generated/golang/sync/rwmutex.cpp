// generated by GoCpp from file '$(ImportDir)/sync/rwmutex.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/sync/rwmutex.h"
#include "gocpp/support.h"

#include "golang/internal/race/norace.h"
#include "golang/sync/atomic/type.h"
#include "golang/sync/mutex.h"
#include "golang/sync/runtime.h"
#include "golang/unsafe/unsafe.h"

namespace golang::sync
{
    namespace rec
    {
        using namespace mocklib::rec;
        using atomic::rec::Add;
        using atomic::rec::CompareAndSwap;
        using atomic::rec::Load;
    }

    // A RWMutex is a reader/writer mutual exclusion lock.
    // The lock can be held by an arbitrary number of readers or a single writer.
    // The zero value for a RWMutex is an unlocked mutex.
    //
    // A RWMutex must not be copied after first use.
    //
    // If any goroutine calls Lock while the lock is already held by
    // one or more readers, concurrent calls to RLock will block until
    // the writer has acquired (and released) the lock, to ensure that
    // the lock eventually becomes available to the writer.
    // Note that this prohibits recursive read-locking.
    //
    // In the terminology of the Go memory model,
    // the n'th call to Unlock “synchronizes before” the m'th call to Lock
    // for any n < m, just as for Mutex.
    // For any call to RLock, there exists an n such that
    // the n'th call to Unlock “synchronizes before” that call to RLock,
    // and the corresponding call to RUnlock “synchronizes before”
    // the n+1'th call to Lock.
    
    template<typename T> requires gocpp::GoStruct<T>
    RWMutex::operator T()
    {
        T result;
        result.w = this->w;
        result.writerSem = this->writerSem;
        result.readerSem = this->readerSem;
        result.readerCount = this->readerCount;
        result.readerWait = this->readerWait;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool RWMutex::operator==(const T& ref) const
    {
        if (w != ref.w) return false;
        if (writerSem != ref.writerSem) return false;
        if (readerSem != ref.readerSem) return false;
        if (readerCount != ref.readerCount) return false;
        if (readerWait != ref.readerWait) return false;
        return true;
    }

    std::ostream& RWMutex::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << w;
        os << " " << writerSem;
        os << " " << readerSem;
        os << " " << readerCount;
        os << " " << readerWait;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct RWMutex& value)
    {
        return value.PrintTo(os);
    }

    // RLock locks rw for reading.
    //
    // It should not be used for recursive read locking; a blocked Lock
    // call excludes new readers from acquiring the lock. See the
    // documentation on the RWMutex type.
    void rec::RLock(struct RWMutex* rw)
    {
        if(race::Enabled)
        {
            _ = rw->w.state;
            race::Disable();
        }
        if(rec::Add(gocpp::recv(rw->readerCount), 1) < 0)
        {
            runtime_SemacquireRWMutexR(& rw->readerSem, false, 0);
        }
        if(race::Enabled)
        {
            race::Enable();
            race::Acquire(unsafe::Pointer(& rw->readerSem));
        }
    }

    // TryRLock tries to lock rw for reading and reports whether it succeeded.
    //
    // Note that while correct uses of TryRLock do exist, they are rare,
    // and use of TryRLock is often a sign of a deeper problem
    // in a particular use of mutexes.
    bool rec::TryRLock(struct RWMutex* rw)
    {
        if(race::Enabled)
        {
            _ = rw->w.state;
            race::Disable();
        }
        for(; ; )
        {
            auto c = rec::Load(gocpp::recv(rw->readerCount));
            if(c < 0)
            {
                if(race::Enabled)
                {
                    race::Enable();
                }
                return false;
            }
            if(rec::CompareAndSwap(gocpp::recv(rw->readerCount), c, c + 1))
            {
                if(race::Enabled)
                {
                    race::Enable();
                    race::Acquire(unsafe::Pointer(& rw->readerSem));
                }
                return true;
            }
        }
    }

    // RUnlock undoes a single RLock call;
    // it does not affect other simultaneous readers.
    // It is a run-time error if rw is not locked for reading
    // on entry to RUnlock.
    void rec::RUnlock(struct RWMutex* rw)
    {
        if(race::Enabled)
        {
            _ = rw->w.state;
            race::ReleaseMerge(unsafe::Pointer(& rw->writerSem));
            race::Disable();
        }
        if(auto r = rec::Add(gocpp::recv(rw->readerCount), - 1); r < 0)
        {
            rec::rUnlockSlow(gocpp::recv(rw), r);
        }
        if(race::Enabled)
        {
            race::Enable();
        }
    }

    void rec::rUnlockSlow(struct RWMutex* rw, int32_t r)
    {
        if(r + 1 == 0 || r + 1 == - rwmutexMaxReaders)
        {
            race::Enable();
            fatal("sync: RUnlock of unlocked RWMutex"s);
        }
        if(rec::Add(gocpp::recv(rw->readerWait), - 1) == 0)
        {
            runtime_Semrelease(& rw->writerSem, false, 1);
        }
    }

    // Lock locks rw for writing.
    // If the lock is already locked for reading or writing,
    // Lock blocks until the lock is available.
    void rec::Lock(struct RWMutex* rw)
    {
        if(race::Enabled)
        {
            _ = rw->w.state;
            race::Disable();
        }
        rec::Lock(gocpp::recv(rw->w));
        auto r = rec::Add(gocpp::recv(rw->readerCount), - rwmutexMaxReaders) + rwmutexMaxReaders;
        if(r != 0 && rec::Add(gocpp::recv(rw->readerWait), r) != 0)
        {
            runtime_SemacquireRWMutex(& rw->writerSem, false, 0);
        }
        if(race::Enabled)
        {
            race::Enable();
            race::Acquire(unsafe::Pointer(& rw->readerSem));
            race::Acquire(unsafe::Pointer(& rw->writerSem));
        }
    }

    // TryLock tries to lock rw for writing and reports whether it succeeded.
    //
    // Note that while correct uses of TryLock do exist, they are rare,
    // and use of TryLock is often a sign of a deeper problem
    // in a particular use of mutexes.
    bool rec::TryLock(struct RWMutex* rw)
    {
        if(race::Enabled)
        {
            _ = rw->w.state;
            race::Disable();
        }
        if(! rec::TryLock(gocpp::recv(rw->w)))
        {
            if(race::Enabled)
            {
                race::Enable();
            }
            return false;
        }
        if(! rec::CompareAndSwap(gocpp::recv(rw->readerCount), 0, - rwmutexMaxReaders))
        {
            rec::Unlock(gocpp::recv(rw->w));
            if(race::Enabled)
            {
                race::Enable();
            }
            return false;
        }
        if(race::Enabled)
        {
            race::Enable();
            race::Acquire(unsafe::Pointer(& rw->readerSem));
            race::Acquire(unsafe::Pointer(& rw->writerSem));
        }
        return true;
    }

    // Unlock unlocks rw for writing. It is a run-time error if rw is
    // not locked for writing on entry to Unlock.
    //
    // As with Mutexes, a locked RWMutex is not associated with a particular
    // goroutine. One goroutine may RLock (Lock) a RWMutex and then
    // arrange for another goroutine to RUnlock (Unlock) it.
    void rec::Unlock(struct RWMutex* rw)
    {
        if(race::Enabled)
        {
            _ = rw->w.state;
            race::Release(unsafe::Pointer(& rw->readerSem));
            race::Disable();
        }
        auto r = rec::Add(gocpp::recv(rw->readerCount), rwmutexMaxReaders);
        if(r >= rwmutexMaxReaders)
        {
            race::Enable();
            fatal("sync: Unlock of unlocked RWMutex"s);
        }
        for(auto i = 0; i < int(r); i++)
        {
            runtime_Semrelease(& rw->readerSem, false, 0);
        }
        rec::Unlock(gocpp::recv(rw->w));
        if(race::Enabled)
        {
            race::Enable();
        }
    }

    // syscall_hasWaitingReaders reports whether any goroutine is waiting
    // to acquire a read lock on rw. This exists because syscall.ForkLock
    // is an RWMutex, and we can't change that without breaking compatibility.
    // We don't need or want RWMutex semantics for ForkLock, and we use
    // this private API to avoid having to change the type of ForkLock.
    // For more details see the syscall package.
    //
    //go:linkname syscall_hasWaitingReaders syscall.hasWaitingReaders
    bool syscall_hasWaitingReaders(struct RWMutex* rw)
    {
        auto r = rec::Load(gocpp::recv(rw->readerCount));
        return r < 0 && r + rwmutexMaxReaders > 0;
    }

    // RLocker returns a Locker interface that implements
    // the Lock and Unlock methods by calling rw.RLock and rw.RUnlock.
    struct Locker rec::RLocker(struct RWMutex* rw)
    {
        return (rlocker*)(rw);
    }

    void rec::Lock(golang::sync::rlocker* r)
    {
        rec::RLock(gocpp::recv((RWMutex*)(r)));
    }

    void rec::Unlock(golang::sync::rlocker* r)
    {
        rec::RUnlock(gocpp::recv((RWMutex*)(r)));
    }

}

