// generated by GoCpp from file '$(ImportDir)/runtime/mgc.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/mgc.h"
#include "gocpp/support.h"

#include "golang/internal/abi/type.h"
#include "golang/internal/chacha8rand/chacha8.h"
#include "golang/internal/cpu/cpu.h"
#include "golang/runtime/arena.h"
#include "golang/runtime/atomic_pointer.h"
#include "golang/runtime/cgocall.h"
#include "golang/runtime/chan.h"
#include "golang/runtime/coro.h"
#include "golang/runtime/debuglog_off.h"
#include "golang/runtime/histogram.h"
#include "golang/runtime/internal/atomic/atomic_amd64.h"
#include "golang/runtime/internal/atomic/stubs.h"
#include "golang/runtime/internal/atomic/types.h"
#include "golang/runtime/internal/sys/nih.h"
#include "golang/runtime/lfstack.h"
#include "golang/runtime/lock_sema.h"
#include "golang/runtime/lockrank.h"
#include "golang/runtime/lockrank_off.h"
#include "golang/runtime/malloc.h"
#include "golang/runtime/mbitmap.h"
#include "golang/runtime/mbitmap_allocheaders.h"
#include "golang/runtime/mcache.h"
#include "golang/runtime/mcentral.h"
#include "golang/runtime/mcheckmark.h"
#include "golang/runtime/mfinal.h"
#include "golang/runtime/mfixalloc.h"
#include "golang/runtime/mgclimit.h"
#include "golang/runtime/mgcmark.h"
#include "golang/runtime/mgcpacer.h"
#include "golang/runtime/mgcscavenge.h"
#include "golang/runtime/mgcsweep.h"
#include "golang/runtime/mgcwork.h"
#include "golang/runtime/mheap.h"
#include "golang/runtime/mpagealloc.h"
#include "golang/runtime/mpagecache.h"
#include "golang/runtime/mpallocbits.h"
#include "golang/runtime/mprof.h"
#include "golang/runtime/mranges.h"
#include "golang/runtime/mspanset.h"
#include "golang/runtime/mstats.h"
#include "golang/runtime/mwbbuf.h"
#include "golang/runtime/os_windows.h"
#include "golang/runtime/pagetrace_off.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/pinner.h"
#include "golang/runtime/plugin.h"
#include "golang/runtime/print.h"
#include "golang/runtime/proc.h"
#include "golang/runtime/runtime1.h"
#include "golang/runtime/runtime2.h"
#include "golang/runtime/sema.h"
#include "golang/runtime/signal_windows.h"
#include "golang/runtime/stack.h"
#include "golang/runtime/stubs.h"
#include "golang/runtime/symtab.h"
#include "golang/runtime/time.h"
#include "golang/runtime/time_nofake.h"
#include "golang/runtime/timeasm.h"
#include "golang/runtime/trace2buf.h"
#include "golang/runtime/trace2runtime.h"
#include "golang/runtime/trace2status.h"
#include "golang/runtime/trace2time.h"
#include "golang/unsafe/unsafe.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
        using atomic::rec::Add;
        using atomic::rec::Load;
        using atomic::rec::Store;
    }

    // concurrentSweep is a debug flag. Disabling this flag
    // ensures all spans are swept while the world is stopped.
    // debugScanConservative enables debug logging for stack
    // frames that are scanned conservatively.
    // sweepMinHeapDistance is a lower bound on the heap distance
    // (in bytes) reserved for concurrent sweeping between GC
    // cycles.
    // heapObjectsCanMove always returns false in the current garbage collector.
    // It exists for go4.org/unsafe/assume-no-moving-gc, which is an
    // unfortunate idea that had an even more unfortunate implementation.
    // Every time a new Go release happened, the package stopped building,
    // and the authors had to add a new file with a new //go:build line, and
    // then the entire ecosystem of packages with that as a dependency had to
    // explicitly update to the new version. Many packages depend on
    // assume-no-moving-gc transitively, through paths like
    // inet.af/netaddr -> go4.org/intern -> assume-no-moving-gc.
    // This was causing a significant amount of friction around each new
    // release, so we added this bool for the package to //go:linkname
    // instead. The bool is still unfortunate, but it's not as bad as
    // breaking the ecosystem on every new release.
    //
    // If the Go garbage collector ever does move heap objects, we can set
    // this to true to break all the programs using assume-no-moving-gc.
    //
    //go:linkname heapObjectsCanMove
    bool heapObjectsCanMove()
    {
        return false;
    }

    void gcinit()
    {
        if(gocpp::Sizeof<workbuf>() != _WorkbufSize)
        {
            go_throw("size of Workbuf is suboptimal"s);
        }
        rec::Store(gocpp::recv(sweep.active.state), sweepDrainedMask);
        rec::init(gocpp::recv(gcController), readGOGC(), readGOMEMLIMIT());
        work.startSema = 1;
        work.markDoneSema = 1;
        lockInit(& work.sweepWaiters.lock, lockRankSweepWaiters);
        lockInit(& work.assistQueue.lock, lockRankAssistQueue);
        lockInit(& work.wbufSpans.lock, lockRankWbufSpans);
    }

    // gcenable is called after the bulk of the runtime initialization,
    // just before we're about to start letting user code run.
    // It kicks off the background sweeper goroutine, the background
    // scavenger goroutine, and enables GC.
    void gcenable()
    {
        auto c = gocpp::make(gocpp::Tag<gocpp::channel<int>>(), 2);
        gocpp::go([&]{ bgsweep(c); });
        gocpp::go([&]{ bgscavenge(c); });
        c.recv();
        c.recv();
        memstats.enablegc = true;
    }

    // Garbage collector phase.
    // Indicates to write barrier and synchronization task to perform.
    uint32_t gcphase;
    struct gocpp_id_0
    {
        bool enabled;
        gocpp::array<unsigned char, 3> pad;
        uint64_t alignme;

        using isGoStruct = void;

        template<typename T> requires gocpp::GoStruct<T>
        operator T()
        {
            T result;
            result.enabled = this->enabled;
            result.pad = this->pad;
            result.alignme = this->alignme;
            return result;
        }

        template<typename T> requires gocpp::GoStruct<T>
        bool operator==(const T& ref) const
        {
            if (enabled != ref.enabled) return false;
            if (pad != ref.pad) return false;
            if (alignme != ref.alignme) return false;
            return true;
        }

        std::ostream& PrintTo(std::ostream& os) const
        {
            os << '{';
            os << "" << enabled;
            os << " " << pad;
            os << " " << alignme;
            os << '}';
            return os;
        }
    };

    std::ostream& operator<<(std::ostream& os, const struct gocpp_id_0& value)
    {
        return value.PrintTo(os);
    }


    // The compiler knows about this variable.
    // If you change it, you must change builtin/runtime.go, too.
    // If you change the first four bytes, you must also change the write
    // barrier insertion code.
    gocpp_id_0 writeBarrier;
    // gcBlackenEnabled is 1 if mutator assists and background mark
    // workers are allowed to blacken objects. This must only be set when
    // gcphase == _GCmark.
    uint32_t gcBlackenEnabled;
    //go:nosplit
    void setGCPhase(uint32_t x)
    {
        atomic::Store(& gcphase, x);
        writeBarrier.enabled = gcphase == _GCmark || gcphase == _GCmarktermination;
    }

    // gcMarkWorkerMode represents the mode that a concurrent mark worker
    // should operate in.
    //
    // Concurrent marking happens through four different mechanisms. One
    // is mutator assists, which happen in response to allocations and are
    // not scheduled. The other three are variations in the per-P mark
    // workers and are distinguished by gcMarkWorkerMode.
    // gcMarkWorkerNotWorker indicates that the next scheduled G is not
    // starting work and the mode should be ignored.
    // gcMarkWorkerDedicatedMode indicates that the P of a mark
    // worker is dedicated to running that mark worker. The mark
    // worker should run without preemption.
    // gcMarkWorkerFractionalMode indicates that a P is currently
    // running the "fractional" mark worker. The fractional worker
    // is necessary when GOMAXPROCS*gcBackgroundUtilization is not
    // an integer and using only dedicated workers would result in
    // utilization too far from the target of gcBackgroundUtilization.
    // The fractional worker should run until it is preempted and
    // will be scheduled to pick up the fractional part of
    // GOMAXPROCS*gcBackgroundUtilization.
    // gcMarkWorkerIdleMode indicates that a P is running the mark
    // worker because it has nothing else to do. The idle worker
    // should run until it is preempted and account its time
    // against gcController.idleMarkTime.
    // gcMarkWorkerModeStrings are the strings labels of gcMarkWorkerModes
    // to use in execution traces.
    gocpp::array<std::string, 4> gcMarkWorkerModeStrings = gocpp::array<std::string, 4> {"Not worker"s, "GC (dedicated)"s, "GC (fractional)"s, "GC (idle)"s};
    // pollFractionalWorkerExit reports whether a fractional mark worker
    // should self-preempt. It assumes it is called from the fractional
    // worker.
    bool pollFractionalWorkerExit()
    {
        auto now = nanotime();
        auto delta = now - gcController.markStartTime;
        if(delta <= 0)
        {
            return true;
        }
        auto p = rec::ptr(gocpp::recv(getg()->m->p));
        auto selfTime = p->gcFractionalMarkTime + (now - p->gcMarkWorkerStartTime);
        return double(selfTime) / double(delta) > 1.2 * gcController.fractionalUtilizationGoal;
    }

    workType work;
    
    template<typename T> requires gocpp::GoStruct<T>
    gocpp_id_1::operator T()
    {
        T result;
        result.lock = this->lock;
        result.free = this->free;
        result.busy = this->busy;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gocpp_id_1::operator==(const T& ref) const
    {
        if (lock != ref.lock) return false;
        if (free != ref.free) return false;
        if (busy != ref.busy) return false;
        return true;
    }

    std::ostream& gocpp_id_1::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << lock;
        os << " " << free;
        os << " " << busy;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gocpp_id_1& value)
    {
        return value.PrintTo(os);
    }


    
    template<typename T> requires gocpp::GoStruct<T>
    gocpp_id_2::operator T()
    {
        T result;
        result.lock = this->lock;
        result.q = this->q;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gocpp_id_2::operator==(const T& ref) const
    {
        if (lock != ref.lock) return false;
        if (q != ref.q) return false;
        return true;
    }

    std::ostream& gocpp_id_2::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << lock;
        os << " " << q;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gocpp_id_2& value)
    {
        return value.PrintTo(os);
    }


    
    template<typename T> requires gocpp::GoStruct<T>
    gocpp_id_3::operator T()
    {
        T result;
        result.lock = this->lock;
        result.list = this->list;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gocpp_id_3::operator==(const T& ref) const
    {
        if (lock != ref.lock) return false;
        if (list != ref.list) return false;
        return true;
    }

    std::ostream& gocpp_id_3::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << lock;
        os << " " << list;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gocpp_id_3& value)
    {
        return value.PrintTo(os);
    }


    
    template<typename T> requires gocpp::GoStruct<T>
    workType::operator T()
    {
        T result;
        result.full = this->full;
        result._1 = this->_1;
        result.empty = this->empty;
        result._2 = this->_2;
        result.wbufSpans = this->wbufSpans;
        result._3 = this->_3;
        result.bytesMarked = this->bytesMarked;
        result.markrootNext = this->markrootNext;
        result.markrootJobs = this->markrootJobs;
        result.nproc = this->nproc;
        result.tstart = this->tstart;
        result.nwait = this->nwait;
        result.nDataRoots = this->nDataRoots;
        result.nBSSRoots = this->nBSSRoots;
        result.nSpanRoots = this->nSpanRoots;
        result.nStackRoots = this->nStackRoots;
        result.baseData = this->baseData;
        result.baseBSS = this->baseBSS;
        result.baseSpans = this->baseSpans;
        result.baseStacks = this->baseStacks;
        result.baseEnd = this->baseEnd;
        result.stackRoots = this->stackRoots;
        result.startSema = this->startSema;
        result.markDoneSema = this->markDoneSema;
        result.bgMarkReady = this->bgMarkReady;
        result.bgMarkDone = this->bgMarkDone;
        result.mode = this->mode;
        result.userForced = this->userForced;
        result.initialHeapLive = this->initialHeapLive;
        result.assistQueue = this->assistQueue;
        result.sweepWaiters = this->sweepWaiters;
        result.cycles = this->cycles;
        result.stwprocs = this->stwprocs;
        result.maxprocs = this->maxprocs;
        result.tSweepTerm = this->tSweepTerm;
        result.tMark = this->tMark;
        result.tMarkTerm = this->tMarkTerm;
        result.tEnd = this->tEnd;
        result.pauseNS = this->pauseNS;
        result.heap0 = this->heap0;
        result.heap1 = this->heap1;
        result.heap2 = this->heap2;
        result.cpuStats = this->cpuStats;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool workType::operator==(const T& ref) const
    {
        if (full != ref.full) return false;
        if (_1 != ref._1) return false;
        if (empty != ref.empty) return false;
        if (_2 != ref._2) return false;
        if (wbufSpans != ref.wbufSpans) return false;
        if (_3 != ref._3) return false;
        if (bytesMarked != ref.bytesMarked) return false;
        if (markrootNext != ref.markrootNext) return false;
        if (markrootJobs != ref.markrootJobs) return false;
        if (nproc != ref.nproc) return false;
        if (tstart != ref.tstart) return false;
        if (nwait != ref.nwait) return false;
        if (nDataRoots != ref.nDataRoots) return false;
        if (nBSSRoots != ref.nBSSRoots) return false;
        if (nSpanRoots != ref.nSpanRoots) return false;
        if (nStackRoots != ref.nStackRoots) return false;
        if (baseData != ref.baseData) return false;
        if (baseBSS != ref.baseBSS) return false;
        if (baseSpans != ref.baseSpans) return false;
        if (baseStacks != ref.baseStacks) return false;
        if (baseEnd != ref.baseEnd) return false;
        if (stackRoots != ref.stackRoots) return false;
        if (startSema != ref.startSema) return false;
        if (markDoneSema != ref.markDoneSema) return false;
        if (bgMarkReady != ref.bgMarkReady) return false;
        if (bgMarkDone != ref.bgMarkDone) return false;
        if (mode != ref.mode) return false;
        if (userForced != ref.userForced) return false;
        if (initialHeapLive != ref.initialHeapLive) return false;
        if (assistQueue != ref.assistQueue) return false;
        if (sweepWaiters != ref.sweepWaiters) return false;
        if (cycles != ref.cycles) return false;
        if (stwprocs != ref.stwprocs) return false;
        if (maxprocs != ref.maxprocs) return false;
        if (tSweepTerm != ref.tSweepTerm) return false;
        if (tMark != ref.tMark) return false;
        if (tMarkTerm != ref.tMarkTerm) return false;
        if (tEnd != ref.tEnd) return false;
        if (pauseNS != ref.pauseNS) return false;
        if (heap0 != ref.heap0) return false;
        if (heap1 != ref.heap1) return false;
        if (heap2 != ref.heap2) return false;
        if (cpuStats != ref.cpuStats) return false;
        return true;
    }

    std::ostream& workType::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << full;
        os << " " << _1;
        os << " " << empty;
        os << " " << _2;
        os << " " << wbufSpans;
        os << " " << _3;
        os << " " << bytesMarked;
        os << " " << markrootNext;
        os << " " << markrootJobs;
        os << " " << nproc;
        os << " " << tstart;
        os << " " << nwait;
        os << " " << nDataRoots;
        os << " " << nBSSRoots;
        os << " " << nSpanRoots;
        os << " " << nStackRoots;
        os << " " << baseData;
        os << " " << baseBSS;
        os << " " << baseSpans;
        os << " " << baseStacks;
        os << " " << baseEnd;
        os << " " << stackRoots;
        os << " " << startSema;
        os << " " << markDoneSema;
        os << " " << bgMarkReady;
        os << " " << bgMarkDone;
        os << " " << mode;
        os << " " << userForced;
        os << " " << initialHeapLive;
        os << " " << assistQueue;
        os << " " << sweepWaiters;
        os << " " << cycles;
        os << " " << stwprocs;
        os << " " << maxprocs;
        os << " " << tSweepTerm;
        os << " " << tMark;
        os << " " << tMarkTerm;
        os << " " << tEnd;
        os << " " << pauseNS;
        os << " " << heap0;
        os << " " << heap1;
        os << " " << heap2;
        os << " " << cpuStats;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct workType& value)
    {
        return value.PrintTo(os);
    }

    // GC runs a garbage collection and blocks the caller until the
    // garbage collection is complete. It may also block the entire
    // program.
    void GC()
    {
        auto n = rec::Load(gocpp::recv(work.cycles));
        gcWaitOnMark(n);
        gcStart(gocpp::Init<gcTrigger>([=](auto& x) {
            x.kind = gcTriggerCycle;
            x.n = n + 1;
        }));
        gcWaitOnMark(n + 1);
        for(; rec::Load(gocpp::recv(work.cycles)) == n + 1 && sweepone() != ~ uintptr_t(0); )
        {
            Gosched();
        }
        for(; rec::Load(gocpp::recv(work.cycles)) == n + 1 && ! isSweepDone(); )
        {
            Gosched();
        }
        auto mp = acquirem();
        auto cycle = rec::Load(gocpp::recv(work.cycles));
        if(cycle == n + 1 || (gcphase == _GCmark && cycle == n + 2))
        {
            mProf_PostSweep();
        }
        releasem(mp);
    }

    // gcWaitOnMark blocks until GC finishes the Nth mark phase. If GC has
    // already completed this mark phase, it returns immediately.
    void gcWaitOnMark(uint32_t n)
    {
        for(; ; )
        {
            lock(& work.sweepWaiters.lock);
            auto nMarks = rec::Load(gocpp::recv(work.cycles));
            if(gcphase != _GCmark)
            {
                nMarks++;
            }
            if(nMarks > n)
            {
                unlock(& work.sweepWaiters.lock);
                return;
            }
            rec::push(gocpp::recv(work.sweepWaiters.list), getg());
            goparkunlock(& work.sweepWaiters.lock, waitReasonWaitForGCCycle, traceBlockUntilGCEnds, 1);
        }
    }

    // gcMode indicates how concurrent a GC cycle should be.
    // A gcTrigger is a predicate for starting a GC cycle. Specifically,
    // it is an exit condition for the _GCoff phase.
    
    template<typename T> requires gocpp::GoStruct<T>
    gcTrigger::operator T()
    {
        T result;
        result.kind = this->kind;
        result.now = this->now;
        result.n = this->n;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gcTrigger::operator==(const T& ref) const
    {
        if (kind != ref.kind) return false;
        if (now != ref.now) return false;
        if (n != ref.n) return false;
        return true;
    }

    std::ostream& gcTrigger::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << kind;
        os << " " << now;
        os << " " << n;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gcTrigger& value)
    {
        return value.PrintTo(os);
    }

    // gcTriggerHeap indicates that a cycle should be started when
    // the heap size reaches the trigger heap size computed by the
    // controller.
    // gcTriggerTime indicates that a cycle should be started when
    // it's been more than forcegcperiod nanoseconds since the
    // previous GC cycle.
    // gcTriggerCycle indicates that a cycle should be started if
    // we have not yet started cycle number gcTrigger.n (relative
    // to work.cycles).
    // test reports whether the trigger condition is satisfied, meaning
    // that the exit condition for the _GCoff phase has been met. The exit
    // condition should be tested when allocating.
    bool rec::test(struct gcTrigger t)
    {
        if(! memstats.enablegc || rec::Load(gocpp::recv(panicking)) != 0 || gcphase != _GCoff)
        {
            return false;
        }
        //Go switch emulation
        {
            auto condition = t.kind;
            int conditionId = -1;
            if(condition == gcTriggerHeap) { conditionId = 0; }
            else if(condition == gcTriggerTime) { conditionId = 1; }
            else if(condition == gcTriggerCycle) { conditionId = 2; }
            switch(conditionId)
            {
                case 0:
                    auto [trigger, gocpp_id_5] = rec::trigger(gocpp::recv(gcController));
                    return rec::Load(gocpp::recv(gcController.heapLive)) >= trigger;
                    break;
                case 1:
                    if(rec::Load(gocpp::recv(gcController.gcPercent)) < 0)
                    {
                        return false;
                    }
                    auto lastgc = int64_t(atomic::Load64(& memstats.last_gc_nanotime));
                    return lastgc != 0 && t.now - lastgc > forcegcperiod;
                    break;
                case 2:
                    return int32_t(t.n - rec::Load(gocpp::recv(work.cycles))) > 0;
                    break;
            }
        }
        return true;
    }

    // gcStart starts the GC. It transitions from _GCoff to _GCmark (if
    // debug.gcstoptheworld == 0) or performs all of GC (if
    // debug.gcstoptheworld != 0).
    //
    // This may return without performing this transition in some cases,
    // such as when called on a system stack or with locks held.
    void gcStart(struct gcTrigger trigger)
    {
        auto mp = acquirem();
        if(auto gp = getg(); gp == mp->g0 || mp->locks > 1 || mp->preemptoff != ""s)
        {
            releasem(mp);
            return;
        }
        releasem(mp);
        mp = nullptr;
        for(; rec::test(gocpp::recv(trigger)) && sweepone() != ~ uintptr_t(0); )
        {
        }
        semacquire(& work.startSema);
        if(! rec::test(gocpp::recv(trigger)))
        {
            semrelease(& work.startSema);
            return;
        }
        auto mode = gcBackgroundMode;
        if(debug.gcstoptheworld == 1)
        {
            mode = gcForceMode;
        }
        else
        if(debug.gcstoptheworld == 2)
        {
            mode = gcForceBlockMode;
        }
        semacquire(& gcsema);
        semacquire(& worldsema);
        work.userForced = trigger.kind == gcTriggerCycle;
        auto trace = traceAcquire();
        if(rec::ok(gocpp::recv(trace)))
        {
            rec::GCStart(gocpp::recv(trace));
            traceRelease(trace);
        }
        for(auto [gocpp_ignored, p] : allp)
        {
            if(auto fg = rec::Load(gocpp::recv(p->mcache->flushGen)); fg != mheap_.sweepgen)
            {
                println("runtime: p"s, p->id, "flushGen"s, fg, "!= sweepgen"s, mheap_.sweepgen);
                go_throw("p mcache not flushed"s);
            }
        }
        gcBgMarkStartWorkers();
        systemstack(gcResetMarkState);
        std::tie(work.stwprocs, work.maxprocs) = std::tuple{gomaxprocs, gomaxprocs};
        if(work.stwprocs > ncpu)
        {
            work.stwprocs = ncpu;
        }
        work.heap0 = rec::Load(gocpp::recv(gcController.heapLive));
        work.pauseNS = 0;
        work.mode = mode;
        auto now = nanotime();
        work.tSweepTerm = now;
        worldStop stw = {};
        systemstack([=]() mutable -> void
        {
            stw = stopTheWorldWithSema(stwGCSweepTerm);
        });
        systemstack([=]() mutable -> void
        {
            finishsweep_m();
        });
        clearpools();
        rec::Add(gocpp::recv(work.cycles), 1);
        rec::startCycle(gocpp::recv(gcController), now, int(gomaxprocs), trigger);
        rec::startGCTransition(gocpp::recv(gcCPULimiter), true, now);
        if(mode != gcBackgroundMode)
        {
            schedEnableUser(false);
        }
        setGCPhase(_GCmark);
        gcBgMarkPrepare();
        gcMarkRootPrepare();
        gcMarkTinyAllocs();
        atomic::Store(& gcBlackenEnabled, 1);
        mp = acquirem();
        systemstack([=]() mutable -> void
        {
            now = startTheWorldWithSema(0, stw);
            work.pauseNS += now - stw.start;
            work.tMark = now;
            auto sweepTermCpu = int64_t(work.stwprocs) * (work.tMark - work.tSweepTerm);
            work.cpuStats.gcPauseTime += sweepTermCpu;
            work.cpuStats.gcTotalTime += sweepTermCpu;
            rec::finishGCTransition(gocpp::recv(gcCPULimiter), now);
        });
        semrelease(& worldsema);
        releasem(mp);
        if(mode != gcBackgroundMode)
        {
            Gosched();
        }
        semrelease(& work.startSema);
    }

    // gcMarkDoneFlushed counts the number of P's with flushed work.
    //
    // Ideally this would be a captured local in gcMarkDone, but forEachP
    // escapes its callback closure, so it can't capture anything.
    //
    // This is protected by markDoneSema.
    uint32_t gcMarkDoneFlushed;
    // gcMarkDone transitions the GC from mark to mark termination if all
    // reachable objects have been marked (that is, there are no grey
    // objects and can be no more in the future). Otherwise, it flushes
    // all local work to the global queues where it can be discovered by
    // other workers.
    //
    // This should be called when all local mark work has been drained and
    // there are no remaining workers. Specifically, when
    //
    //	work.nwait == work.nproc && !gcMarkWorkAvailable(p)
    //
    // The calling context must be preemptible.
    //
    // Flushing local work is important because idle Ps may have local
    // work queued. This is the only way to make that work visible and
    // drive GC to completion.
    //
    // It is explicitly okay to have write barriers in this function. If
    // it does transition to mark termination, then all reachable objects
    // have been marked, so the write barrier cannot shade any more
    // objects.
    void gcMarkDone()
    {
        semacquire(& work.markDoneSema);
        top:
        if(! (gcphase == _GCmark && work.nwait == work.nproc && ! gcMarkWorkAvailable(nullptr)))
        {
            semrelease(& work.markDoneSema);
            return;
        }
        semacquire(& worldsema);
        gcMarkDoneFlushed = 0;
        forEachP(waitReasonGCMarkTermination, [=](struct p* pp) mutable -> void
        {
            wbBufFlush1(pp);
            rec::dispose(gocpp::recv(pp->gcw));
            if(pp->gcw.flushedWork)
            {
                atomic::Xadd(& gcMarkDoneFlushed, 1);
                pp->gcw.flushedWork = false;
            }
        });
        if(gcMarkDoneFlushed != 0)
        {
            semrelease(& worldsema);
            goto top;
        }
        auto now = nanotime();
        work.tMarkTerm = now;
        getg()->m->preemptoff = "gcing"s;
        worldStop stw = {};
        systemstack([=]() mutable -> void
        {
            stw = stopTheWorldWithSema(stwGCMarkTerm);
        });
        auto restart = false;
        systemstack([=]() mutable -> void
        {
            for(auto [gocpp_ignored, p] : allp)
            {
                wbBufFlush1(p);
                if(! rec::empty(gocpp::recv(p->gcw)))
                {
                    restart = true;
                    break;
                }
            }
        });
        if(restart)
        {
            getg()->m->preemptoff = ""s;
            systemstack([=]() mutable -> void
            {
                auto now = startTheWorldWithSema(0, stw);
                work.pauseNS += now - stw.start;
            });
            semrelease(& worldsema);
            goto top;
        }
        gcComputeStartingStackSize();
        atomic::Store(& gcBlackenEnabled, 0);
        rec::startGCTransition(gocpp::recv(gcCPULimiter), false, now);
        gcWakeAllAssists();
        semrelease(& work.markDoneSema);
        schedEnableUser(true);
        rec::endCycle(gocpp::recv(gcController), now, int(gomaxprocs), work.userForced);
        gcMarkTermination(stw);
    }

    // World must be stopped and mark assists and background workers must be
    // disabled.
    void gcMarkTermination(struct worldStop stw)
    {
        setGCPhase(_GCmarktermination);
        work.heap1 = rec::Load(gocpp::recv(gcController.heapLive));
        auto startTime = nanotime();
        auto mp = acquirem();
        mp->preemptoff = "gcing"s;
        mp->traceback = 2;
        auto curgp = mp->curg;
        casGToWaiting(curgp, _Grunning, waitReasonGarbageCollection);
        systemstack([=]() mutable -> void
        {
            gcMark(startTime);
        });
        bool stwSwept = {};
        systemstack([=]() mutable -> void
        {
            work.heap2 = work.bytesMarked;
            if(debug.gccheckmark > 0)
            {
                startCheckmarks();
                gcResetMarkState();
                auto gcw = & rec::ptr(gocpp::recv(getg()->m->p))->gcw;
                gcDrain(gcw, 0);
                wbBufFlush1(rec::ptr(gocpp::recv(getg()->m->p)));
                rec::dispose(gocpp::recv(gcw));
                endCheckmarks();
            }
            setGCPhase(_GCoff);
            stwSwept = gcSweep(work.mode);
        });
        mp->traceback = 0;
        casgstatus(curgp, _Gwaiting, _Grunning);
        auto trace = traceAcquire();
        if(rec::ok(gocpp::recv(trace)))
        {
            rec::GCDone(gocpp::recv(trace));
            traceRelease(trace);
        }
        mp->preemptoff = ""s;
        if(gcphase != _GCoff)
        {
            go_throw("gc done but gcphase != _GCoff"s);
        }
        memstats.lastHeapInUse = rec::load(gocpp::recv(gcController.heapInUse));
        systemstack(gcControllerCommit);
        auto now = nanotime();
        auto [sec, nsec, gocpp_id_7] = time_now();
        auto unixNow = sec * 1e9 + int64_t(nsec);
        work.pauseNS += now - stw.start;
        work.tEnd = now;
        atomic::Store64(& memstats.last_gc_unix, uint64_t(unixNow));
        atomic::Store64(& memstats.last_gc_nanotime, uint64_t(now));
        memstats.pause_ns[memstats.numgc % uint32_t(len(memstats.pause_ns))] = uint64_t(work.pauseNS);
        memstats.pause_end[memstats.numgc % uint32_t(len(memstats.pause_end))] = uint64_t(unixNow);
        memstats.pause_total_ns += uint64_t(work.pauseNS);
        auto markTermCpu = int64_t(work.stwprocs) * (work.tEnd - work.tMarkTerm);
        work.cpuStats.gcPauseTime += markTermCpu;
        work.cpuStats.gcTotalTime += markTermCpu;
        rec::accumulate(gocpp::recv(work.cpuStats), now, true);
        memstats.gc_cpu_fraction = double(work.cpuStats.gcTotalTime - work.cpuStats.gcIdleTime) / double(work.cpuStats.totalTime);
        rec::Store(gocpp::recv(scavenge.assistTime), 0);
        rec::Store(gocpp::recv(scavenge.backgroundTime), 0);
        rec::Store(gocpp::recv(sched.idleTime), 0);
        if(work.userForced)
        {
            memstats.numforcedgc++;
        }
        lock(& work.sweepWaiters.lock);
        memstats.numgc++;
        injectglist(& work.sweepWaiters.list);
        unlock(& work.sweepWaiters.lock);
        rec::nextGen(gocpp::recv(mheap_.pages.scav.index));
        rec::finishGCTransition(gocpp::recv(gcCPULimiter), now);
        mProf_NextCycle();
        auto sl = rec::begin(gocpp::recv(sweep.active));
        if(! stwSwept && ! sl.valid)
        {
            go_throw("failed to set sweep barrier"s);
        }
        else
        if(stwSwept && sl.valid)
        {
            go_throw("non-concurrent sweep failed to drain all sweep queues"s);
        }
        systemstack([=]() mutable -> void
        {
            startTheWorldWithSema(now, stw);
        });
        mProf_Flush();
        prepareFreeWorkbufs();
        systemstack(freeStackSpans);
        forEachP(waitReasonFlushProcCaches, [=](struct p* pp) mutable -> void
        {
            rec::prepareForSweep(gocpp::recv(pp->mcache));
            if(pp->status == _Pidle)
            {
                systemstack([=]() mutable -> void
                {
                    lock(& mheap_.lock);
                    rec::flush(gocpp::recv(pp->pcache), & mheap_.pages);
                    unlock(& mheap_.lock);
                });
            }
            pp->pinnerCache = nullptr;
        });
        if(sl.valid)
        {
            rec::end(gocpp::recv(sweep.active), sl);
        }
        if(debug.gctrace > 0)
        {
            auto util = int(memstats.gc_cpu_fraction * 100);
            gocpp::array<unsigned char, 24> sbuf = {};
            printlock();
            print("gc "s, memstats.numgc, " @"s, std::string(itoaDiv(sbuf.make_slice(0), uint64_t(work.tSweepTerm - runtimeInitTime) / 1e6, 3)), "s "s, util, "%: "s);
            auto prev = work.tSweepTerm;
            for(auto [i, ns] : gocpp::slice<int64_t> {work.tMark, work.tMarkTerm, work.tEnd})
            {
                if(i != 0)
                {
                    print("+"s);
                }
                print(std::string(fmtNSAsMS(sbuf.make_slice(0), uint64_t(ns - prev))));
                prev = ns;
            }
            print(" ms clock, "s);
            for(auto [i, ns] : gocpp::slice<int64_t> {int64_t(work.stwprocs) * (work.tMark - work.tSweepTerm), rec::Load(gocpp::recv(gcController.assistTime)), rec::Load(gocpp::recv(gcController.dedicatedMarkTime)) + rec::Load(gocpp::recv(gcController.fractionalMarkTime)), rec::Load(gocpp::recv(gcController.idleMarkTime)), markTermCpu})
            {
                if(i == 2 || i == 3)
                {
                    print("/"s);
                }
                else
                if(i != 0)
                {
                    print("+"s);
                }
                print(std::string(fmtNSAsMS(sbuf.make_slice(0), uint64_t(ns))));
            }
            print(" ms cpu, "s, work.heap0 >> 20, "->"s, work.heap1 >> 20, "->"s, work.heap2 >> 20, " MB, "s, gcController.lastHeapGoal >> 20, " MB goal, "s, rec::Load(gocpp::recv(gcController.lastStackScan)) >> 20, " MB stacks, "s, rec::Load(gocpp::recv(gcController.globalsScan)) >> 20, " MB globals, "s, work.maxprocs, " P"s);
            if(work.userForced)
            {
                print(" (forced)"s);
            }
            print("\n"s);
            printunlock();
        }
        lock(& userArenaState.lock);
        auto faultList = userArenaState.fault;
        userArenaState.fault = nullptr;
        unlock(& userArenaState.lock);
        for(auto [gocpp_ignored, lc] : faultList)
        {
            rec::setUserArenaChunkToFault(gocpp::recv(lc.mspan));
        }
        if(rec::heapGoal(gocpp::recv(gcController)) > minHeapForMetadataHugePages)
        {
            systemstack([=]() mutable -> void
            {
                rec::enableMetadataHugePages(gocpp::recv(mheap_));
            });
        }
        semrelease(& worldsema);
        semrelease(& gcsema);
        releasem(mp);
        mp = nullptr;
        if(! concurrentSweep)
        {
            Gosched();
        }
    }

    // gcBgMarkStartWorkers prepares background mark worker goroutines. These
    // goroutines will not run until the mark phase, but they must be started while
    // the work is not stopped and from a regular G stack. The caller must hold
    // worldsema.
    void gcBgMarkStartWorkers()
    {
        for(; gcBgMarkWorkerCount < gomaxprocs; )
        {
            gocpp::go([&]{ gcBgMarkWorker(); });
            notetsleepg(& work.bgMarkReady, - 1);
            noteclear(& work.bgMarkReady);
            gcBgMarkWorkerCount++;
        }
    }

    // gcBgMarkPrepare sets up state for background marking.
    // Mutator assists must not yet be enabled.
    void gcBgMarkPrepare()
    {
        work.nproc = ~ uint32_t(0);
        work.nwait = ~ uint32_t(0);
    }

    // gcBgMarkWorkerNode is an entry in the gcBgMarkWorkerPool. It points to a single
    // gcBgMarkWorker goroutine.
    
    template<typename T> requires gocpp::GoStruct<T>
    gcBgMarkWorkerNode::operator T()
    {
        T result;
        result.node = this->node;
        result.gp = this->gp;
        result.m = this->m;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gcBgMarkWorkerNode::operator==(const T& ref) const
    {
        if (node != ref.node) return false;
        if (gp != ref.gp) return false;
        if (m != ref.m) return false;
        return true;
    }

    std::ostream& gcBgMarkWorkerNode::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << node;
        os << " " << gp;
        os << " " << m;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gcBgMarkWorkerNode& value)
    {
        return value.PrintTo(os);
    }

    void gcBgMarkWorker()
    {
        auto gp = getg();
        gp->m->preemptoff = "GC worker init"s;
        auto node = new(gcBgMarkWorkerNode);
        gp->m->preemptoff = ""s;
        rec::set(gocpp::recv(node->gp), gp);
        rec::set(gocpp::recv(node->m), acquirem());
        notewakeup(& work.bgMarkReady);
        for(; ; )
        {
            gopark([=](struct g* g, unsafe::Pointer nodep) mutable -> bool
            {
                auto node = (gcBgMarkWorkerNode*)(nodep);
                if(auto mp = rec::ptr(gocpp::recv(node->m)); mp != nullptr)
                {
                    releasem(mp);
                }
                rec::push(gocpp::recv(gcBgMarkWorkerPool), & node->node);
                return true;
            }, unsafe::Pointer(node), waitReasonGCWorkerIdle, traceBlockSystemGoroutine, 0);
            rec::set(gocpp::recv(node->m), acquirem());
            auto pp = rec::ptr(gocpp::recv(gp->m->p));
            if(gcBlackenEnabled == 0)
            {
                println("worker mode"s, pp->gcMarkWorkerMode);
                go_throw("gcBgMarkWorker: blackening not enabled"s);
            }
            if(pp->gcMarkWorkerMode == gcMarkWorkerNotWorker)
            {
                go_throw("gcBgMarkWorker: mode not set"s);
            }
            auto startTime = nanotime();
            pp->gcMarkWorkerStartTime = startTime;
            bool trackLimiterEvent = {};
            if(pp->gcMarkWorkerMode == gcMarkWorkerIdleMode)
            {
                trackLimiterEvent = rec::start(gocpp::recv(pp->limiterEvent), limiterEventIdleMarkWork, startTime);
            }
            auto decnwait = atomic::Xadd(& work.nwait, - 1);
            if(decnwait == work.nproc)
            {
                println("runtime: work.nwait="s, decnwait, "work.nproc="s, work.nproc);
                go_throw("work.nwait was > work.nproc"s);
            }
            systemstack([=]() mutable -> void
            {
                casGToWaiting(gp, _Grunning, waitReasonGCWorkerActive);
                //Go switch emulation
                {
                    auto condition = pp->gcMarkWorkerMode;
                    int conditionId = -1;
                    if(condition == gcMarkWorkerDedicatedMode) { conditionId = 0; }
                    else if(condition == gcMarkWorkerFractionalMode) { conditionId = 1; }
                    else if(condition == gcMarkWorkerIdleMode) { conditionId = 2; }
                    switch(conditionId)
                    {
                        default:
                            go_throw("gcBgMarkWorker: unexpected gcMarkWorkerMode"s);
                            break;
                        case 0:
                            gcDrainMarkWorkerDedicated(& pp->gcw, true);
                            if(gp->preempt)
                            {
                                if(auto [drainQ, n] = runqdrain(pp); n > 0)
                                {
                                    lock(& sched.lock);
                                    globrunqputbatch(& drainQ, int32_t(n));
                                    unlock(& sched.lock);
                                }
                            }
                            gcDrainMarkWorkerDedicated(& pp->gcw, false);
                            break;
                        case 1:
                            gcDrainMarkWorkerFractional(& pp->gcw);
                            break;
                        case 2:
                            gcDrainMarkWorkerIdle(& pp->gcw);
                            break;
                    }
                }
                casgstatus(gp, _Gwaiting, _Grunning);
            });
            auto now = nanotime();
            auto duration = now - startTime;
            rec::markWorkerStop(gocpp::recv(gcController), pp->gcMarkWorkerMode, duration);
            if(trackLimiterEvent)
            {
                rec::stop(gocpp::recv(pp->limiterEvent), limiterEventIdleMarkWork, now);
            }
            if(pp->gcMarkWorkerMode == gcMarkWorkerFractionalMode)
            {
                atomic::Xaddint64(& pp->gcFractionalMarkTime, duration);
            }
            auto incnwait = atomic::Xadd(& work.nwait, + 1);
            if(incnwait > work.nproc)
            {
                println("runtime: p.gcMarkWorkerMode="s, pp->gcMarkWorkerMode, "work.nwait="s, incnwait, "work.nproc="s, work.nproc);
                go_throw("work.nwait > work.nproc"s);
            }
            pp->gcMarkWorkerMode = gcMarkWorkerNotWorker;
            if(incnwait == work.nproc && ! gcMarkWorkAvailable(nullptr))
            {
                releasem(rec::ptr(gocpp::recv(node->m)));
                rec::set(gocpp::recv(node->m), nullptr);
                gcMarkDone();
            }
        }
    }

    // gcMarkWorkAvailable reports whether executing a mark worker
    // on p is potentially useful. p may be nil, in which case it only
    // checks the global sources of work.
    bool gcMarkWorkAvailable(struct p* p)
    {
        if(p != nullptr && ! rec::empty(gocpp::recv(p->gcw)))
        {
            return true;
        }
        if(! rec::empty(gocpp::recv(work.full)))
        {
            return true;
        }
        if(work.markrootNext < work.markrootJobs)
        {
            return true;
        }
        return false;
    }

    // gcMark runs the mark (or, for concurrent GC, mark termination)
    // All gcWork caches must be empty.
    // STW is in effect at this point.
    void gcMark(int64_t startTime)
    {
        if(debug.allocfreetrace > 0)
        {
            tracegc();
        }
        if(gcphase != _GCmarktermination)
        {
            go_throw("in gcMark expecting to see gcphase as _GCmarktermination"s);
        }
        work.tstart = startTime;
        if(work.full != 0 || work.markrootNext < work.markrootJobs)
        {
            print("runtime: full="s, hex(work.full), " next="s, work.markrootNext, " jobs="s, work.markrootJobs, " nDataRoots="s, work.nDataRoots, " nBSSRoots="s, work.nBSSRoots, " nSpanRoots="s, work.nSpanRoots, " nStackRoots="s, work.nStackRoots, "\n"s);
            gocpp::panic("non-empty mark queue after concurrent mark"s);
        }
        if(debug.gccheckmark > 0)
        {
            gcMarkRootCheck();
        }
        work.stackRoots = nullptr;
        for(auto [gocpp_ignored, p] : allp)
        {
            if(debug.gccheckmark > 0)
            {
                wbBufFlush1(p);
            }
            else
            {
                rec::reset(gocpp::recv(p->wbBuf));
            }
            auto gcw = & p->gcw;
            if(! rec::empty(gocpp::recv(gcw)))
            {
                printlock();
                print("runtime: P "s, p->id, " flushedWork "s, gcw->flushedWork);
                if(gcw->wbuf1 == nullptr)
                {
                    print(" wbuf1=<nil>"s);
                }
                else
                {
                    print(" wbuf1.n="s, gcw->wbuf1->nobj);
                }
                if(gcw->wbuf2 == nullptr)
                {
                    print(" wbuf2=<nil>"s);
                }
                else
                {
                    print(" wbuf2.n="s, gcw->wbuf2->nobj);
                }
                print("\n"s);
                go_throw("P has cached GC work at end of mark termination"s);
            }
            rec::dispose(gocpp::recv(gcw));
        }
        for(auto [gocpp_ignored, p] : allp)
        {
            auto c = p->mcache;
            if(c == nullptr)
            {
                continue;
            }
            c->scanAlloc = 0;
        }
        rec::resetLive(gocpp::recv(gcController), work.bytesMarked);
    }

    // gcSweep must be called on the system stack because it acquires the heap
    // lock. See mheap for details.
    //
    // Returns true if the heap was fully swept by this function.
    //
    // The world must be stopped.
    //
    //go:systemstack
    bool gcSweep(golang::runtime::gcMode mode)
    {
        assertWorldStopped();
        if(gcphase != _GCoff)
        {
            go_throw("gcSweep being done but phase is not GCoff"s);
        }
        lock(& mheap_.lock);
        mheap_.sweepgen += 2;
        rec::reset(gocpp::recv(sweep.active));
        rec::Store(gocpp::recv(mheap_.pagesSwept), 0);
        mheap_.sweepArenas = mheap_.allArenas;
        rec::Store(gocpp::recv(mheap_.reclaimIndex), 0);
        rec::Store(gocpp::recv(mheap_.reclaimCredit), 0);
        unlock(& mheap_.lock);
        rec::clear(gocpp::recv(sweep.centralIndex));
        if(! concurrentSweep || mode == gcForceBlockMode)
        {
            lock(& mheap_.lock);
            mheap_.sweepPagesPerByte = 0;
            unlock(& mheap_.lock);
            for(auto [gocpp_ignored, pp] : allp)
            {
                rec::prepareForSweep(gocpp::recv(pp->mcache));
            }
            for(; sweepone() != ~ uintptr_t(0); )
            {
            }
            prepareFreeWorkbufs();
            for(; freeSomeWbufs(false); )
            {
            }
            mProf_NextCycle();
            mProf_Flush();
            return true;
        }
        lock(& sweep.lock);
        if(sweep.parked)
        {
            sweep.parked = false;
            ready(sweep.g, 0, true);
        }
        unlock(& sweep.lock);
        return false;
    }

    // gcResetMarkState resets global state prior to marking (concurrent
    // or STW) and resets the stack scan state of all Gs.
    //
    // This is safe to do without the world stopped because any Gs created
    // during or after this will start out in the reset state.
    //
    // gcResetMarkState must be called on the system stack because it acquires
    // the heap lock. See mheap for details.
    //
    //go:systemstack
    void gcResetMarkState()
    {
        forEachG([=](struct g* gp) mutable -> void
        {
            gp->gcscandone = false;
            gp->gcAssistBytes = 0;
        });
        lock(& mheap_.lock);
        auto arenas = mheap_.allArenas;
        unlock(& mheap_.lock);
        for(auto [gocpp_ignored, ai] : arenas)
        {
            auto ha = mheap_.arenas[rec::l1(gocpp::recv(ai))][rec::l2(gocpp::recv(ai))];
            for(auto [i, gocpp_ignored] : ha->pageMarks)
            {
                ha->pageMarks[i] = 0;
            }
        }
        work.bytesMarked = 0;
        work.initialHeapLive = rec::Load(gocpp::recv(gcController.heapLive));
    }

    std::function<void ()> poolcleanup;
    gocpp::slice<unsafe::Pointer> boringCaches;
    //go:linkname sync_runtime_registerPoolCleanup sync.runtime_registerPoolCleanup
    void sync_runtime_registerPoolCleanup(std::function<void ()> f)
    {
        poolcleanup = f;
    }

    //go:linkname boring_registerCache crypto/internal/boring/bcache.registerCache
    void boring_registerCache(unsafe::Pointer p)
    {
        boringCaches = append(boringCaches, p);
    }

    void clearpools()
    {
        if(poolcleanup != nullptr)
        {
            poolcleanup();
        }
        for(auto [gocpp_ignored, p] : boringCaches)
        {
            atomicstorep(p, nullptr);
        }
        lock(& sched.sudoglock);
        sudog* sg = {};
        sudog* sgnext = {};
        for(sg = sched.sudogcache; sg != nullptr; sg = sgnext)
        {
            sgnext = sg->next;
            sg->next = nullptr;
        }
        sched.sudogcache = nullptr;
        unlock(& sched.sudoglock);
        lock(& sched.deferlock);
        // disconnect cached list before dropping it on the floor,
        // so that a dangling ref to one entry does not pin all of them.
        _defer* d = {};
        _defer* dlink = {};
        for(d = sched.deferpool; d != nullptr; d = dlink)
        {
            dlink = d->link;
            d->link = nullptr;
        }
        sched.deferpool = nullptr;
        unlock(& sched.deferlock);
    }

    // itoaDiv formats val/(10**dec) into buf.
    gocpp::slice<unsigned char> itoaDiv(gocpp::slice<unsigned char> buf, uint64_t val, int dec)
    {
        auto i = len(buf) - 1;
        auto idec = i - dec;
        for(; val >= 10 || i >= idec; )
        {
            buf[i] = (unsigned char)(val % 10 + '0');
            i--;
            if(i == idec)
            {
                buf[i] = '.';
                i--;
            }
            val /= 10;
        }
        buf[i] = (unsigned char)(val + '0');
        return buf.make_slice(i);
    }

    // fmtNSAsMS nicely formats ns nanoseconds as milliseconds.
    gocpp::slice<unsigned char> fmtNSAsMS(gocpp::slice<unsigned char> buf, uint64_t ns)
    {
        if(ns >= 10e6)
        {
            return itoaDiv(buf, ns / 1e6, 0);
        }
        auto x = ns / 1e3;
        if(x == 0)
        {
            buf[0] = '0';
            return buf.make_slice(0, 1);
        }
        auto dec = 3;
        for(; x >= 100; )
        {
            x /= 10;
            dec--;
        }
        return itoaDiv(buf, x, dec);
    }

    // gcTestMoveStackOnNextCall causes the stack to be moved on a call
    // immediately following the call to this. It may not work correctly
    // if any other work appears after this call (such as returning).
    // Typically the following call should be marked go:noinline so it
    // performs a stack check.
    //
    // In rare cases this may not cause the stack to move, specifically if
    // there's a preemption between this call and the next.
    void gcTestMoveStackOnNextCall()
    {
        auto gp = getg();
        gp->stackguard0 = stackForceMove;
    }

    // gcTestIsReachable performs a GC and returns a bit set where bit i
    // is set if ptrs[i] is reachable.
    uint64_t gcTestIsReachable(gocpp::slice<unsafe::Pointer> ptrs)
    {
        uint64_t mask;
        if(len(ptrs) > 64)
        {
            gocpp::panic("too many pointers for uint64 mask"s);
        }
        semacquire(& gcsema);
        auto specials = gocpp::make(gocpp::Tag<gocpp::slice<specialReachable*>>(), len(ptrs));
        for(auto [i, p] : ptrs)
        {
            lock(& mheap_.speciallock);
            auto s = (specialReachable*)(rec::alloc(gocpp::recv(mheap_.specialReachableAlloc)));
            unlock(& mheap_.speciallock);
            s->special.kind = _KindSpecialReachable;
            if(! addspecial(p, & s->special))
            {
                go_throw("already have a reachable special (duplicate pointer?)"s);
            }
            specials[i] = s;
            ptrs[i] = nullptr;
        }
        semrelease(& gcsema);
        GC();
        for(auto [i, s] : specials)
        {
            if(! s->done)
            {
                printlock();
                println("runtime: object"s, i, "was not swept"s);
                go_throw("IsReachable failed"s);
            }
            if(s->reachable)
            {
                mask |= 1 << i;
            }
            lock(& mheap_.speciallock);
            rec::free(gocpp::recv(mheap_.specialReachableAlloc), unsafe::Pointer(s));
            unlock(& mheap_.speciallock);
        }
        return mask;
    }

    // gcTestPointerClass returns the category of what p points to, one of:
    // "heap", "stack", "data", "bss", "other". This is useful for checking
    // that a test is doing what it's intended to do.
    //
    // This is nosplit simply to avoid extra pointer shuffling that may
    // complicate a test.
    //
    //go:nosplit
    std::string gcTestPointerClass(unsafe::Pointer p)
    {
        auto p2 = uintptr_t(noescape(p));
        auto gp = getg();
        if(gp->stack.lo <= p2 && p2 < gp->stack.hi)
        {
            return "stack"s;
        }
        if(auto [base, gocpp_id_10, gocpp_id_11] = findObject(p2, 0, 0); base != 0)
        {
            return "heap"s;
        }
        for(auto [gocpp_ignored, datap] : activeModules())
        {
            if(datap->data <= p2 && p2 < datap->edata || datap->noptrdata <= p2 && p2 < datap->enoptrdata)
            {
                return "data"s;
            }
            if(datap->bss <= p2 && p2 < datap->ebss || datap->noptrbss <= p2 && p2 <= datap->enoptrbss)
            {
                return "bss"s;
            }
        }
        KeepAlive(p);
        return "other"s;
    }

}

