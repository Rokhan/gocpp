// generated by GoCpp from file '$(ImportDir)/runtime/profbuf.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/profbuf.h"
#include "gocpp/support.h"

#include "golang/runtime/internal/atomic/atomic_amd64.h"
#include "golang/runtime/internal/atomic/types.h"
#include "golang/runtime/lock_sema.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/race0.h"
#include "golang/runtime/runtime2.h"
#include "golang/unsafe/unsafe.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
        using atomic::rec::CompareAndSwap;
        using atomic::rec::Load;
        using atomic::rec::Store;
    }

    // A profBuf is a lock-free buffer for profiling events,
    // safe for concurrent use by one reader and one writer.
    // The writer may be a signal handler running without a user g.
    // The reader is assumed to be a user g.
    //
    // Each logged event corresponds to a fixed size header, a list of
    // uintptrs (typically a stack), and exactly one unsafe.Pointer tag.
    // The header and uintptrs are stored in the circular buffer data and the
    // tag is stored in a circular buffer tags, running in parallel.
    // In the circular buffer data, each event takes 2+hdrsize+len(stk)
    // words: the value 2+hdrsize+len(stk), then the time of the event, then
    // hdrsize words giving the fixed-size header, and then len(stk) words
    // for the stack.
    //
    // The current effective offsets into the tags and data circular buffers
    // for reading and writing are stored in the high 30 and low 32 bits of r and w.
    // The bottom bits of the high 32 are additional flag bits in w, unused in r.
    // "Effective" offsets means the total number of reads or writes, mod 2^length.
    // The offset in the buffer is the effective offset mod the length of the buffer.
    // To make wraparound mod 2^length match wraparound mod length of the buffer,
    // the length of the buffer must be a power of two.
    //
    // If the reader catches up to the writer, a flag passed to read controls
    // whether the read blocks until more data is available. A read returns a
    // pointer to the buffer data itself; the caller is assumed to be done with
    // that data at the next read. The read offset rNext tracks the next offset to
    // be returned by read. By definition, r ≤ rNext ≤ w (before wraparound),
    // and rNext is only used by the reader, so it can be accessed without atomics.
    //
    // If the writer gets ahead of the reader, so that the buffer fills,
    // future writes are discarded and replaced in the output stream by an
    // overflow entry, which has size 2+hdrsize+1, time set to the time of
    // the first discarded write, a header of all zeroed words, and a "stack"
    // containing one word, the number of discarded writes.
    //
    // Between the time the buffer fills and the buffer becomes empty enough
    // to hold more data, the overflow entry is stored as a pending overflow
    // entry in the fields overflow and overflowTime. The pending overflow
    // entry can be turned into a real record by either the writer or the
    // reader. If the writer is called to write a new record and finds that
    // the output buffer has room for both the pending overflow entry and the
    // new record, the writer emits the pending overflow entry and the new
    // record into the buffer. If the reader is called to read data and finds
    // that the output buffer is empty but that there is a pending overflow
    // entry, the reader will return a synthesized record for the pending
    // overflow entry.
    //
    // Only the writer can create or add to a pending overflow entry, but
    // either the reader or the writer can clear the pending overflow entry.
    // A pending overflow entry is indicated by the low 32 bits of 'overflow'
    // holding the number of discarded writes, and overflowTime holding the
    // time of the first discarded write. The high 32 bits of 'overflow'
    // increment each time the low 32 bits transition from zero to non-zero
    // or vice versa. This sequence number avoids ABA problems in the use of
    // compare-and-swap to coordinate between reader and writer.
    // The overflowTime is only written when the low 32 bits of overflow are
    // zero, that is, only when there is no pending overflow entry, in
    // preparation for creating a new one. The reader can therefore fetch and
    // clear the entry atomically using
    //
    //	for {
    //		overflow = load(&b.overflow)
    //		if uint32(overflow) == 0 {
    //			// no pending entry
    //			break
    //		}
    //		time = load(&b.overflowTime)
    //		if cas(&b.overflow, overflow, ((overflow>>32)+1)<<32) {
    //			// pending entry cleared
    //			break
    //		}
    //	}
    //	if uint32(overflow) > 0 {
    //		emit entry for uint32(overflow), time
    //	}
    
    template<typename T> requires gocpp::GoStruct<T>
    profBuf::operator T()
    {
        T result;
        result.r = this->r;
        result.w = this->w;
        result.overflow = this->overflow;
        result.overflowTime = this->overflowTime;
        result.eof = this->eof;
        result.hdrsize = this->hdrsize;
        result.data = this->data;
        result.tags = this->tags;
        result.rNext = this->rNext;
        result.overflowBuf = this->overflowBuf;
        result.wait = this->wait;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool profBuf::operator==(const T& ref) const
    {
        if (r != ref.r) return false;
        if (w != ref.w) return false;
        if (overflow != ref.overflow) return false;
        if (overflowTime != ref.overflowTime) return false;
        if (eof != ref.eof) return false;
        if (hdrsize != ref.hdrsize) return false;
        if (data != ref.data) return false;
        if (tags != ref.tags) return false;
        if (rNext != ref.rNext) return false;
        if (overflowBuf != ref.overflowBuf) return false;
        if (wait != ref.wait) return false;
        return true;
    }

    std::ostream& profBuf::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << r;
        os << " " << w;
        os << " " << overflow;
        os << " " << overflowTime;
        os << " " << eof;
        os << " " << hdrsize;
        os << " " << data;
        os << " " << tags;
        os << " " << rNext;
        os << " " << overflowBuf;
        os << " " << wait;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct profBuf& value)
    {
        return value.PrintTo(os);
    }

    // A profAtomic is the atomically-accessed word holding a profIndex.
    // A profIndex is the packet tag and data counts and flags bits, described above.
    runtime::profIndex rec::load(golang::runtime::profAtomic* x)
    {
        return profIndex(atomic::Load64((uint64_t*)(x)));
    }

    void rec::store(golang::runtime::profAtomic* x, golang::runtime::profIndex go_new)
    {
        atomic::Store64((uint64_t*)(x), uint64_t(go_new));
    }

    bool rec::cas(golang::runtime::profAtomic* x, golang::runtime::profIndex old, golang::runtime::profIndex go_new)
    {
        return atomic::Cas64((uint64_t*)(x), uint64_t(old), uint64_t(go_new));
    }

    uint32_t rec::dataCount(golang::runtime::profIndex x)
    {
        return uint32_t(x);
    }

    uint32_t rec::tagCount(golang::runtime::profIndex x)
    {
        return uint32_t(x >> 34);
    }

    // countSub subtracts two counts obtained from profIndex.dataCount or profIndex.tagCount,
    // assuming that they are no more than 2^29 apart (guaranteed since they are never more than
    // len(data) or len(tags) apart, respectively).
    // tagCount wraps at 2^30, while dataCount wraps at 2^32.
    // This function works for both.
    int countSub(uint32_t x, uint32_t y)
    {
        return int((int32_t(x - y) << 2) >> 2);
    }

    // addCountsAndClearFlags returns the packed form of "x + (data, tag) - all flags".
    runtime::profIndex rec::addCountsAndClearFlags(golang::runtime::profIndex x, int data, int tag)
    {
        return profIndex((((uint64_t(x) >> 34) + uint64_t((uint32_t(tag) << 2) >> 2)) << 34) | uint64_t(uint32_t(x) + uint32_t(data)));
    }

    // hasOverflow reports whether b has any overflow records pending.
    bool rec::hasOverflow(struct profBuf* b)
    {
        return uint32_t(rec::Load(gocpp::recv(b->overflow))) > 0;
    }

    // takeOverflow consumes the pending overflow records, returning the overflow count
    // and the time of the first overflow.
    // When called by the reader, it is racing against incrementOverflow.
    std::tuple<uint32_t, uint64_t> rec::takeOverflow(struct profBuf* b)
    {
        uint32_t count;
        uint64_t time;
        auto overflow = rec::Load(gocpp::recv(b->overflow));
        time = rec::Load(gocpp::recv(b->overflowTime));
        for(; ; )
        {
            count = uint32_t(overflow);
            if(count == 0)
            {
                time = 0;
                break;
            }
            if(rec::CompareAndSwap(gocpp::recv(b->overflow), overflow, ((overflow >> 32) + 1) << 32))
            {
                break;
            }
            overflow = rec::Load(gocpp::recv(b->overflow));
            time = rec::Load(gocpp::recv(b->overflowTime));
        }
        return {uint32_t(overflow), time};
    }

    // incrementOverflow records a single overflow at time now.
    // It is racing against a possible takeOverflow in the reader.
    void rec::incrementOverflow(struct profBuf* b, int64_t now)
    {
        for(; ; )
        {
            auto overflow = rec::Load(gocpp::recv(b->overflow));
            if(uint32_t(overflow) == 0)
            {
                rec::Store(gocpp::recv(b->overflowTime), uint64_t(now));
                rec::Store(gocpp::recv(b->overflow), (((overflow >> 32) + 1) << 32) + 1);
                break;
            }
            if(int32_t(overflow) == - 1)
            {
                break;
            }
            if(rec::CompareAndSwap(gocpp::recv(b->overflow), overflow, overflow + 1))
            {
                break;
            }
        }
    }

    // newProfBuf returns a new profiling buffer with room for
    // a header of hdrsize words and a buffer of at least bufwords words.
    struct profBuf* newProfBuf(int hdrsize, int bufwords, int tags)
    {
        if(auto min = 2 + hdrsize + 1; bufwords < min)
        {
            bufwords = min;
        }
        if(bufwords >= (1 << 28) || tags >= (1 << 28))
        {
            go_throw("newProfBuf: buffer too large"s);
        }
        int i = {};
        for(i = 1; i < bufwords; i <<= 1)
        {
        }
        bufwords = i;
        for(i = 1; i < tags; i <<= 1)
        {
        }
        tags = i;
        auto b = new(profBuf);
        b->hdrsize = uintptr_t(hdrsize);
        b->data = gocpp::make(gocpp::Tag<gocpp::slice<uint64_t>>(), bufwords);
        b->tags = gocpp::make(gocpp::Tag<gocpp::slice<unsafe::Pointer>>(), tags);
        b->overflowBuf = gocpp::make(gocpp::Tag<gocpp::slice<uint64_t>>(), 2 + b->hdrsize + 1);
        return b;
    }

    // canWriteRecord reports whether the buffer has room
    // for a single contiguous record with a stack of length nstk.
    bool rec::canWriteRecord(struct profBuf* b, int nstk)
    {
        auto br = rec::load(gocpp::recv(b->r));
        auto bw = rec::load(gocpp::recv(b->w));
        if(countSub(rec::tagCount(gocpp::recv(br)), rec::tagCount(gocpp::recv(bw))) + len(b->tags) < 1)
        {
            return false;
        }
        auto nd = countSub(rec::dataCount(gocpp::recv(br)), rec::dataCount(gocpp::recv(bw))) + len(b->data);
        auto want = 2 + int(b->hdrsize) + nstk;
        auto i = int(rec::dataCount(gocpp::recv(bw)) % uint32_t(len(b->data)));
        if(i + want > len(b->data))
        {
            nd -= len(b->data) - i;
        }
        return nd >= want;
    }

    // canWriteTwoRecords reports whether the buffer has room
    // for two records with stack lengths nstk1, nstk2, in that order.
    // Each record must be contiguous on its own, but the two
    // records need not be contiguous (one can be at the end of the buffer
    // and the other can wrap around and start at the beginning of the buffer).
    bool rec::canWriteTwoRecords(struct profBuf* b, int nstk1, int nstk2)
    {
        auto br = rec::load(gocpp::recv(b->r));
        auto bw = rec::load(gocpp::recv(b->w));
        if(countSub(rec::tagCount(gocpp::recv(br)), rec::tagCount(gocpp::recv(bw))) + len(b->tags) < 2)
        {
            return false;
        }
        auto nd = countSub(rec::dataCount(gocpp::recv(br)), rec::dataCount(gocpp::recv(bw))) + len(b->data);
        auto want = 2 + int(b->hdrsize) + nstk1;
        auto i = int(rec::dataCount(gocpp::recv(bw)) % uint32_t(len(b->data)));
        if(i + want > len(b->data))
        {
            nd -= len(b->data) - i;
            i = 0;
        }
        i += want;
        nd -= want;
        want = 2 + int(b->hdrsize) + nstk2;
        if(i + want > len(b->data))
        {
            nd -= len(b->data) - i;
            i = 0;
        }
        return nd >= want;
    }

    // write writes an entry to the profiling buffer b.
    // The entry begins with a fixed hdr, which must have
    // length b.hdrsize, followed by a variable-sized stack
    // and a single tag pointer *tagPtr (or nil if tagPtr is nil).
    // No write barriers allowed because this might be called from a signal handler.
    void rec::write(struct profBuf* b, unsafe::Pointer* tagPtr, int64_t now, gocpp::slice<uint64_t> hdr, gocpp::slice<uintptr_t> stk)
    {
        if(b == nullptr)
        {
            return;
        }
        if(len(hdr) > int(b->hdrsize))
        {
            go_throw("misuse of profBuf.write"s);
        }
        if(auto hasOverflow = rec::hasOverflow(gocpp::recv(b)); hasOverflow && rec::canWriteTwoRecords(gocpp::recv(b), 1, len(stk)))
        {
            auto [count, time] = rec::takeOverflow(gocpp::recv(b));
            if(count > 0)
            {
                gocpp::array<uintptr_t, 1> stk = {};
                stk[0] = uintptr_t(count);
                rec::write(gocpp::recv(b), nullptr, int64_t(time), nullptr, stk.make_slice(0));
            }
        }
        else
        if(hasOverflow || ! rec::canWriteRecord(gocpp::recv(b), len(stk)))
        {
            rec::incrementOverflow(gocpp::recv(b), now);
            rec::wakeupExtra(gocpp::recv(b));
            return;
        }
        auto br = rec::load(gocpp::recv(b->r));
        auto bw = rec::load(gocpp::recv(b->w));
        auto wt = int(rec::tagCount(gocpp::recv(bw)) % uint32_t(len(b->tags)));
        if(tagPtr != nullptr)
        {
            *(uintptr_t*)(unsafe::Pointer(& b->tags[wt])) = uintptr_t(*tagPtr);
        }
        auto wd = int(rec::dataCount(gocpp::recv(bw)) % uint32_t(len(b->data)));
        auto nd = countSub(rec::dataCount(gocpp::recv(br)), rec::dataCount(gocpp::recv(bw))) + len(b->data);
        auto skip = 0;
        if(wd + 2 + int(b->hdrsize) + len(stk) > len(b->data))
        {
            b->data[wd] = 0;
            skip = len(b->data) - wd;
            nd -= skip;
            wd = 0;
        }
        auto data = b->data.make_slice(wd);
        data[0] = uint64_t(2 + b->hdrsize + uintptr_t(len(stk)));
        data[1] = uint64_t(now);
        auto i = uintptr_t(copy(data.make_slice(2, 2 + b->hdrsize), hdr));
        for(; i < b->hdrsize; i++)
        {
            data[2 + i] = 0;
        }
        for(auto [i, pc] : stk)
        {
            data[2 + b->hdrsize + uintptr_t(i)] = uint64_t(pc);
        }
        for(; ; )
        {
            auto old = rec::load(gocpp::recv(b->w));
            auto go_new = rec::addCountsAndClearFlags(gocpp::recv(old), skip + 2 + len(stk) + int(b->hdrsize), 1);
            if(! rec::cas(gocpp::recv(b->w), old, go_new))
            {
                continue;
            }
            if(old & profReaderSleeping != 0)
            {
                notewakeup(& b->wait);
            }
            break;
        }
    }

    // close signals that there will be no more writes on the buffer.
    // Once all the data has been read from the buffer, reads will return eof=true.
    void rec::close(struct profBuf* b)
    {
        if(rec::Load(gocpp::recv(b->eof)) > 0)
        {
            go_throw("runtime: profBuf already closed"s);
        }
        rec::Store(gocpp::recv(b->eof), 1);
        rec::wakeupExtra(gocpp::recv(b));
    }

    // wakeupExtra must be called after setting one of the "extra"
    // atomic fields b.overflow or b.eof.
    // It records the change in b.w and wakes up the reader if needed.
    void rec::wakeupExtra(struct profBuf* b)
    {
        for(; ; )
        {
            auto old = rec::load(gocpp::recv(b->w));
            auto go_new = old | profWriteExtra;
            if(! rec::cas(gocpp::recv(b->w), old, go_new))
            {
                continue;
            }
            if(old & profReaderSleeping != 0)
            {
                notewakeup(& b->wait);
            }
            break;
        }
    }

    // profBufReadMode specifies whether to block when no data is available to read.
    gocpp::array<unsafe::Pointer, 1> overflowTag;
    std::tuple<gocpp::slice<uint64_t>, gocpp::slice<unsafe::Pointer>, bool> rec::read(struct profBuf* b, golang::runtime::profBufReadMode mode)
    {
        gocpp::slice<uint64_t> data;
        gocpp::slice<unsafe::Pointer> tags;
        bool eof;
        if(b == nullptr)
        {
            return {nullptr, nullptr, true};
        }
        auto br = b->rNext;
        auto rPrev = rec::load(gocpp::recv(b->r));
        if(rPrev != br)
        {
            auto ntag = countSub(rec::tagCount(gocpp::recv(br)), rec::tagCount(gocpp::recv(rPrev)));
            auto ti = int(rec::tagCount(gocpp::recv(rPrev)) % uint32_t(len(b->tags)));
            for(auto i = 0; i < ntag; i++)
            {
                b->tags[ti] = nullptr;
                if(ti++; ti == len(b->tags))
                {
                    ti = 0;
                }
            }
            rec::store(gocpp::recv(b->r), br);
        }
        Read:
        auto bw = rec::load(gocpp::recv(b->w));
        auto numData = countSub(rec::dataCount(gocpp::recv(bw)), rec::dataCount(gocpp::recv(br)));
        if(numData == 0)
        {
            if(rec::hasOverflow(gocpp::recv(b)))
            {
                auto [count, time] = rec::takeOverflow(gocpp::recv(b));
                if(count == 0)
                {
                    goto Read;
                }
                auto dst = b->overflowBuf;
                dst[0] = uint64_t(2 + b->hdrsize + 1);
                dst[1] = time;
                for(auto i = uintptr_t(0); i < b->hdrsize; i++)
                {
                    dst[2 + i] = 0;
                }
                dst[2 + b->hdrsize] = uint64_t(count);
                return {dst.make_slice(0, 2 + b->hdrsize + 1), overflowTag.make_slice(0, 1), false};
            }
            if(rec::Load(gocpp::recv(b->eof)) > 0)
            {
                return {nullptr, nullptr, true};
            }
            if(bw & profWriteExtra != 0)
            {
                rec::cas(gocpp::recv(b->w), bw, bw &^ profWriteExtra);
                goto Read;
            }
            if(mode == profBufNonBlocking)
            {
                return {nullptr, nullptr, false};
            }
            if(! rec::cas(gocpp::recv(b->w), bw, bw | profReaderSleeping))
            {
                goto Read;
            }
            notetsleepg(& b->wait, - 1);
            noteclear(& b->wait);
            goto Read;
        }
        data = b->data.make_slice(rec::dataCount(gocpp::recv(br)) % uint32_t(len(b->data)));
        if(len(data) > numData)
        {
            data = data.make_slice(0, numData);
        }
        else
        {
            numData -= len(data);
        }
        auto skip = 0;
        if(data[0] == 0)
        {
            skip = len(data);
            data = b->data;
            if(len(data) > numData)
            {
                data = data.make_slice(0, numData);
            }
        }
        auto ntag = countSub(rec::tagCount(gocpp::recv(bw)), rec::tagCount(gocpp::recv(br)));
        if(ntag == 0)
        {
            go_throw("runtime: malformed profBuf buffer - tag and data out of sync"s);
        }
        tags = b->tags.make_slice(rec::tagCount(gocpp::recv(br)) % uint32_t(len(b->tags)));
        if(len(tags) > ntag)
        {
            tags = tags.make_slice(0, ntag);
        }
        auto di = 0;
        auto ti = 0;
        for(; di < len(data) && data[di] != 0 && ti < len(tags); )
        {
            if(uintptr_t(di) + uintptr_t(data[di]) > uintptr_t(len(data)))
            {
                go_throw("runtime: malformed profBuf buffer - invalid size"s);
            }
            di += int(data[di]);
            ti++;
        }
        b->rNext = rec::addCountsAndClearFlags(gocpp::recv(br), skip + di, ti);
        if(raceenabled)
        {
            raceacquire(unsafe::Pointer(& labelSync));
        }
        return {data.make_slice(0, di), tags.make_slice(0, ti), false};
    }

}

