// generated by GoCpp from file '$(ImportDir)/runtime/debug.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/debug.h"
#include "gocpp/support.h"

#include "golang/internal/abi/type.h"
#include "golang/internal/chacha8rand/chacha8.h"
#include "golang/runtime/cgocall.h"
#include "golang/runtime/chan.h"
#include "golang/runtime/coro.h"
#include "golang/runtime/debuglog_off.h"
#include "golang/runtime/extern.h"
#include "golang/runtime/histogram.h"
#include "golang/runtime/internal/atomic/atomic_amd64.h"
#include "golang/runtime/internal/atomic/types.h"
#include "golang/runtime/internal/sys/nih.h"
#include "golang/runtime/lock_sema.h"
#include "golang/runtime/lockrank.h"
#include "golang/runtime/lockrank_off.h"
#include "golang/runtime/malloc.h"
#include "golang/runtime/mcache.h"
#include "golang/runtime/mgc.h"
#include "golang/runtime/mgclimit.h"
#include "golang/runtime/mgcwork.h"
#include "golang/runtime/mheap.h"
#include "golang/runtime/mpagecache.h"
#include "golang/runtime/mprof.h"
#include "golang/runtime/mranges.h"
#include "golang/runtime/mwbbuf.h"
#include "golang/runtime/os_windows.h"
#include "golang/runtime/pagetrace_off.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/pinner.h"
#include "golang/runtime/proc.h"
#include "golang/runtime/runtime2.h"
#include "golang/runtime/signal_windows.h"
#include "golang/runtime/stack.h"
#include "golang/runtime/stubs.h"
#include "golang/runtime/symtab.h"
#include "golang/runtime/time.h"
#include "golang/runtime/trace2buf.h"
#include "golang/runtime/trace2runtime.h"
#include "golang/runtime/trace2status.h"
#include "golang/runtime/trace2time.h"
#include "golang/unsafe/unsafe.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
        using atomic::rec::Load;
    }

    // GOMAXPROCS sets the maximum number of CPUs that can be executing
    // simultaneously and returns the previous setting. It defaults to
    // the value of [runtime.NumCPU]. If n < 1, it does not change the current setting.
    // This call will go away when the scheduler improves.
    int GOMAXPROCS(int n)
    {
        if(GOARCH == "wasm"s && n > 1)
        {
            n = 1;
        }
        lock(& sched.lock);
        auto ret = int(gomaxprocs);
        unlock(& sched.lock);
        if(n <= 0 || n == ret)
        {
            return ret;
        }
        auto stw = stopTheWorldGC(stwGOMAXPROCS);
        newprocs = int32_t(n);
        startTheWorldGC(stw);
        return ret;
    }

    // NumCPU returns the number of logical CPUs usable by the current process.
    //
    // The set of available CPUs is checked by querying the operating system
    // at process startup. Changes to operating system CPU allocation after
    // process startup are not reflected.
    int NumCPU()
    {
        return int(ncpu);
    }

    // NumCgoCall returns the number of cgo calls made by the current process.
    int64_t NumCgoCall()
    {
        auto n = int64_t(atomic::Load64(& ncgocall));
        for(auto mp = (m*)(atomic::Loadp(unsafe::Pointer(& allm))); mp != nullptr; mp = mp->alllink)
        {
            n += int64_t(mp->ncgocall);
        }
        return n;
    }

    int64_t totalMutexWaitTimeNanos()
    {
        auto total = rec::Load(gocpp::recv(sched.totalMutexWaitTime));
        total += rec::Load(gocpp::recv(sched.totalRuntimeLockWaitTime));
        for(auto mp = (m*)(atomic::Loadp(unsafe::Pointer(& allm))); mp != nullptr; mp = mp->alllink)
        {
            total += rec::Load(gocpp::recv(mp->mLockProfile.waitTime));
        }
        return total;
    }

    // NumGoroutine returns the number of goroutines that currently exist.
    int NumGoroutine()
    {
        return int(gcount());
    }

    //go:linkname debug_modinfo runtime/debug.modinfo
    std::string debug_modinfo()
    {
        return modinfo;
    }

    // mayMoreStackPreempt is a maymorestack hook that forces a preemption
    // at every possible cooperative preemption point.
    //
    // This is valuable to apply to the runtime, which can be sensitive to
    // preemption points. To apply this to all preemption points in the
    // runtime and runtime-like code, use the following in bash or zsh:
    //
    //	X=(-{gc,asm}flags={runtime/...,reflect,sync}=-d=maymorestack=runtime.mayMoreStackPreempt) GOFLAGS=${X[@]}
    //
    // This must be deeply nosplit because it is called from a function
    // prologue before the stack is set up and because the compiler will
    // call it from any splittable prologue (leading to infinite
    // recursion).
    //
    // Ideally it should also use very little stack because the linker
    // doesn't currently account for this in nosplit stack depth checking.
    //
    // Ensure mayMoreStackPreempt can be called for all ABIs.
    //
    //go:nosplit
    //go:linkname mayMoreStackPreempt
    void mayMoreStackPreempt()
    {
        auto gp = getg();
        if(gp == gp->m->g0 || gp == gp->m->gsignal)
        {
            return;
        }
        if(gp->stackguard0 < stackPoisonMin)
        {
            gp->stackguard0 = stackPreempt;
        }
    }

    // mayMoreStackMove is a maymorestack hook that forces stack movement
    // at every possible point.
    //
    // See mayMoreStackPreempt.
    //
    //go:nosplit
    //go:linkname mayMoreStackMove
    void mayMoreStackMove()
    {
        auto gp = getg();
        if(gp == gp->m->g0 || gp == gp->m->gsignal)
        {
            return;
        }
        if(gp->stackguard0 < stackPoisonMin)
        {
            gp->stackguard0 = stackForceMove;
        }
    }

}

