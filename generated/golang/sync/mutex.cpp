// generated by GoCpp from file '$(ImportDir)/sync/mutex.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/sync/mutex.h"
#include "gocpp/support.h"

#include "golang/internal/race/norace.h"
#include "golang/sync/atomic/doc.h"
#include "golang/sync/runtime.h"
#include "golang/unsafe/unsafe.h"

namespace golang::sync
{
    namespace rec
    {
        using namespace mocklib::rec;
    }

    void go_throw(std::string)
    /* convertBlockStmt, nil block */;

    void fatal(std::string)
    /* convertBlockStmt, nil block */;

    
    template<typename T> requires gocpp::GoStruct<T>
    Mutex::operator T()
    {
        T result;
        result.state = this->state;
        result.sema = this->sema;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool Mutex::operator==(const T& ref) const
    {
        if (state != ref.state) return false;
        if (sema != ref.sema) return false;
        return true;
    }

    std::ostream& Mutex::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << state;
        os << " " << sema;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct Mutex& value)
    {
        return value.PrintTo(os);
    }

    
    template<typename T>
    Locker::Locker(T& ref)
    {
        value.reset(new LockerImpl<T, std::unique_ptr<T>>(new T(ref)));
    }

    template<typename T>
    Locker::Locker(const T& ref)
    {
        value.reset(new LockerImpl<T, std::unique_ptr<T>>(new T(ref)));
    }

    template<typename T>
    Locker::Locker(T* ptr)
    {
        value.reset(new LockerImpl<T, gocpp::ptr<T>>(ptr));
    }

    std::ostream& Locker::PrintTo(std::ostream& os) const
    {
        return os;
    }

    template<typename T, typename StoreT>
    void Locker::LockerImpl<T, StoreT>::vLock()
    {
        return rec::Lock(gocpp::PtrRecv<T, false>(value.get()));
    }
    template<typename T, typename StoreT>
    void Locker::LockerImpl<T, StoreT>::vUnlock()
    {
        return rec::Unlock(gocpp::PtrRecv<T, false>(value.get()));
    }

    namespace rec
    {
        void Lock(const gocpp::PtrRecv<struct Locker, false>& self)
        {
            return self.ptr->value->vLock();
        }

        void Lock(const gocpp::ObjRecv<struct Locker>& self)
        {
            return self.obj.value->vLock();
        }

        void Unlock(const gocpp::PtrRecv<struct Locker, false>& self)
        {
            return self.ptr->value->vUnlock();
        }

        void Unlock(const gocpp::ObjRecv<struct Locker>& self)
        {
            return self.obj.value->vUnlock();
        }
    }

    std::ostream& operator<<(std::ostream& os, const struct Locker& value)
    {
        return value.PrintTo(os);
    }

    void rec::Lock(struct Mutex* m)
    {
        if(atomic::CompareAndSwapInt32(& m->state, 0, mutexLocked))
        {
            if(race::Enabled)
            {
                race::Acquire(unsafe::Pointer(m));
            }
            return;
        }
        rec::lockSlow(gocpp::recv(m));
    }

    bool rec::TryLock(struct Mutex* m)
    {
        auto old = m->state;
        if(old & (mutexLocked | mutexStarving) != 0)
        {
            return false;
        }
        if(! atomic::CompareAndSwapInt32(& m->state, old, old | mutexLocked))
        {
            return false;
        }
        if(race::Enabled)
        {
            race::Acquire(unsafe::Pointer(m));
        }
        return true;
    }

    void rec::lockSlow(struct Mutex* m)
    {
        int64_t waitStartTime = {};
        auto starving = false;
        auto awoke = false;
        auto iter = 0;
        auto old = m->state;
        for(; ; )
        {
            if(old & (mutexLocked | mutexStarving) == mutexLocked && runtime_canSpin(iter))
            {
                if(! awoke && old & mutexWoken == 0 && (old >> mutexWaiterShift) != 0 && atomic::CompareAndSwapInt32(& m->state, old, old | mutexWoken))
                {
                    awoke = true;
                }
                runtime_doSpin();
                iter++;
                old = m->state;
                continue;
            }
            auto go_new = old;
            if(old & mutexStarving == 0)
            {
                go_new |= mutexLocked;
            }
            if(old & (mutexLocked | mutexStarving) != 0)
            {
                go_new += 1 << mutexWaiterShift;
            }
            if(starving && old & mutexLocked != 0)
            {
                go_new |= mutexStarving;
            }
            if(awoke)
            {
                if(go_new & mutexWoken == 0)
                {
                    go_throw("sync: inconsistent mutex state");
                }
                go_new &^= mutexWoken;
            }
            if(atomic::CompareAndSwapInt32(& m->state, old, go_new))
            {
                if(old & (mutexLocked | mutexStarving) == 0)
                {
                    break;
                }
                auto queueLifo = waitStartTime != 0;
                if(waitStartTime == 0)
                {
                    waitStartTime = runtime_nanotime();
                }
                runtime_SemacquireMutex(& m->sema, queueLifo, 1);
                starving = starving || runtime_nanotime() - waitStartTime > starvationThresholdNs;
                old = m->state;
                if(old & mutexStarving != 0)
                {
                    if(old & (mutexLocked | mutexWoken) != 0 || (old >> mutexWaiterShift) == 0)
                    {
                        go_throw("sync: inconsistent mutex state");
                    }
                    auto delta = int32_t(mutexLocked - (1 << mutexWaiterShift));
                    if(! starving || (old >> mutexWaiterShift) == 1)
                    {
                        delta -= mutexStarving;
                    }
                    atomic::AddInt32(& m->state, delta);
                    break;
                }
                awoke = true;
                iter = 0;
            }
            else
            {
                old = m->state;
            }
        }
        if(race::Enabled)
        {
            race::Acquire(unsafe::Pointer(m));
        }
    }

    void rec::Unlock(struct Mutex* m)
    {
        if(race::Enabled)
        {
            _ = m->state;
            race::Release(unsafe::Pointer(m));
        }
        auto go_new = atomic::AddInt32(& m->state, - mutexLocked);
        if(go_new != 0)
        {
            rec::unlockSlow(gocpp::recv(m), go_new);
        }
    }

    void rec::unlockSlow(struct Mutex* m, int32_t go_new)
    {
        if((go_new + mutexLocked) & mutexLocked == 0)
        {
            fatal("sync: unlock of unlocked mutex");
        }
        if(go_new & mutexStarving == 0)
        {
            auto old = go_new;
            for(; ; )
            {
                if((old >> mutexWaiterShift) == 0 || old & (mutexLocked | mutexWoken | mutexStarving) != 0)
                {
                    return;
                }
                go_new = (old - (1 << mutexWaiterShift)) | mutexWoken;
                if(atomic::CompareAndSwapInt32(& m->state, old, go_new))
                {
                    runtime_Semrelease(& m->sema, false, 1);
                    return;
                }
                old = m->state;
            }
        }
        else
        {
            runtime_Semrelease(& m->sema, true, 1);
        }
    }

}

