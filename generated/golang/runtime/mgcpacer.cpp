// generated by GoCpp from file '$(ImportDir)/runtime/mgcpacer.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/mgcpacer.h"
#include "gocpp/support.h"

#include "golang/internal/abi/type.h"
#include "golang/internal/chacha8rand/chacha8.h"
#include "golang/internal/cpu/cpu.h"
#include "golang/internal/goexperiment/exp_heapminimum512kib_off.h"
#include "golang/runtime/cgocall.h"
#include "golang/runtime/chan.h"
#include "golang/runtime/coro.h"
#include "golang/runtime/debuglog_off.h"
#include "golang/runtime/env_posix.h"
#include "golang/runtime/internal/atomic/types.h"
#include "golang/runtime/internal/sys/nih.h"
#include "golang/runtime/lfstack.h"
#include "golang/runtime/lock_sema.h"
#include "golang/runtime/lockrank.h"
#include "golang/runtime/lockrank_off.h"
#include "golang/runtime/malloc.h"
#include "golang/runtime/mbitmap_allocheaders.h"
#include "golang/runtime/mcache.h"
#include "golang/runtime/mcentral.h"
#include "golang/runtime/mcheckmark.h"
#include "golang/runtime/mfixalloc.h"
#include "golang/runtime/mgc.h"
#include "golang/runtime/mgclimit.h"
#include "golang/runtime/mgcscavenge.h"
#include "golang/runtime/mgcsweep.h"
#include "golang/runtime/mgcwork.h"
#include "golang/runtime/mheap.h"
#include "golang/runtime/mpagealloc.h"
#include "golang/runtime/mpagecache.h"
#include "golang/runtime/mpallocbits.h"
#include "golang/runtime/mprof.h"
#include "golang/runtime/mranges.h"
#include "golang/runtime/mspanset.h"
#include "golang/runtime/mstats.h"
#include "golang/runtime/mwbbuf.h"
#include "golang/runtime/os_windows.h"
#include "golang/runtime/pagetrace_off.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/pinner.h"
#include "golang/runtime/print.h"
#include "golang/runtime/proc.h"
#include "golang/runtime/rand.h"
#include "golang/runtime/runtime1.h"
#include "golang/runtime/runtime2.h"
#include "golang/runtime/signal_windows.h"
#include "golang/runtime/string.h"
#include "golang/runtime/stubs.h"
#include "golang/runtime/symtab.h"
#include "golang/runtime/time.h"
#include "golang/runtime/time_nofake.h"
#include "golang/runtime/trace2buf.h"
#include "golang/runtime/trace2runtime.h"
#include "golang/runtime/trace2status.h"
#include "golang/runtime/trace2time.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
        using atomic::rec::Add;
        using atomic::rec::CompareAndSwap;
        using atomic::rec::Load;
        using atomic::rec::Store;
    }

    // gcGoalUtilization is the goal CPU utilization for
    // marking as a fraction of GOMAXPROCS.
    //
    // Increasing the goal utilization will shorten GC cycles as the GC
    // has more resources behind it, lessening costs from the write barrier,
    // but comes at the cost of increasing mutator latency.
    // gcBackgroundUtilization is the fixed CPU utilization for background
    // marking. It must be <= gcGoalUtilization. The difference between
    // gcGoalUtilization and gcBackgroundUtilization will be made up by
    // mark assists. The scheduler will aim to use within 50% of this
    // goal.
    //
    // As a general rule, there's little reason to set gcBackgroundUtilization
    // < gcGoalUtilization. One reason might be in mostly idle applications,
    // where goroutines are unlikely to assist at all, so the actual
    // utilization will be lower than the goal. But this is moot point
    // because the idle mark workers already soak up idle CPU resources.
    // These two values are still kept separate however because they are
    // distinct conceptually, and in previous iterations of the pacer the
    // distinction was more important.
    // gcCreditSlack is the amount of scan work credit that can
    // accumulate locally before updating gcController.heapScanWork and,
    // optionally, gcController.bgScanCredit. Lower values give a more
    // accurate assist ratio and make it more likely that assists will
    // successfully steal background credit. Higher values reduce memory
    // contention.
    // gcAssistTimeSlack is the nanoseconds of mutator assist time that
    // can accumulate on a P before updating gcController.assistTime.
    // gcOverAssistWork determines how many extra units of scan work a GC
    // assist does when an assist happens. This amortizes the cost of an
    // assist by pre-paying for this many bytes of future allocations.
    // defaultHeapMinimum is the value of heapMinimum for GOGC==100.
    // maxStackScanSlack is the bytes of stack space allocated or freed
    // that can accumulate on a P before updating gcController.stackSize.
    // memoryLimitMinHeapGoalHeadroom is the minimum amount of headroom the
    // pacer gives to the heap goal when operating in the memory-limited regime.
    // That is, it'll reduce the heap goal by this many extra bytes off of the
    // base calculation, at minimum.
    // memoryLimitHeapGoalHeadroomPercent is how headroom the memory-limit-based
    // heap goal should have as a percent of the maximum possible heap goal allowed
    // to maintain the memory limit.
    // gcController implements the GC pacing controller that determines
    // when to trigger concurrent garbage collection and how much marking
    // work to do in mutator assists and background marking.
    //
    // It calculates the ratio between the allocation rate (in terms of CPU
    // time) and the GC scan throughput to determine the heap size at which to
    // trigger a GC cycle such that no GC assists are required to finish on time.
    // This algorithm thus optimizes GC CPU utilization to the dedicated background
    // mark utilization of 25% of GOMAXPROCS by minimizing GC assists.
    // GOMAXPROCS. The high-level design of this algorithm is documented
    // at https://github.com/golang/proposal/blob/master/design/44167-gc-pacer-redesign.md.
    // See https://golang.org/s/go15gcpacing for additional historical context.
    gcControllerState gcController;
    
    template<typename T> requires gocpp::GoStruct<T>
    gcControllerState::operator T()
    {
        T result;
        result.gcPercent = this->gcPercent;
        result.memoryLimit = this->memoryLimit;
        result.heapMinimum = this->heapMinimum;
        result.runway = this->runway;
        result.consMark = this->consMark;
        result.lastConsMark = this->lastConsMark;
        result.gcPercentHeapGoal = this->gcPercentHeapGoal;
        result.sweepDistMinTrigger = this->sweepDistMinTrigger;
        result.triggered = this->triggered;
        result.lastHeapGoal = this->lastHeapGoal;
        result.heapLive = this->heapLive;
        result.heapScan = this->heapScan;
        result.lastHeapScan = this->lastHeapScan;
        result.lastStackScan = this->lastStackScan;
        result.maxStackScan = this->maxStackScan;
        result.globalsScan = this->globalsScan;
        result.heapMarked = this->heapMarked;
        result.heapScanWork = this->heapScanWork;
        result.stackScanWork = this->stackScanWork;
        result.globalsScanWork = this->globalsScanWork;
        result.bgScanCredit = this->bgScanCredit;
        result.assistTime = this->assistTime;
        result.dedicatedMarkTime = this->dedicatedMarkTime;
        result.fractionalMarkTime = this->fractionalMarkTime;
        result.idleMarkTime = this->idleMarkTime;
        result.markStartTime = this->markStartTime;
        result.dedicatedMarkWorkersNeeded = this->dedicatedMarkWorkersNeeded;
        result.idleMarkWorkers = this->idleMarkWorkers;
        result.assistWorkPerByte = this->assistWorkPerByte;
        result.assistBytesPerWork = this->assistBytesPerWork;
        result.fractionalUtilizationGoal = this->fractionalUtilizationGoal;
        result.heapInUse = this->heapInUse;
        result.heapReleased = this->heapReleased;
        result.heapFree = this->heapFree;
        result.totalAlloc = this->totalAlloc;
        result.totalFree = this->totalFree;
        result.mappedReady = this->mappedReady;
        result.test = this->test;
        result._1 = this->_1;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gcControllerState::operator==(const T& ref) const
    {
        if (gcPercent != ref.gcPercent) return false;
        if (memoryLimit != ref.memoryLimit) return false;
        if (heapMinimum != ref.heapMinimum) return false;
        if (runway != ref.runway) return false;
        if (consMark != ref.consMark) return false;
        if (lastConsMark != ref.lastConsMark) return false;
        if (gcPercentHeapGoal != ref.gcPercentHeapGoal) return false;
        if (sweepDistMinTrigger != ref.sweepDistMinTrigger) return false;
        if (triggered != ref.triggered) return false;
        if (lastHeapGoal != ref.lastHeapGoal) return false;
        if (heapLive != ref.heapLive) return false;
        if (heapScan != ref.heapScan) return false;
        if (lastHeapScan != ref.lastHeapScan) return false;
        if (lastStackScan != ref.lastStackScan) return false;
        if (maxStackScan != ref.maxStackScan) return false;
        if (globalsScan != ref.globalsScan) return false;
        if (heapMarked != ref.heapMarked) return false;
        if (heapScanWork != ref.heapScanWork) return false;
        if (stackScanWork != ref.stackScanWork) return false;
        if (globalsScanWork != ref.globalsScanWork) return false;
        if (bgScanCredit != ref.bgScanCredit) return false;
        if (assistTime != ref.assistTime) return false;
        if (dedicatedMarkTime != ref.dedicatedMarkTime) return false;
        if (fractionalMarkTime != ref.fractionalMarkTime) return false;
        if (idleMarkTime != ref.idleMarkTime) return false;
        if (markStartTime != ref.markStartTime) return false;
        if (dedicatedMarkWorkersNeeded != ref.dedicatedMarkWorkersNeeded) return false;
        if (idleMarkWorkers != ref.idleMarkWorkers) return false;
        if (assistWorkPerByte != ref.assistWorkPerByte) return false;
        if (assistBytesPerWork != ref.assistBytesPerWork) return false;
        if (fractionalUtilizationGoal != ref.fractionalUtilizationGoal) return false;
        if (heapInUse != ref.heapInUse) return false;
        if (heapReleased != ref.heapReleased) return false;
        if (heapFree != ref.heapFree) return false;
        if (totalAlloc != ref.totalAlloc) return false;
        if (totalFree != ref.totalFree) return false;
        if (mappedReady != ref.mappedReady) return false;
        if (test != ref.test) return false;
        if (_1 != ref._1) return false;
        return true;
    }

    std::ostream& gcControllerState::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << gcPercent;
        os << " " << memoryLimit;
        os << " " << heapMinimum;
        os << " " << runway;
        os << " " << consMark;
        os << " " << lastConsMark;
        os << " " << gcPercentHeapGoal;
        os << " " << sweepDistMinTrigger;
        os << " " << triggered;
        os << " " << lastHeapGoal;
        os << " " << heapLive;
        os << " " << heapScan;
        os << " " << lastHeapScan;
        os << " " << lastStackScan;
        os << " " << maxStackScan;
        os << " " << globalsScan;
        os << " " << heapMarked;
        os << " " << heapScanWork;
        os << " " << stackScanWork;
        os << " " << globalsScanWork;
        os << " " << bgScanCredit;
        os << " " << assistTime;
        os << " " << dedicatedMarkTime;
        os << " " << fractionalMarkTime;
        os << " " << idleMarkTime;
        os << " " << markStartTime;
        os << " " << dedicatedMarkWorkersNeeded;
        os << " " << idleMarkWorkers;
        os << " " << assistWorkPerByte;
        os << " " << assistBytesPerWork;
        os << " " << fractionalUtilizationGoal;
        os << " " << heapInUse;
        os << " " << heapReleased;
        os << " " << heapFree;
        os << " " << totalAlloc;
        os << " " << totalFree;
        os << " " << mappedReady;
        os << " " << test;
        os << " " << _1;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gcControllerState& value)
    {
        return value.PrintTo(os);
    }

    void rec::init(struct gcControllerState* c, int32_t gcPercent, int64_t memoryLimit)
    {
        c->heapMinimum = defaultHeapMinimum;
        c->triggered = ~ uint64_t(0);
        rec::setGCPercent(gocpp::recv(c), gcPercent);
        rec::setMemoryLimit(gocpp::recv(c), memoryLimit);
        rec::commit(gocpp::recv(c), true);
    }

    // startCycle resets the GC controller's state and computes estimates
    // for a new GC cycle. The caller must hold worldsema and the world
    // must be stopped.
    void rec::startCycle(struct gcControllerState* c, int64_t markStartTime, int procs, struct gcTrigger trigger)
    {
        rec::Store(gocpp::recv(c->heapScanWork), 0);
        rec::Store(gocpp::recv(c->stackScanWork), 0);
        rec::Store(gocpp::recv(c->globalsScanWork), 0);
        rec::Store(gocpp::recv(c->bgScanCredit), 0);
        rec::Store(gocpp::recv(c->assistTime), 0);
        rec::Store(gocpp::recv(c->dedicatedMarkTime), 0);
        rec::Store(gocpp::recv(c->fractionalMarkTime), 0);
        rec::Store(gocpp::recv(c->idleMarkTime), 0);
        c->markStartTime = markStartTime;
        c->triggered = rec::Load(gocpp::recv(c->heapLive));
        auto totalUtilizationGoal = double(procs) * gcBackgroundUtilization;
        auto dedicatedMarkWorkersNeeded = int64_t(totalUtilizationGoal + 0.5);
        auto utilError = double(dedicatedMarkWorkersNeeded) / totalUtilizationGoal - 1;
        auto maxUtilError = 0.3;
        if(utilError < - maxUtilError || utilError > maxUtilError)
        {
            if(double(dedicatedMarkWorkersNeeded) > totalUtilizationGoal)
            {
                dedicatedMarkWorkersNeeded--;
            }
            c->fractionalUtilizationGoal = (totalUtilizationGoal - double(dedicatedMarkWorkersNeeded)) / double(procs);
        }
        else
        {
            c->fractionalUtilizationGoal = 0;
        }
        if(debug.gcstoptheworld > 0)
        {
            dedicatedMarkWorkersNeeded = int64_t(procs);
            c->fractionalUtilizationGoal = 0;
        }
        for(auto [gocpp_ignored, p] : allp)
        {
            p->gcAssistTime = 0;
            p->gcFractionalMarkTime = 0;
        }
        if(trigger.kind == gcTriggerTime)
        {
            if(dedicatedMarkWorkersNeeded > 0)
            {
                rec::setMaxIdleMarkWorkers(gocpp::recv(c), 0);
            }
            else
            {
                rec::setMaxIdleMarkWorkers(gocpp::recv(c), 1);
            }
        }
        else
        {
            rec::setMaxIdleMarkWorkers(gocpp::recv(c), int32_t(procs) - int32_t(dedicatedMarkWorkersNeeded));
        }
        rec::Store(gocpp::recv(c->dedicatedMarkWorkersNeeded), dedicatedMarkWorkersNeeded);
        rec::revise(gocpp::recv(c));
        if(debug.gcpacertrace > 0)
        {
            auto heapGoal = rec::heapGoal(gocpp::recv(c));
            auto assistRatio = rec::Load(gocpp::recv(c->assistWorkPerByte));
            print("pacer: assist ratio="_s, assistRatio, " (scan "_s, rec::Load(gocpp::recv(gcController.heapScan)) >> 20, " MB in "_s, work.initialHeapLive >> 20, "->"_s, heapGoal >> 20, " MB)"_s, " workers="_s, dedicatedMarkWorkersNeeded, "+"_s, c->fractionalUtilizationGoal, "\n"_s);
        }
    }

    // revise updates the assist ratio during the GC cycle to account for
    // improved estimates. This should be called whenever gcController.heapScan,
    // gcController.heapLive, or if any inputs to gcController.heapGoal are
    // updated. It is safe to call concurrently, but it may race with other
    // calls to revise.
    //
    // The result of this race is that the two assist ratio values may not line
    // up or may be stale. In practice this is OK because the assist ratio
    // moves slowly throughout a GC cycle, and the assist ratio is a best-effort
    // heuristic anyway. Furthermore, no part of the heuristic depends on
    // the two assist ratio values being exact reciprocals of one another, since
    // the two values are used to convert values from different sources.
    //
    // The worst case result of this raciness is that we may miss a larger shift
    // in the ratio (say, if we decide to pace more aggressively against the
    // hard heap goal) but even this "hard goal" is best-effort (see #40460).
    // The dedicated GC should ensure we don't exceed the hard goal by too much
    // in the rare case we do exceed it.
    //
    // It should only be called when gcBlackenEnabled != 0 (because this
    // is when assists are enabled and the necessary statistics are
    // available).
    void rec::revise(struct gcControllerState* c)
    {
        auto gcPercent = rec::Load(gocpp::recv(c->gcPercent));
        if(gcPercent < 0)
        {
            gcPercent = 100000;
        }
        auto live = rec::Load(gocpp::recv(c->heapLive));
        auto scan = rec::Load(gocpp::recv(c->heapScan));
        auto work = rec::Load(gocpp::recv(c->heapScanWork)) + rec::Load(gocpp::recv(c->stackScanWork)) + rec::Load(gocpp::recv(c->globalsScanWork));
        auto heapGoal = int64_t(rec::heapGoal(gocpp::recv(c)));
        auto scanWorkExpected = int64_t(c->lastHeapScan + rec::Load(gocpp::recv(c->lastStackScan)) + rec::Load(gocpp::recv(c->globalsScan)));
        auto maxStackScan = rec::Load(gocpp::recv(c->maxStackScan));
        auto maxScanWork = int64_t(scan + maxStackScan + rec::Load(gocpp::recv(c->globalsScan)));
        if(work > scanWorkExpected)
        {
            auto extHeapGoal = int64_t(double(heapGoal - int64_t(c->triggered)) / double(scanWorkExpected) * double(maxScanWork)) + int64_t(c->triggered);
            scanWorkExpected = maxScanWork;
            auto hardGoal = int64_t((1.0 + double(gcPercent) / 100.0) * double(heapGoal));
            if(extHeapGoal > hardGoal)
            {
                extHeapGoal = hardGoal;
            }
            heapGoal = extHeapGoal;
        }
        if(int64_t(live) > heapGoal)
        {
            // We're already past our heap goal, even the extrapolated one.
            // Leave ourselves some extra runway, so in the worst case we
            // finish by that point.
            auto maxOvershoot = 1.1;
            heapGoal = int64_t(double(heapGoal) * maxOvershoot);
            scanWorkExpected = maxScanWork;
        }
        auto scanWorkRemaining = scanWorkExpected - work;
        if(scanWorkRemaining < 1000)
        {
            scanWorkRemaining = 1000;
        }
        auto heapRemaining = heapGoal - int64_t(live);
        if(heapRemaining <= 0)
        {
            heapRemaining = 1;
        }
        auto assistWorkPerByte = double(scanWorkRemaining) / double(heapRemaining);
        auto assistBytesPerWork = double(heapRemaining) / double(scanWorkRemaining);
        rec::Store(gocpp::recv(c->assistWorkPerByte), assistWorkPerByte);
        rec::Store(gocpp::recv(c->assistBytesPerWork), assistBytesPerWork);
    }

    // endCycle computes the consMark estimate for the next cycle.
    // userForced indicates whether the current GC cycle was forced
    // by the application.
    void rec::endCycle(struct gcControllerState* c, int64_t now, int procs, bool userForced)
    {
        gcController.lastHeapGoal = rec::heapGoal(gocpp::recv(c));
        auto assistDuration = now - c->markStartTime;
        auto utilization = gcBackgroundUtilization;
        if(assistDuration > 0)
        {
            utilization += double(rec::Load(gocpp::recv(c->assistTime))) / double(assistDuration * int64_t(procs));
        }
        if(rec::Load(gocpp::recv(c->heapLive)) <= c->triggered)
        {
            return;
        }
        auto idleUtilization = 0.0;
        if(assistDuration > 0)
        {
            idleUtilization = double(rec::Load(gocpp::recv(c->idleMarkTime))) / double(assistDuration * int64_t(procs));
        }
        auto scanWork = rec::Load(gocpp::recv(c->heapScanWork)) + rec::Load(gocpp::recv(c->stackScanWork)) + rec::Load(gocpp::recv(c->globalsScanWork));
        auto currentConsMark = (double(rec::Load(gocpp::recv(c->heapLive)) - c->triggered) * (utilization + idleUtilization)) / (double(scanWork) * (1 - utilization));
        auto oldConsMark = c->consMark;
        c->consMark = currentConsMark;
        for(auto [i, gocpp_ignored] : c->lastConsMark)
        {
            if(c->lastConsMark[i] > c->consMark)
            {
                c->consMark = c->lastConsMark[i];
            }
        }
        copy(c->lastConsMark.make_slice(0), c->lastConsMark.make_slice(1));
        c->lastConsMark[len(c->lastConsMark) - 1] = currentConsMark;
        if(debug.gcpacertrace > 0)
        {
            printlock();
            auto goal = gcGoalUtilization * 100;
            print("pacer: "_s, int(utilization * 100), "% CPU ("_s, int(goal), " exp.) for "_s);
            print(rec::Load(gocpp::recv(c->heapScanWork)), "+"_s, rec::Load(gocpp::recv(c->stackScanWork)), "+"_s, rec::Load(gocpp::recv(c->globalsScanWork)), " B work ("_s, c->lastHeapScan + rec::Load(gocpp::recv(c->lastStackScan)) + rec::Load(gocpp::recv(c->globalsScan)), " B exp.) "_s);
            auto live = rec::Load(gocpp::recv(c->heapLive));
            print("in "_s, c->triggered, " B -> "_s, live, " B (âˆ†goal "_s, int64_t(live) - int64_t(c->lastHeapGoal), ", cons/mark "_s, oldConsMark, ")"_s);
            println();
            printunlock();
        }
    }

    // enlistWorker encourages another dedicated mark worker to start on
    // another P if there are spare worker slots. It is used by putfull
    // when more work is made available.
    //
    //go:nowritebarrier
    void rec::enlistWorker(struct gcControllerState* c)
    {
        if(rec::Load(gocpp::recv(c->dedicatedMarkWorkersNeeded)) <= 0)
        {
            return;
        }
        if(gomaxprocs <= 1)
        {
            return;
        }
        auto gp = getg();
        if(gp == nullptr || gp->m == nullptr || gp->m->p == 0)
        {
            return;
        }
        auto myID = rec::ptr(gocpp::recv(gp->m->p))->id;
        for(auto tries = 0; tries < 5; tries++)
        {
            auto id = int32_t(cheaprandn(uint32_t(gomaxprocs - 1)));
            if(id >= myID)
            {
                id++;
            }
            auto p = allp[id];
            if(p->status != _Prunning)
            {
                continue;
            }
            if(preemptone(p))
            {
                return;
            }
        }
    }

    // findRunnableGCWorker returns a background mark worker for pp if it
    // should be run. This must only be called when gcBlackenEnabled != 0.
    std::tuple<struct g*, int64_t> rec::findRunnableGCWorker(struct gcControllerState* c, struct p* pp, int64_t now)
    {
        if(gcBlackenEnabled == 0)
        {
            go_throw("gcControllerState.findRunnable: blackening not enabled"_s);
        }
        if(now == 0)
        {
            now = nanotime();
        }
        if(rec::needUpdate(gocpp::recv(gcCPULimiter), now))
        {
            rec::update(gocpp::recv(gcCPULimiter), now);
        }
        if(! gcMarkWorkAvailable(pp))
        {
            return {nullptr, now};
        }
        auto node = (gcBgMarkWorkerNode*)(rec::pop(gocpp::recv(gcBgMarkWorkerPool)));
        if(node == nullptr)
        {
            return {nullptr, now};
        }
        auto decIfPositive = [=](atomic::Int64* val) mutable -> bool
        {
            for(; ; )
            {
                auto v = rec::Load(gocpp::recv(val));
                if(v <= 0)
                {
                    return false;
                }
                if(rec::CompareAndSwap(gocpp::recv(val), v, v - 1))
                {
                    return true;
                }
            }
        };
        if(decIfPositive(& c->dedicatedMarkWorkersNeeded))
        {
            pp->gcMarkWorkerMode = gcMarkWorkerDedicatedMode;
        }
        else
        if(c->fractionalUtilizationGoal == 0)
        {
            rec::push(gocpp::recv(gcBgMarkWorkerPool), & node->node);
            return {nullptr, now};
        }
        else
        {
            auto delta = now - c->markStartTime;
            if(delta > 0 && double(pp->gcFractionalMarkTime) / double(delta) > c->fractionalUtilizationGoal)
            {
                rec::push(gocpp::recv(gcBgMarkWorkerPool), & node->node);
                return {nullptr, now};
            }
            pp->gcMarkWorkerMode = gcMarkWorkerFractionalMode;
        }
        auto gp = rec::ptr(gocpp::recv(node->gp));
        auto trace = traceAcquire();
        casgstatus(gp, _Gwaiting, _Grunnable);
        if(rec::ok(gocpp::recv(trace)))
        {
            rec::GoUnpark(gocpp::recv(trace), gp, 0);
            traceRelease(trace);
        }
        return {gp, now};
    }

    // resetLive sets up the controller state for the next mark phase after the end
    // of the previous one. Must be called after endCycle and before commit, before
    // the world is started.
    //
    // The world must be stopped.
    void rec::resetLive(struct gcControllerState* c, uint64_t bytesMarked)
    {
        c->heapMarked = bytesMarked;
        rec::Store(gocpp::recv(c->heapLive), bytesMarked);
        rec::Store(gocpp::recv(c->heapScan), uint64_t(rec::Load(gocpp::recv(c->heapScanWork))));
        c->lastHeapScan = uint64_t(rec::Load(gocpp::recv(c->heapScanWork)));
        rec::Store(gocpp::recv(c->lastStackScan), uint64_t(rec::Load(gocpp::recv(c->stackScanWork))));
        c->triggered = ~ uint64_t(0);
        auto trace = traceAcquire();
        if(rec::ok(gocpp::recv(trace)))
        {
            rec::HeapAlloc(gocpp::recv(trace), bytesMarked);
            traceRelease(trace);
        }
    }

    // markWorkerStop must be called whenever a mark worker stops executing.
    //
    // It updates mark work accounting in the controller by a duration of
    // work in nanoseconds and other bookkeeping.
    //
    // Safe to execute at any time.
    void rec::markWorkerStop(struct gcControllerState* c, golang::runtime::gcMarkWorkerMode mode, int64_t duration)
    {
        //Go switch emulation
        {
            auto condition = mode;
            int conditionId = -1;
            if(condition == gcMarkWorkerDedicatedMode) { conditionId = 0; }
            else if(condition == gcMarkWorkerFractionalMode) { conditionId = 1; }
            else if(condition == gcMarkWorkerIdleMode) { conditionId = 2; }
            switch(conditionId)
            {
                case 0:
                    rec::Add(gocpp::recv(c->dedicatedMarkTime), duration);
                    rec::Add(gocpp::recv(c->dedicatedMarkWorkersNeeded), 1);
                    break;
                case 1:
                    rec::Add(gocpp::recv(c->fractionalMarkTime), duration);
                    break;
                case 2:
                    rec::Add(gocpp::recv(c->idleMarkTime), duration);
                    rec::removeIdleMarkWorker(gocpp::recv(c));
                    break;
                default:
                    go_throw("markWorkerStop: unknown mark worker mode"_s);
                    break;
            }
        }
    }

    void rec::update(struct gcControllerState* c, int64_t dHeapLive, int64_t dHeapScan)
    {
        if(dHeapLive != 0)
        {
            auto trace = traceAcquire();
            auto live = rec::Add(gocpp::recv(gcController.heapLive), dHeapLive);
            if(rec::ok(gocpp::recv(trace)))
            {
                rec::HeapAlloc(gocpp::recv(trace), live);
                traceRelease(trace);
            }
        }
        if(gcBlackenEnabled == 0)
        {
            if(dHeapScan != 0)
            {
                rec::Add(gocpp::recv(gcController.heapScan), dHeapScan);
            }
        }
        else
        {
            rec::revise(gocpp::recv(c));
        }
    }

    void rec::addScannableStack(struct gcControllerState* c, struct p* pp, int64_t amount)
    {
        if(pp == nullptr)
        {
            rec::Add(gocpp::recv(c->maxStackScan), amount);
            return;
        }
        pp->maxStackScanDelta += amount;
        if(pp->maxStackScanDelta >= maxStackScanSlack || pp->maxStackScanDelta <= - maxStackScanSlack)
        {
            rec::Add(gocpp::recv(c->maxStackScan), pp->maxStackScanDelta);
            pp->maxStackScanDelta = 0;
        }
    }

    void rec::addGlobals(struct gcControllerState* c, int64_t amount)
    {
        rec::Add(gocpp::recv(c->globalsScan), amount);
    }

    // heapGoal returns the current heap goal.
    uint64_t rec::heapGoal(struct gcControllerState* c)
    {
        auto [goal, gocpp_id_0] = rec::heapGoalInternal(gocpp::recv(c));
        return goal;
    }

    // heapGoalInternal is the implementation of heapGoal which returns additional
    // information that is necessary for computing the trigger.
    //
    // The returned minTrigger is always <= goal.
    std::tuple<uint64_t, uint64_t> rec::heapGoalInternal(struct gcControllerState* c)
    {
        uint64_t goal;
        uint64_t minTrigger;
        goal = rec::Load(gocpp::recv(c->gcPercentHeapGoal));
        if(auto newGoal = rec::memoryLimitHeapGoal(gocpp::recv(c)); newGoal < goal)
        {
            goal = newGoal;
        }
        else
        {
            auto sweepDistTrigger = rec::Load(gocpp::recv(c->sweepDistMinTrigger));
            if(sweepDistTrigger > goal)
            {
                goal = sweepDistTrigger;
            }
            minTrigger = sweepDistTrigger;
            // Ensure that the heap goal is at least a little larger than
            // the point at which we triggered. This may not be the case if GC
            // start is delayed or if the allocation that pushed gcController.heapLive
            // over trigger is large or if the trigger is really close to
            // GOGC. Assist is proportional to this distance, so enforce a
            // minimum distance, even if it means going over the GOGC goal
            // by a tiny bit.
            //
            // Ignore this if we're in the memory limit regime: we'd prefer to
            // have the GC respond hard about how close we are to the goal than to
            // push the goal back in such a manner that it could cause us to exceed
            // the memory limit.
            auto minRunway = 64 << 10;
            if(c->triggered != ~ uint64_t(0) && goal < c->triggered + minRunway)
            {
                goal = c->triggered + minRunway;
            }
        }
        return {goal, minTrigger};
    }

    // memoryLimitHeapGoal returns a heap goal derived from memoryLimit.
    uint64_t rec::memoryLimitHeapGoal(struct gcControllerState* c)
    {
        // Start by pulling out some values we'll need. Be careful about overflow.
        uint64_t heapFree = {};
        uint64_t heapAlloc = {};
        uint64_t mappedReady = {};
        for(; ; )
        {
            heapFree = rec::load(gocpp::recv(c->heapFree));
            heapAlloc = rec::Load(gocpp::recv(c->totalAlloc)) - rec::Load(gocpp::recv(c->totalFree));
            mappedReady = rec::Load(gocpp::recv(c->mappedReady));
            if(heapFree + heapAlloc <= mappedReady)
            {
                break;
            }
        }
        auto memoryLimit = uint64_t(rec::Load(gocpp::recv(c->memoryLimit)));
        auto nonHeapMemory = mappedReady - heapFree - heapAlloc;
        // Compute term 2.
        uint64_t overage = {};
        if(mappedReady > memoryLimit)
        {
            overage = mappedReady - memoryLimit;
        }
        if(nonHeapMemory + overage >= memoryLimit)
        {
            return c->heapMarked;
        }
        auto goal = memoryLimit - (nonHeapMemory + overage);
        auto headroom = goal / 100 * memoryLimitHeapGoalHeadroomPercent;
        if(headroom < memoryLimitMinHeapGoalHeadroom)
        {
            headroom = memoryLimitMinHeapGoalHeadroom;
        }
        if(goal < headroom || goal - headroom < headroom)
        {
            goal = headroom;
        }
        else
        {
            goal = goal - headroom;
        }
        if(goal < c->heapMarked)
        {
            goal = c->heapMarked;
        }
        return goal;
    }

    // These constants determine the bounds on the GC trigger as a fraction
    // of heap bytes allocated between the start of a GC (heapLive == heapMarked)
    // and the end of a GC (heapLive == heapGoal).
    //
    // The constants are obscured in this way for efficiency. The denominator
    // of the fraction is always a power-of-two for a quick division, so that
    // the numerator is a single constant integer multiplication.
    // The minimum trigger constant was chosen empirically: given a sufficiently
    // fast/scalable allocator with 48 Ps that could drive the trigger ratio
    // to <0.05, this constant causes applications to retain the same peak
    // RSS compared to not having this allocator.
    // The maximum trigger constant is chosen somewhat arbitrarily, but the
    // current constant has served us well over the years.
    // trigger returns the current point at which a GC should trigger along with
    // the heap goal.
    //
    // The returned value may be compared against heapLive to determine whether
    // the GC should trigger. Thus, the GC trigger condition should be (but may
    // not be, in the case of small movements for efficiency) checked whenever
    // the heap goal may change.
    std::tuple<uint64_t, uint64_t> rec::trigger(struct gcControllerState* c)
    {
        auto [goal, minTrigger] = rec::heapGoalInternal(gocpp::recv(c));
        if(c->heapMarked >= goal)
        {
            return {goal, goal};
        }
        if(minTrigger < c->heapMarked)
        {
            minTrigger = c->heapMarked;
        }
        auto triggerLowerBound = ((goal - c->heapMarked) / triggerRatioDen) * minTriggerRatioNum + c->heapMarked;
        if(minTrigger < triggerLowerBound)
        {
            minTrigger = triggerLowerBound;
        }
        auto maxTrigger = ((goal - c->heapMarked) / triggerRatioDen) * maxTriggerRatioNum + c->heapMarked;
        if(goal > defaultHeapMinimum && goal - defaultHeapMinimum > maxTrigger)
        {
            maxTrigger = goal - defaultHeapMinimum;
        }
        maxTrigger = gocpp::max(maxTrigger, minTrigger);
        // Compute the trigger from our bounds and the runway stored by commit.
        uint64_t trigger = {};
        auto runway = rec::Load(gocpp::recv(c->runway));
        if(runway > goal)
        {
            trigger = minTrigger;
        }
        else
        {
            trigger = goal - runway;
        }
        trigger = gocpp::max(trigger, minTrigger);
        trigger = gocpp::min(trigger, maxTrigger);
        if(trigger > goal)
        {
            print("trigger="_s, trigger, " heapGoal="_s, goal, "\n"_s);
            print("minTrigger="_s, minTrigger, " maxTrigger="_s, maxTrigger, "\n"_s);
            go_throw("produced a trigger greater than the heap goal"_s);
        }
        return {trigger, goal};
    }

    // commit recomputes all pacing parameters needed to derive the
    // trigger and the heap goal. Namely, the gcPercent-based heap goal,
    // and the amount of runway we want to give the GC this cycle.
    //
    // This can be called any time. If GC is the in the middle of a
    // concurrent phase, it will adjust the pacing of that phase.
    //
    // isSweepDone should be the result of calling isSweepDone(),
    // unless we're testing or we know we're executing during a GC cycle.
    //
    // This depends on gcPercent, gcController.heapMarked, and
    // gcController.heapLive. These must be up to date.
    //
    // Callers must call gcControllerState.revise after calling this
    // function if the GC is enabled.
    //
    // mheap_.lock must be held or the world must be stopped.
    void rec::commit(struct gcControllerState* c, bool isSweepDone)
    {
        if(! c->test)
        {
            assertWorldStoppedOrLockHeld(& mheap_.lock);
        }
        if(isSweepDone)
        {
            rec::Store(gocpp::recv(c->sweepDistMinTrigger), 0);
        }
        else
        {
            rec::Store(gocpp::recv(c->sweepDistMinTrigger), rec::Load(gocpp::recv(c->heapLive)) + sweepMinHeapDistance);
        }
        auto gcPercentHeapGoal = ~ uint64_t(0);
        if(auto gcPercent = rec::Load(gocpp::recv(c->gcPercent)); gcPercent >= 0)
        {
            gcPercentHeapGoal = c->heapMarked + (c->heapMarked + rec::Load(gocpp::recv(c->lastStackScan)) + rec::Load(gocpp::recv(c->globalsScan))) * uint64_t(gcPercent) / 100;
        }
        if(gcPercentHeapGoal < c->heapMinimum)
        {
            gcPercentHeapGoal = c->heapMinimum;
        }
        rec::Store(gocpp::recv(c->gcPercentHeapGoal), gcPercentHeapGoal);
        rec::Store(gocpp::recv(c->runway), uint64_t((c->consMark * (1 - gcGoalUtilization) / (gcGoalUtilization)) * double(c->lastHeapScan + rec::Load(gocpp::recv(c->lastStackScan)) + rec::Load(gocpp::recv(c->globalsScan)))));
    }

    // setGCPercent updates gcPercent. commit must be called after.
    // Returns the old value of gcPercent.
    //
    // The world must be stopped, or mheap_.lock must be held.
    int32_t rec::setGCPercent(struct gcControllerState* c, int32_t in)
    {
        if(! c->test)
        {
            assertWorldStoppedOrLockHeld(& mheap_.lock);
        }
        auto out = rec::Load(gocpp::recv(c->gcPercent));
        if(in < 0)
        {
            in = - 1;
        }
        c->heapMinimum = defaultHeapMinimum * uint64_t(in) / 100;
        rec::Store(gocpp::recv(c->gcPercent), in);
        return out;
    }

    //go:linkname setGCPercent runtime/debug.setGCPercent
    int32_t setGCPercent(int32_t in)
    {
        int32_t out;
        systemstack([=]() mutable -> void
        {
            lock(& mheap_.lock);
            out = rec::setGCPercent(gocpp::recv(gcController), in);
            gcControllerCommit();
            unlock(& mheap_.lock);
        });
        if(in < 0)
        {
            gcWaitOnMark(rec::Load(gocpp::recv(work.cycles)));
        }
        return out;
    }

    int32_t readGOGC()
    {
        auto p = gogetenv("GOGC"_s);
        if(p == "off"_s)
        {
            return - 1;
        }
        if(auto [n, ok] = atoi32(p); ok)
        {
            return n;
        }
        return 100;
    }

    // setMemoryLimit updates memoryLimit. commit must be called after
    // Returns the old value of memoryLimit.
    //
    // The world must be stopped, or mheap_.lock must be held.
    int64_t rec::setMemoryLimit(struct gcControllerState* c, int64_t in)
    {
        if(! c->test)
        {
            assertWorldStoppedOrLockHeld(& mheap_.lock);
        }
        auto out = rec::Load(gocpp::recv(c->memoryLimit));
        if(in >= 0)
        {
            rec::Store(gocpp::recv(c->memoryLimit), in);
        }
        return out;
    }

    //go:linkname setMemoryLimit runtime/debug.setMemoryLimit
    int64_t setMemoryLimit(int64_t in)
    {
        int64_t out;
        systemstack([=]() mutable -> void
        {
            lock(& mheap_.lock);
            out = rec::setMemoryLimit(gocpp::recv(gcController), in);
            if(in < 0 || out == in)
            {
                unlock(& mheap_.lock);
                return;
            }
            gcControllerCommit();
            unlock(& mheap_.lock);
        });
        return out;
    }

    int64_t readGOMEMLIMIT()
    {
        auto p = gogetenv("GOMEMLIMIT"_s);
        if(p == ""_s || p == "off"_s)
        {
            return maxInt64;
        }
        auto [n, ok] = parseByteCount(p);
        if(! ok)
        {
            print("GOMEMLIMIT="_s, p, "\n"_s);
            go_throw("malformed GOMEMLIMIT; see `go doc runtime/debug.SetMemoryLimit`"_s);
        }
        return n;
    }

    // addIdleMarkWorker attempts to add a new idle mark worker.
    //
    // If this returns true, the caller must become an idle mark worker unless
    // there's no background mark worker goroutines in the pool. This case is
    // harmless because there are already background mark workers running.
    // If this returns false, the caller must NOT become an idle mark worker.
    //
    // nosplit because it may be called without a P.
    //
    //go:nosplit
    bool rec::addIdleMarkWorker(struct gcControllerState* c)
    {
        for(; ; )
        {
            auto old = rec::Load(gocpp::recv(c->idleMarkWorkers));
            auto [n, max] = std::tuple{int32_t(old & uint64_t(~ uint32_t(0))), int32_t(old >> 32)};
            if(n >= max)
            {
                return false;
            }
            if(n < 0)
            {
                print("n="_s, n, " max="_s, max, "\n"_s);
                go_throw("negative idle mark workers"_s);
            }
            auto go_new = uint64_t(uint32_t(n + 1)) | (uint64_t(max) << 32);
            if(rec::CompareAndSwap(gocpp::recv(c->idleMarkWorkers), old, go_new))
            {
                return true;
            }
        }
    }

    // needIdleMarkWorker is a hint as to whether another idle mark worker is needed.
    //
    // The caller must still call addIdleMarkWorker to become one. This is mainly
    // useful for a quick check before an expensive operation.
    //
    // nosplit because it may be called without a P.
    //
    //go:nosplit
    bool rec::needIdleMarkWorker(struct gcControllerState* c)
    {
        auto p = rec::Load(gocpp::recv(c->idleMarkWorkers));
        auto [n, max] = std::tuple{int32_t(p & uint64_t(~ uint32_t(0))), int32_t(p >> 32)};
        return n < max;
    }

    // removeIdleMarkWorker must be called when a new idle mark worker stops executing.
    void rec::removeIdleMarkWorker(struct gcControllerState* c)
    {
        for(; ; )
        {
            auto old = rec::Load(gocpp::recv(c->idleMarkWorkers));
            auto [n, max] = std::tuple{int32_t(old & uint64_t(~ uint32_t(0))), int32_t(old >> 32)};
            if(n - 1 < 0)
            {
                print("n="_s, n, " max="_s, max, "\n"_s);
                go_throw("negative idle mark workers"_s);
            }
            auto go_new = uint64_t(uint32_t(n - 1)) | (uint64_t(max) << 32);
            if(rec::CompareAndSwap(gocpp::recv(c->idleMarkWorkers), old, go_new))
            {
                return;
            }
        }
    }

    // setMaxIdleMarkWorkers sets the maximum number of idle mark workers allowed.
    //
    // This method is optimistic in that it does not wait for the number of
    // idle mark workers to reduce to max before returning; it assumes the workers
    // will deschedule themselves.
    void rec::setMaxIdleMarkWorkers(struct gcControllerState* c, int32_t max)
    {
        for(; ; )
        {
            auto old = rec::Load(gocpp::recv(c->idleMarkWorkers));
            auto n = int32_t(old & uint64_t(~ uint32_t(0)));
            if(n < 0)
            {
                print("n="_s, n, " max="_s, max, "\n"_s);
                go_throw("negative idle mark workers"_s);
            }
            auto go_new = uint64_t(uint32_t(n)) | (uint64_t(max) << 32);
            if(rec::CompareAndSwap(gocpp::recv(c->idleMarkWorkers), old, go_new))
            {
                return;
            }
        }
    }

    // gcControllerCommit is gcController.commit, but passes arguments from live
    // (non-test) data. It also updates any consumers of the GC pacing, such as
    // sweep pacing and the background scavenger.
    //
    // Calls gcController.commit.
    //
    // The heap lock must be held, so this must be executed on the system stack.
    //
    //go:systemstack
    void gcControllerCommit()
    {
        assertWorldStoppedOrLockHeld(& mheap_.lock);
        rec::commit(gocpp::recv(gcController), isSweepDone());
        if(gcphase != _GCoff)
        {
            rec::revise(gocpp::recv(gcController));
        }
        auto trace = traceAcquire();
        if(rec::ok(gocpp::recv(trace)))
        {
            rec::HeapGoal(gocpp::recv(trace));
            traceRelease(trace);
        }
        auto [trigger, heapGoal] = rec::trigger(gocpp::recv(gcController));
        gcPaceSweeper(trigger);
        gcPaceScavenger(rec::Load(gocpp::recv(gcController.memoryLimit)), heapGoal, gcController.lastHeapGoal);
    }

}

