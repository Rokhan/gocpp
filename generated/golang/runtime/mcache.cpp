// generated by GoCpp from file '$(ImportDir)/runtime/mcache.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/mcache.h"
#include "gocpp/support.h"

#include "golang/internal/abi/type.h"
#include "golang/internal/chacha8rand/chacha8.h"
#include "golang/internal/cpu/cpu.h"
#include "golang/runtime/cgocall.h"
#include "golang/runtime/chan.h"
#include "golang/runtime/coro.h"
#include "golang/runtime/debuglog_off.h"
#include "golang/runtime/internal/atomic/atomic_amd64.h"
#include "golang/runtime/internal/atomic/types.h"
#include "golang/runtime/internal/sys/nih.h"
#include "golang/runtime/lock_sema.h"
#include "golang/runtime/lockrank.h"
#include "golang/runtime/lockrank_off.h"
#include "golang/runtime/malloc.h"
#include "golang/runtime/mbitmap_allocheaders.h"
#include "golang/runtime/mcentral.h"
#include "golang/runtime/mcheckmark.h"
#include "golang/runtime/mfixalloc.h"
#include "golang/runtime/mgc.h"
#include "golang/runtime/mgclimit.h"
#include "golang/runtime/mgcpacer.h"
#include "golang/runtime/mgcscavenge.h"
#include "golang/runtime/mgcsweep.h"
#include "golang/runtime/mgcwork.h"
#include "golang/runtime/mheap.h"
#include "golang/runtime/mpagealloc.h"
#include "golang/runtime/mpagecache.h"
#include "golang/runtime/mpallocbits.h"
#include "golang/runtime/mprof.h"
#include "golang/runtime/mranges.h"
#include "golang/runtime/mspanset.h"
#include "golang/runtime/mstats.h"
#include "golang/runtime/mwbbuf.h"
#include "golang/runtime/os_windows.h"
#include "golang/runtime/pagetrace_off.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/pinner.h"
#include "golang/runtime/proc.h"
#include "golang/runtime/runtime2.h"
#include "golang/runtime/signal_windows.h"
#include "golang/runtime/sizeclasses.h"
#include "golang/runtime/stack.h"
#include "golang/runtime/stubs.h"
#include "golang/runtime/symtab.h"
#include "golang/runtime/time.h"
#include "golang/runtime/trace2buf.h"
#include "golang/runtime/trace2runtime.h"
#include "golang/runtime/trace2status.h"
#include "golang/runtime/trace2time.h"
#include "golang/unsafe/unsafe.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
        using atomic::rec::Add;
        using atomic::rec::Load;
        using atomic::rec::Store;
    }

    // Per-thread (in Go, per-P) cache for small objects.
    // This includes a small object cache and local allocation stats.
    // No locking needed because it is per-thread (per-P).
    //
    // mcaches are allocated from non-GC'd memory, so any heap pointers
    // must be specially handled.
    
    template<typename T> requires gocpp::GoStruct<T>
    mcache::operator T()
    {
        T result;
        result._1 = this->_1;
        result.nextSample = this->nextSample;
        result.scanAlloc = this->scanAlloc;
        result.tiny = this->tiny;
        result.tinyoffset = this->tinyoffset;
        result.tinyAllocs = this->tinyAllocs;
        result.alloc = this->alloc;
        result.stackcache = this->stackcache;
        result.flushGen = this->flushGen;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool mcache::operator==(const T& ref) const
    {
        if (_1 != ref._1) return false;
        if (nextSample != ref.nextSample) return false;
        if (scanAlloc != ref.scanAlloc) return false;
        if (tiny != ref.tiny) return false;
        if (tinyoffset != ref.tinyoffset) return false;
        if (tinyAllocs != ref.tinyAllocs) return false;
        if (alloc != ref.alloc) return false;
        if (stackcache != ref.stackcache) return false;
        if (flushGen != ref.flushGen) return false;
        return true;
    }

    std::ostream& mcache::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << _1;
        os << " " << nextSample;
        os << " " << scanAlloc;
        os << " " << tiny;
        os << " " << tinyoffset;
        os << " " << tinyAllocs;
        os << " " << alloc;
        os << " " << stackcache;
        os << " " << flushGen;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct mcache& value)
    {
        return value.PrintTo(os);
    }

    // A gclink is a node in a linked list of blocks, like mlink,
    // but it is opaque to the garbage collector.
    // The GC does not trace the pointers during collection,
    // and the compiler does not emit write barriers for assignments
    // of gclinkptr values. Code should store references to gclinks
    // as gclinkptr, not as *gclink.
    
    template<typename T> requires gocpp::GoStruct<T>
    gclink::operator T()
    {
        T result;
        result.next = this->next;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool gclink::operator==(const T& ref) const
    {
        if (next != ref.next) return false;
        return true;
    }

    std::ostream& gclink::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << next;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct gclink& value)
    {
        return value.PrintTo(os);
    }

    // A gclinkptr is a pointer to a gclink, but it is opaque
    // to the garbage collector.
    // ptr returns the *gclink form of p.
    // The result should be used for accessing fields, not stored
    // in other data structures.
    struct gclink* rec::ptr(golang::runtime::gclinkptr p)
    {
        return (gclink*)(unsafe::Pointer(p));
    }

    
    template<typename T> requires gocpp::GoStruct<T>
    stackfreelist::operator T()
    {
        T result;
        result.list = this->list;
        result.size = this->size;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool stackfreelist::operator==(const T& ref) const
    {
        if (list != ref.list) return false;
        if (size != ref.size) return false;
        return true;
    }

    std::ostream& stackfreelist::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << list;
        os << " " << size;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct stackfreelist& value)
    {
        return value.PrintTo(os);
    }

    // dummy mspan that contains no free objects.
    mspan emptymspan;
    struct mcache* allocmcache()
    {
        mcache* c = {};
        systemstack([=]() mutable -> void
        {
            lock(& mheap_.lock);
            c = (mcache*)(rec::alloc(gocpp::recv(mheap_.cachealloc)));
            rec::Store(gocpp::recv(c->flushGen), mheap_.sweepgen);
            unlock(& mheap_.lock);
        });
        for(auto [i, gocpp_ignored] : c->alloc)
        {
            c->alloc[i] = & emptymspan;
        }
        c->nextSample = nextSample();
        return c;
    }

    // freemcache releases resources associated with this
    // mcache and puts the object onto a free list.
    //
    // In some cases there is no way to simply release
    // resources, such as statistics, so donate them to
    // a different mcache (the recipient).
    void freemcache(struct mcache* c)
    {
        systemstack([=]() mutable -> void
        {
            rec::releaseAll(gocpp::recv(c));
            stackcache_clear(c);
            lock(& mheap_.lock);
            rec::free(gocpp::recv(mheap_.cachealloc), unsafe::Pointer(c));
            unlock(& mheap_.lock);
        });
    }

    // getMCache is a convenience function which tries to obtain an mcache.
    //
    // Returns nil if we're not bootstrapping or we don't have a P. The caller's
    // P must not change, so we must be in a non-preemptible state.
    struct mcache* getMCache(struct m* mp)
    {
        auto pp = rec::ptr(gocpp::recv(mp->p));
        mcache* c = {};
        if(pp == nullptr)
        {
            c = mcache0;
        }
        else
        {
            c = pp->mcache;
        }
        return c;
    }

    // refill acquires a new span of span class spc for c. This span will
    // have at least one free object. The current span in c must be full.
    //
    // Must run in a non-preemptible context since otherwise the owner of
    // c could change.
    void rec::refill(struct mcache* c, golang::runtime::spanClass spc)
    {
        auto s = c->alloc[spc];
        if(s->allocCount != s->nelems)
        {
            go_throw("refill of span with free space remaining"_s);
        }
        if(s != & emptymspan)
        {
            if(s->sweepgen != mheap_.sweepgen + 3)
            {
                go_throw("bad sweepgen in refill"_s);
            }
            rec::uncacheSpan(gocpp::recv(mheap_.central[spc].mcentral), s);
            auto stats = rec::acquire(gocpp::recv(memstats.heapStats));
            auto slotsUsed = int64_t(s->allocCount) - int64_t(s->allocCountBeforeCache);
            atomic::Xadd64(& stats->smallAllocCount[rec::sizeclass(gocpp::recv(spc))], slotsUsed);
            if(spc == tinySpanClass)
            {
                atomic::Xadd64(& stats->tinyAllocCount, int64_t(c->tinyAllocs));
                c->tinyAllocs = 0;
            }
            rec::release(gocpp::recv(memstats.heapStats));
            auto bytesAllocated = slotsUsed * int64_t(s->elemsize);
            rec::Add(gocpp::recv(gcController.totalAlloc), bytesAllocated);
            s->allocCountBeforeCache = 0;
        }
        s = rec::cacheSpan(gocpp::recv(mheap_.central[spc].mcentral));
        if(s == nullptr)
        {
            go_throw("out of memory"_s);
        }
        if(s->allocCount == s->nelems)
        {
            go_throw("span has no free space"_s);
        }
        s->sweepgen = mheap_.sweepgen + 3;
        s->allocCountBeforeCache = s->allocCount;
        auto usedBytes = uintptr_t(s->allocCount) * s->elemsize;
        rec::update(gocpp::recv(gcController), int64_t(s->npages * pageSize) - int64_t(usedBytes), int64_t(c->scanAlloc));
        c->scanAlloc = 0;
        c->alloc[spc] = s;
    }

    // allocLarge allocates a span for a large object.
    struct mspan* rec::allocLarge(struct mcache* c, uintptr_t size, bool noscan)
    {
        if(size + _PageSize < size)
        {
            go_throw("out of memory"_s);
        }
        auto npages = size >> _PageShift;
        if(size & _PageMask != 0)
        {
            npages++;
        }
        deductSweepCredit(npages * _PageSize, npages);
        auto spc = makeSpanClass(0, noscan);
        auto s = rec::alloc(gocpp::recv(mheap_), npages, spc);
        if(s == nullptr)
        {
            go_throw("out of memory"_s);
        }
        auto stats = rec::acquire(gocpp::recv(memstats.heapStats));
        atomic::Xadd64(& stats->largeAlloc, int64_t(npages * pageSize));
        atomic::Xadd64(& stats->largeAllocCount, 1);
        rec::release(gocpp::recv(memstats.heapStats));
        rec::Add(gocpp::recv(gcController.totalAlloc), int64_t(npages * pageSize));
        rec::update(gocpp::recv(gcController), int64_t(s->npages * pageSize), 0);
        rec::push(gocpp::recv(rec::fullSwept(gocpp::recv(mheap_.central[spc].mcentral), mheap_.sweepgen)), s);
        s->limit = rec::base(gocpp::recv(s)) + size;
        rec::initHeapBits(gocpp::recv(s), false);
        return s;
    }

    void rec::releaseAll(struct mcache* c)
    {
        auto scanAlloc = int64_t(c->scanAlloc);
        c->scanAlloc = 0;
        auto sg = mheap_.sweepgen;
        auto dHeapLive = int64_t(0);
        for(auto [i, gocpp_ignored] : c->alloc)
        {
            auto s = c->alloc[i];
            if(s != & emptymspan)
            {
                auto slotsUsed = int64_t(s->allocCount) - int64_t(s->allocCountBeforeCache);
                s->allocCountBeforeCache = 0;
                auto stats = rec::acquire(gocpp::recv(memstats.heapStats));
                atomic::Xadd64(& stats->smallAllocCount[rec::sizeclass(gocpp::recv(spanClass(i)))], slotsUsed);
                rec::release(gocpp::recv(memstats.heapStats));
                rec::Add(gocpp::recv(gcController.totalAlloc), slotsUsed * int64_t(s->elemsize));
                if(s->sweepgen != sg + 1)
                {
                    dHeapLive -= int64_t(s->nelems - s->allocCount) * int64_t(s->elemsize);
                }
                rec::uncacheSpan(gocpp::recv(mheap_.central[i].mcentral), s);
                c->alloc[i] = & emptymspan;
            }
        }
        c->tiny = 0;
        c->tinyoffset = 0;
        auto stats = rec::acquire(gocpp::recv(memstats.heapStats));
        atomic::Xadd64(& stats->tinyAllocCount, int64_t(c->tinyAllocs));
        c->tinyAllocs = 0;
        rec::release(gocpp::recv(memstats.heapStats));
        rec::update(gocpp::recv(gcController), dHeapLive, scanAlloc);
    }

    // prepareForSweep flushes c if the system has entered a new sweep phase
    // since c was populated. This must happen between the sweep phase
    // starting and the first allocation from c.
    void rec::prepareForSweep(struct mcache* c)
    {
        auto sg = mheap_.sweepgen;
        auto flushGen = rec::Load(gocpp::recv(c->flushGen));
        if(flushGen == sg)
        {
            return;
        }
        else
        if(flushGen != sg - 2)
        {
            println("bad flushGen"_s, flushGen, "in prepareForSweep; sweepgen"_s, sg);
            go_throw("bad flushGen"_s);
        }
        rec::releaseAll(gocpp::recv(c));
        stackcache_clear(c);
        rec::Store(gocpp::recv(c->flushGen), mheap_.sweepgen);
    }

}

