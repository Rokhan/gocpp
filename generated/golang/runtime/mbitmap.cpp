// generated by GoCpp from file '$(ImportDir)/runtime/mbitmap.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/mbitmap.h"
#include "gocpp/support.h"

#include "golang/internal/abi/type.h"
#include "golang/internal/chacha8rand/chacha8.h"
#include "golang/internal/cpu/cpu.h"
#include "golang/internal/goarch/goarch.h"
#include "golang/runtime/cgocall.h"
#include "golang/runtime/chan.h"
#include "golang/runtime/coro.h"
#include "golang/runtime/debuglog_off.h"
#include "golang/runtime/extern.h"
#include "golang/runtime/internal/atomic/atomic_amd64.h"
#include "golang/runtime/internal/atomic/types.h"
#include "golang/runtime/internal/sys/intrinsics.h"
#include "golang/runtime/internal/sys/nih.h"
#include "golang/runtime/lockrank.h"
#include "golang/runtime/lockrank_off.h"
#include "golang/runtime/malloc.h"
#include "golang/runtime/mbitmap_allocheaders.h"
#include "golang/runtime/mcache.h"
#include "golang/runtime/mcentral.h"
#include "golang/runtime/mcheckmark.h"
#include "golang/runtime/mfixalloc.h"
#include "golang/runtime/mgc.h"
#include "golang/runtime/mgclimit.h"
#include "golang/runtime/mgcmark.h"
#include "golang/runtime/mgcscavenge.h"
#include "golang/runtime/mgcwork.h"
#include "golang/runtime/mheap.h"
#include "golang/runtime/mpagealloc.h"
#include "golang/runtime/mpagecache.h"
#include "golang/runtime/mpallocbits.h"
#include "golang/runtime/mprof.h"
#include "golang/runtime/mranges.h"
#include "golang/runtime/mspanset.h"
#include "golang/runtime/mstats.h"
#include "golang/runtime/mwbbuf.h"
#include "golang/runtime/os_windows.h"
#include "golang/runtime/pagetrace_off.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/pinner.h"
#include "golang/runtime/print.h"
#include "golang/runtime/proc.h"
#include "golang/runtime/runtime1.h"
#include "golang/runtime/runtime2.h"
#include "golang/runtime/signal_windows.h"
#include "golang/runtime/stack.h"
#include "golang/runtime/stubs.h"
#include "golang/runtime/symtab.h"
#include "golang/runtime/time.h"
#include "golang/runtime/trace2buf.h"
#include "golang/runtime/trace2runtime.h"
#include "golang/runtime/trace2status.h"
#include "golang/runtime/trace2time.h"
#include "golang/runtime/type.h"
#include "golang/runtime/typekind.h"
#include "golang/unsafe/unsafe.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
    }

    // addb returns the byte pointer p+n.
    //
    //go:nowritebarrier
    //go:nosplit
    unsigned char* addb(unsigned char* p, uintptr_t n)
    {
        return (unsigned char*)(unsafe::Pointer(uintptr_t(unsafe::Pointer(p)) + n));
    }

    // subtractb returns the byte pointer p-n.
    //
    //go:nowritebarrier
    //go:nosplit
    unsigned char* subtractb(unsigned char* p, uintptr_t n)
    {
        return (unsigned char*)(unsafe::Pointer(uintptr_t(unsafe::Pointer(p)) - n));
    }

    // add1 returns the byte pointer p+1.
    //
    //go:nowritebarrier
    //go:nosplit
    unsigned char* add1(unsigned char* p)
    {
        return (unsigned char*)(unsafe::Pointer(uintptr_t(unsafe::Pointer(p)) + 1));
    }

    // subtract1 returns the byte pointer p-1.
    //
    // nosplit because it is used during write barriers and must not be preempted.
    //
    //go:nowritebarrier
    //go:nosplit
    unsigned char* subtract1(unsigned char* p)
    {
        return (unsigned char*)(unsafe::Pointer(uintptr_t(unsafe::Pointer(p)) - 1));
    }

    // markBits provides access to the mark bit for an object in the heap.
    // bytep points to the byte holding the mark bit.
    // mask is a byte with a single bit set that can be &ed with *bytep
    // to see if the bit has been set.
    // *m.byte&m.mask != 0 indicates the mark bit is set.
    // index can be used along with span information to generate
    // the address of the object in the heap.
    // We maintain one set of mark bits for allocation and one for
    // marking purposes.
    
    template<typename T> requires gocpp::GoStruct<T>
    markBits::operator T()
    {
        T result;
        result.bytep = this->bytep;
        result.mask = this->mask;
        result.index = this->index;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool markBits::operator==(const T& ref) const
    {
        if (bytep != ref.bytep) return false;
        if (mask != ref.mask) return false;
        if (index != ref.index) return false;
        return true;
    }

    std::ostream& markBits::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << bytep;
        os << " " << mask;
        os << " " << index;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct markBits& value)
    {
        return value.PrintTo(os);
    }

    //go:nosplit
    struct markBits rec::allocBitsForIndex(golang::runtime::mspan* s, uintptr_t allocBitIndex)
    {
        auto [bytep, mask] = rec::bitp(gocpp::recv(s->allocBits), allocBitIndex);
        return markBits {bytep, mask, allocBitIndex};
    }

    // refillAllocCache takes 8 bytes s.allocBits starting at whichByte
    // and negates them so that ctz (count trailing zeros) instructions
    // can be used. It then places these 8 bytes into the cached 64 bit
    // s.allocCache.
    void rec::refillAllocCache(golang::runtime::mspan* s, uint16_t whichByte)
    {
        auto bytes = (gocpp::array<uint8_t, 8>*)(unsafe::Pointer(rec::bytep(gocpp::recv(s->allocBits), uintptr_t(whichByte))));
        auto aCache = uint64_t(0);
        aCache |= uint64_t(bytes[0]);
        aCache |= uint64_t(bytes[1]) << (1 * 8);
        aCache |= uint64_t(bytes[2]) << (2 * 8);
        aCache |= uint64_t(bytes[3]) << (3 * 8);
        aCache |= uint64_t(bytes[4]) << (4 * 8);
        aCache |= uint64_t(bytes[5]) << (5 * 8);
        aCache |= uint64_t(bytes[6]) << (6 * 8);
        aCache |= uint64_t(bytes[7]) << (7 * 8);
        s->allocCache = ~ aCache;
    }

    // nextFreeIndex returns the index of the next free object in s at
    // or after s.freeindex.
    // There are hardware instructions that can be used to make this
    // faster if profiling warrants it.
    uint16_t rec::nextFreeIndex(golang::runtime::mspan* s)
    {
        auto sfreeindex = s->freeindex;
        auto snelems = s->nelems;
        if(sfreeindex == snelems)
        {
            return sfreeindex;
        }
        if(sfreeindex > snelems)
        {
            go_throw("s.freeindex > s.nelems"_s);
        }
        auto aCache = s->allocCache;
        auto bitIndex = sys::TrailingZeros64(aCache);
        for(; bitIndex == 64; )
        {
            sfreeindex = (sfreeindex + 64) &^ (64 - 1);
            if(sfreeindex >= snelems)
            {
                s->freeindex = snelems;
                return snelems;
            }
            auto whichByte = sfreeindex / 8;
            rec::refillAllocCache(gocpp::recv(s), whichByte);
            aCache = s->allocCache;
            bitIndex = sys::TrailingZeros64(aCache);
        }
        auto result = sfreeindex + uint16_t(bitIndex);
        if(result >= snelems)
        {
            s->freeindex = snelems;
            return snelems;
        }
        s->allocCache >>= (unsigned int)(bitIndex + 1);
        sfreeindex = result + 1;
        if(sfreeindex % 64 == 0 && sfreeindex != snelems)
        {
            auto whichByte = sfreeindex / 8;
            rec::refillAllocCache(gocpp::recv(s), whichByte);
        }
        s->freeindex = sfreeindex;
        return result;
    }

    // isFree reports whether the index'th object in s is unallocated.
    //
    // The caller must ensure s.state is mSpanInUse, and there must have
    // been no preemption points since ensuring this (which could allow a
    // GC transition, which would allow the state to change).
    bool rec::isFree(golang::runtime::mspan* s, uintptr_t index)
    {
        if(index < uintptr_t(s->freeIndexForScan))
        {
            return false;
        }
        auto [bytep, mask] = rec::bitp(gocpp::recv(s->allocBits), index);
        return *bytep & mask == 0;
    }

    // divideByElemSize returns n/s.elemsize.
    // n must be within [0, s.npages*_PageSize),
    // or may be exactly s.npages*_PageSize
    // if s.elemsize is from sizeclasses.go.
    //
    // nosplit, because it is called by objIndex, which is nosplit
    //
    //go:nosplit
    uintptr_t rec::divideByElemSize(golang::runtime::mspan* s, uintptr_t n)
    {
        auto doubleCheck = false;
        auto q = uintptr_t((uint64_t(n) * uint64_t(s->divMul)) >> 32);
        if(doubleCheck && q != n / s->elemsize)
        {
            println(n, "/"_s, s->elemsize, "should be"_s, n / s->elemsize, "but got"_s, q);
            go_throw("bad magic division"_s);
        }
        return q;
    }

    // nosplit, because it is called by other nosplit code like findObject
    //
    //go:nosplit
    uintptr_t rec::objIndex(golang::runtime::mspan* s, uintptr_t p)
    {
        return rec::divideByElemSize(gocpp::recv(s), p - rec::base(gocpp::recv(s)));
    }

    struct markBits markBitsForAddr(uintptr_t p)
    {
        auto s = spanOf(p);
        auto objIndex = rec::objIndex(gocpp::recv(s), p);
        return rec::markBitsForIndex(gocpp::recv(s), objIndex);
    }

    struct markBits rec::markBitsForIndex(golang::runtime::mspan* s, uintptr_t objIndex)
    {
        auto [bytep, mask] = rec::bitp(gocpp::recv(s->gcmarkBits), objIndex);
        return markBits {bytep, mask, objIndex};
    }

    struct markBits rec::markBitsForBase(golang::runtime::mspan* s)
    {
        return markBits {& s->gcmarkBits->x, uint8_t(1), 0};
    }

    // isMarked reports whether mark bit m is set.
    bool rec::isMarked(golang::runtime::markBits m)
    {
        return *m.bytep & m.mask != 0;
    }

    // setMarked sets the marked bit in the markbits, atomically.
    void rec::setMarked(golang::runtime::markBits m)
    {
        atomic::Or8(m.bytep, m.mask);
    }

    // setMarkedNonAtomic sets the marked bit in the markbits, non-atomically.
    void rec::setMarkedNonAtomic(golang::runtime::markBits m)
    {
        *m.bytep |= m.mask;
    }

    // clearMarked clears the marked bit in the markbits, atomically.
    void rec::clearMarked(golang::runtime::markBits m)
    {
        atomic::And8(m.bytep, ~ m.mask);
    }

    // markBitsForSpan returns the markBits for the span base address base.
    struct markBits markBitsForSpan(uintptr_t base)
    {
        struct markBits mbits;
        mbits = markBitsForAddr(base);
        if(mbits.mask != 1)
        {
            go_throw("markBitsForSpan: unaligned start"_s);
        }
        return mbits;
    }

    // advance advances the markBits to the next object in the span.
    void rec::advance(golang::runtime::markBits* m)
    {
        if(m->mask == (1 << 7))
        {
            m->bytep = (uint8_t*)(unsafe::Pointer(uintptr_t(unsafe::Pointer(m->bytep)) + 1));
            m->mask = 1;
        }
        else
        {
            m->mask = m->mask << 1;
        }
        m->index++;
    }

    // clobberdeadPtr is a special value that is used by the compiler to
    // clobber dead stack slots, when -clobberdead flag is set.
    // badPointer throws bad pointer in heap panic.
    void badPointer(struct mspan* s, uintptr_t p, uintptr_t refBase, uintptr_t refOff)
    {
        printlock();
        print("runtime: pointer "_s, hex(p));
        if(s != nullptr)
        {
            auto state = rec::get(gocpp::recv(s->state));
            if(state != mSpanInUse)
            {
                print(" to unallocated span"_s);
            }
            else
            {
                print(" to unused region of span"_s);
            }
            print(" span.base()="_s, hex(rec::base(gocpp::recv(s))), " span.limit="_s, hex(s->limit), " span.state="_s, state);
        }
        print("\n"_s);
        if(refBase != 0)
        {
            print("runtime: found in object at *("_s, hex(refBase), "+"_s, hex(refOff), ")\n"_s);
            gcDumpObject("object"_s, refBase, refOff);
        }
        getg()->m->traceback = 2;
        go_throw("found bad pointer in Go heap (incorrect use of unsafe or cgo?)"_s);
    }

    // findObject returns the base address for the heap object containing
    // the address p, the object's span, and the index of the object in s.
    // If p does not point into a heap object, it returns base == 0.
    //
    // If p points is an invalid heap pointer and debug.invalidptr != 0,
    // findObject panics.
    //
    // refBase and refOff optionally give the base address of the object
    // in which the pointer p was found and the byte offset at which it
    // was found. These are used for error reporting.
    //
    // It is nosplit so it is safe for p to be a pointer to the current goroutine's stack.
    // Since p is a uintptr, it would not be adjusted if the stack were to move.
    //
    //go:nosplit
    std::tuple<uintptr_t, struct mspan*, uintptr_t> findObject(uintptr_t p, uintptr_t refBase, uintptr_t refOff)
    {
        uintptr_t base;
        struct mspan* s;
        uintptr_t objIndex;
        s = spanOf(p);
        if(s == nullptr)
        {
            if((GOARCH == "amd64"_s || GOARCH == "arm64"_s) && p == clobberdeadPtr && debug.invalidptr != 0)
            {
                badPointer(s, p, refBase, refOff);
            }
            return {base, s, objIndex};
        }
        if(auto state = rec::get(gocpp::recv(s->state)); state != mSpanInUse || p < rec::base(gocpp::recv(s)) || p >= s->limit)
        {
            if(state == mSpanManual)
            {
                return {base, s, objIndex};
            }
            if(debug.invalidptr != 0)
            {
                badPointer(s, p, refBase, refOff);
            }
            return {base, s, objIndex};
        }
        objIndex = rec::objIndex(gocpp::recv(s), p);
        base = rec::base(gocpp::recv(s)) + objIndex * s->elemsize;
        return {base, s, objIndex};
    }

    // reflect_verifyNotInHeapPtr reports whether converting the not-in-heap pointer into a unsafe.Pointer is ok.
    //
    //go:linkname reflect_verifyNotInHeapPtr reflect.verifyNotInHeapPtr
    bool reflect_verifyNotInHeapPtr(uintptr_t p)
    {
        return spanOf(p) == nullptr && p != clobberdeadPtr;
    }

    // bulkBarrierBitmap executes write barriers for copying from [src,
    // src+size) to [dst, dst+size) using a 1-bit pointer bitmap. src is
    // assumed to start maskOffset bytes into the data covered by the
    // bitmap in bits (which may not be a multiple of 8).
    //
    // This is used by bulkBarrierPreWrite for writes to data and BSS.
    //
    //go:nosplit
    void bulkBarrierBitmap(uintptr_t dst, uintptr_t src, uintptr_t size, uintptr_t maskOffset, uint8_t* bits)
    {
        auto word = maskOffset / goarch::PtrSize;
        bits = addb(bits, word / 8);
        auto mask = uint8_t(1) << (word % 8);
        auto buf = & rec::ptr(gocpp::recv(getg()->m->p))->wbBuf;
        for(auto i = uintptr_t(0); i < size; i += goarch::PtrSize)
        {
            if(mask == 0)
            {
                bits = addb(bits, 1);
                if(*bits == 0)
                {
                    i += 7 * goarch::PtrSize;
                    continue;
                }
                mask = 1;
            }
            if(*bits & mask != 0)
            {
                auto dstx = (uintptr_t*)(unsafe::Pointer(dst + i));
                if(src == 0)
                {
                    auto p = rec::get1(gocpp::recv(buf));
                    p[0] = *dstx;
                }
                else
                {
                    auto srcx = (uintptr_t*)(unsafe::Pointer(src + i));
                    auto p = rec::get2(gocpp::recv(buf));
                    p[0] = *dstx;
                    p[1] = *srcx;
                }
            }
            mask <<= 1;
        }
    }

    // typeBitsBulkBarrier executes a write barrier for every
    // pointer that would be copied from [src, src+size) to [dst,
    // dst+size) by a memmove using the type bitmap to locate those
    // pointer slots.
    //
    // The type typ must correspond exactly to [src, src+size) and [dst, dst+size).
    // dst, src, and size must be pointer-aligned.
    // The type typ must have a plain bitmap, not a GC program.
    // The only use of this function is in channel sends, and the
    // 64 kB channel element limit takes care of this for us.
    //
    // Must not be preempted because it typically runs right before memmove,
    // and the GC must observe them as an atomic action.
    //
    // Callers must perform cgo checks if goexperiment.CgoCheck2.
    //
    //go:nosplit
    void typeBitsBulkBarrier(golang::runtime::_type* typ, uintptr_t dst, uintptr_t src, uintptr_t size)
    {
        if(typ == nullptr)
        {
            go_throw("runtime: typeBitsBulkBarrier without type"_s);
        }
        if(typ->Size_ != size)
        {
            println("runtime: typeBitsBulkBarrier with type "_s, rec::string(gocpp::recv(toRType(typ))), " of size "_s, typ->Size_, " but memory size"_s, size);
            go_throw("runtime: invalid typeBitsBulkBarrier"_s);
        }
        if(typ->Kind_ & kindGCProg != 0)
        {
            println("runtime: typeBitsBulkBarrier with type "_s, rec::string(gocpp::recv(toRType(typ))), " with GC prog"_s);
            go_throw("runtime: invalid typeBitsBulkBarrier"_s);
        }
        if(! writeBarrier.enabled)
        {
            return;
        }
        auto ptrmask = typ->GCData;
        auto buf = & rec::ptr(gocpp::recv(getg()->m->p))->wbBuf;
        uint32_t bits = {};
        for(auto i = uintptr_t(0); i < typ->PtrBytes; i += goarch::PtrSize)
        {
            if(i & (goarch::PtrSize * 8 - 1) == 0)
            {
                bits = uint32_t(*ptrmask);
                ptrmask = addb(ptrmask, 1);
            }
            else
            {
                bits = bits >> 1;
            }
            if(bits & 1 != 0)
            {
                auto dstx = (uintptr_t*)(unsafe::Pointer(dst + i));
                auto srcx = (uintptr_t*)(unsafe::Pointer(src + i));
                auto p = rec::get2(gocpp::recv(buf));
                p[0] = *dstx;
                p[1] = *srcx;
            }
        }
    }

    // countAlloc returns the number of objects allocated in span s by
    // scanning the mark bitmap.
    int rec::countAlloc(golang::runtime::mspan* s)
    {
        auto count = 0;
        auto bytes = divRoundUp(uintptr_t(s->nelems), 8);
        for(auto i = uintptr_t(0); i < bytes; i += 8)
        {
            auto mrkBits = *(uint64_t*)(unsafe::Pointer(rec::bytep(gocpp::recv(s->gcmarkBits), i)));
            count += sys::OnesCount64(mrkBits);
        }
        return count;
    }

    // Read the bytes starting at the aligned pointer p into a uintptr.
    // Read is little-endian.
    uintptr_t readUintptr(unsigned char* p)
    {
        auto x = *(uintptr_t*)(unsafe::Pointer(p));
        if(goarch::BigEndian)
        {
            if(goarch::PtrSize == 8)
            {
                return uintptr_t(sys::Bswap64(uint64_t(x)));
            }
            return uintptr_t(sys::Bswap32(uint32_t(x)));
        }
        return x;
    }

    struct gocpp_id_0
    {
        mutex lock;
        unsigned char* data;

        using isGoStruct = void;

        template<typename T> requires gocpp::GoStruct<T>
        operator T()
        {
            T result;
            result.lock = this->lock;
            result.data = this->data;
            return result;
        }

        template<typename T> requires gocpp::GoStruct<T>
        bool operator==(const T& ref) const
        {
            if (lock != ref.lock) return false;
            if (data != ref.data) return false;
            return true;
        }

        std::ostream& PrintTo(std::ostream& os) const
        {
            os << '{';
            os << "" << lock;
            os << " " << data;
            os << '}';
            return os;
        }
    };

    std::ostream& operator<<(std::ostream& os, const struct gocpp_id_0& value)
    {
        return value.PrintTo(os);
    }


    gocpp_id_0 debugPtrmask;
    // progToPointerMask returns the 1-bit pointer mask output by the GC program prog.
    // size the size of the region described by prog, in bytes.
    // The resulting bitvector will have no more than size/goarch.PtrSize bits.
    struct bitvector progToPointerMask(unsigned char* prog, uintptr_t size)
    {
        auto n = (size / goarch::PtrSize + 7) / 8;
        auto x = (gocpp::array<unsigned char, 1 << 30>*)(persistentalloc(n + 1, 1, & memstats.buckhash_sys)).make_slice(0, n + 1);
        x[len(x) - 1] = 0xa1;
        n = runGCProg(prog, & x[0]);
        if(x[len(x) - 1] != 0xa1)
        {
            go_throw("progToPointerMask: overflow"_s);
        }
        return bitvector {int32_t(n), & x[0]};
    }

    // runGCProg returns the number of 1-bit entries written to memory.
    uintptr_t runGCProg(unsigned char* prog, unsigned char* dst)
    {
        auto dstStart = dst;
        // Bits waiting to be written to memory.
        uintptr_t bits = {};
        uintptr_t nbits = {};
        auto p = prog;
        Run:
        for(; ; )
        {
            for(; nbits >= 8; nbits -= 8)
            {
                *dst = uint8_t(bits);
                dst = add1(dst);
                bits >>= 8;
            }
            auto inst = uintptr_t(*p);
            p = add1(p);
            auto n = inst & 0x7F;
            if(inst & 0x80 == 0)
            {
                if(n == 0)
                {
                    goto Run_break;
                }
                auto nbyte = n / 8;
                for(auto i = uintptr_t(0); i < nbyte; i++)
                {
                    bits |= uintptr_t(*p) << nbits;
                    p = add1(p);
                    *dst = uint8_t(bits);
                    dst = add1(dst);
                    bits >>= 8;
                }
                if(n %= 8; n > 0)
                {
                    bits |= uintptr_t(*p) << nbits;
                    p = add1(p);
                    nbits += n;
                }
                goto Run_continue;
            }
            if(n == 0)
            {
                for(auto off = (unsigned int)(0); ; off += 7)
                {
                    auto x = uintptr_t(*p);
                    p = add1(p);
                    n |= (x & 0x7F) << off;
                    if(x & 0x80 == 0)
                    {
                        break;
                    }
                }
            }
            auto c = uintptr_t(0);
            for(auto off = (unsigned int)(0); ; off += 7)
            {
                auto x = uintptr_t(*p);
                p = add1(p);
                c |= (x & 0x7F) << off;
                if(x & 0x80 == 0)
                {
                    break;
                }
            }
            c *= n;
            auto src = dst;
            auto maxBits = goarch::PtrSize * 8 - 7;
            if(n <= maxBits)
            {
                auto pattern = bits;
                auto npattern = nbits;
                src = subtract1(src);
                for(; npattern < n; )
                {
                    pattern <<= 8;
                    pattern |= uintptr_t(*src);
                    src = subtract1(src);
                    npattern += 8;
                }
                if(npattern > n)
                {
                    pattern >>= npattern - n;
                    npattern = n;
                }
                if(npattern == 1)
                {
                    if(pattern == 1)
                    {
                        pattern = (1 << maxBits) - 1;
                        npattern = maxBits;
                    }
                    else
                    {
                        npattern = c;
                    }
                }
                else
                {
                    auto b = pattern;
                    auto nb = npattern;
                    if(nb + nb <= maxBits)
                    {
                        for(; nb <= goarch::PtrSize * 8; )
                        {
                            b |= b << nb;
                            nb += nb;
                        }
                        nb = maxBits / npattern * npattern;
                        b &= (1 << nb) - 1;
                        pattern = b;
                        npattern = nb;
                    }
                }
                for(; c >= npattern; c -= npattern)
                {
                    bits |= pattern << nbits;
                    nbits += npattern;
                    for(; nbits >= 8; )
                    {
                        *dst = uint8_t(bits);
                        dst = add1(dst);
                        bits >>= 8;
                        nbits -= 8;
                    }
                }
                if(c > 0)
                {
                    pattern &= (1 << c) - 1;
                    bits |= pattern << nbits;
                    nbits += c;
                }
                goto Run_continue;
            }
            auto off = n - nbits;
            src = subtractb(src, (off + 7) / 8);
            if(auto frag = off & 7; frag != 0)
            {
                bits |= (uintptr_t(*src) >> (8 - frag)) << nbits;
                src = add1(src);
                nbits += frag;
                c -= frag;
            }
            for(auto i = c / 8; i > 0; i--)
            {
                bits |= uintptr_t(*src) << nbits;
                src = add1(src);
                *dst = uint8_t(bits);
                dst = add1(dst);
                bits >>= 8;
            }
            if(c %= 8; c > 0)
            {
                bits |= (uintptr_t(*src) & ((1 << c) - 1)) << nbits;
                nbits += c;
            }
            if(false) {
            Run_continue:
                continue;
            Run_break:
                break;
            }
        }
        auto totalBits = (uintptr_t(unsafe::Pointer(dst)) - uintptr_t(unsafe::Pointer(dstStart))) * 8 + nbits;
        nbits += - nbits & 7;
        for(; nbits > 0; nbits -= 8)
        {
            *dst = uint8_t(bits);
            dst = add1(dst);
            bits >>= 8;
        }
        return totalBits;
    }

    // materializeGCProg allocates space for the (1-bit) pointer bitmask
    // for an object of size ptrdata.  Then it fills that space with the
    // pointer bitmask specified by the program prog.
    // The bitmask starts at s.startAddr.
    // The result must be deallocated with dematerializeGCProg.
    struct mspan* materializeGCProg(uintptr_t ptrdata, unsigned char* prog)
    {
        auto bitmapBytes = divRoundUp(ptrdata, 8 * goarch::PtrSize);
        auto pages = divRoundUp(bitmapBytes, pageSize);
        auto s = rec::allocManual(gocpp::recv(mheap_), pages, spanAllocPtrScalarBits);
        runGCProg(addb(prog, 4), (unsigned char*)(unsafe::Pointer(s->startAddr)));
        return s;
    }

    void dematerializeGCProg(struct mspan* s)
    {
        rec::freeManual(gocpp::recv(mheap_), s, spanAllocPtrScalarBits);
    }

    void dumpGCProg(unsigned char* p)
    {
        auto nptr = 0;
        for(; ; )
        {
            auto x = *p;
            p = add1(p);
            if(x == 0)
            {
                print("\t"_s, nptr, " end\n"_s);
                break;
            }
            if(x & 0x80 == 0)
            {
                print("\t"_s, nptr, " lit "_s, x, ":"_s);
                auto n = int(x + 7) / 8;
                for(auto i = 0; i < n; i++)
                {
                    print(" "_s, hex(*p));
                    p = add1(p);
                }
                print("\n"_s);
                nptr += int(x);
            }
            else
            {
                auto nbit = int(x &^ 0x80);
                if(nbit == 0)
                {
                    for(auto nb = (unsigned int)(0); ; nb += 7)
                    {
                        auto x = *p;
                        p = add1(p);
                        nbit |= int(x & 0x7f) << nb;
                        if(x & 0x80 == 0)
                        {
                            break;
                        }
                    }
                }
                auto count = 0;
                for(auto nb = (unsigned int)(0); ; nb += 7)
                {
                    auto x = *p;
                    p = add1(p);
                    count |= int(x & 0x7f) << nb;
                    if(x & 0x80 == 0)
                    {
                        break;
                    }
                }
                print("\t"_s, nptr, " repeat "_s, nbit, " Ã— "_s, count, "\n"_s);
                nptr += nbit * count;
            }
        }
    }

    // reflect_gcbits returns the GC type info for x, for testing.
    // The result is the bitmap entries (0 or 1), one entry per byte.
    //
    //go:linkname reflect_gcbits reflect.gcbits
    gocpp::slice<unsigned char> reflect_gcbits(go_any x)
    {
        return getgcmask(x);
    }

}

