// generated by GoCpp from file '$(ImportDir)/runtime/map.go'
#include <complex>
#include <functional>
#include <iostream>
#include <iomanip>
#include <map>
#include <string>
#include <tuple>
#include <vector>

#include "golang/runtime/map.h"
#include "gocpp/support.h"

#include "golang/internal/abi/funcpc.h"
#include "golang/internal/abi/map.h"
#include "golang/internal/abi/type.h"
#include "golang/internal/goarch/goarch.h"
#include "golang/runtime/alg.h"
#include "golang/runtime/asan0.h"
#include "golang/runtime/error.h"
#include "golang/runtime/internal/atomic/atomic_amd64.h"
#include "golang/runtime/internal/math/math.h"
#include "golang/runtime/malloc.h"
#include "golang/runtime/map_faststr.h"
#include "golang/runtime/mbarrier.h"
#include "golang/runtime/msan0.h"
#include "golang/runtime/msize_allocheaders.h"
#include "golang/runtime/panic.h"
#include "golang/runtime/race0.h"
#include "golang/runtime/rand.h"
#include "golang/runtime/runtime2.h"
#include "golang/runtime/slice.h"
#include "golang/runtime/stubs.h"
#include "golang/runtime/type.h"
#include "golang/unsafe/unsafe.h"

namespace golang::runtime
{
    namespace rec
    {
        using namespace mocklib::rec;
        using abi::rec::Equal;
        using abi::rec::Hasher;
        using abi::rec::IndirectElem;
        using abi::rec::IndirectKey;
        using abi::rec::NeedKeyUpdate;
        using abi::rec::ReflexiveKey;
        using abi::rec::Size;
    }

    struct gocpp_id_0
    {
        bmap b;
        int64_t v;

        using isGoStruct = void;

        template<typename T> requires gocpp::GoStruct<T>
        operator T()
        {
            T result;
            result.b = this->b;
            result.v = this->v;
            return result;
        }

        template<typename T> requires gocpp::GoStruct<T>
        bool operator==(const T& ref) const
        {
            if (b != ref.b) return false;
            if (v != ref.v) return false;
            return true;
        }

        std::ostream& PrintTo(std::ostream& os) const
        {
            os << '{';
            os << "" << b;
            os << " " << v;
            os << '}';
            return os;
        }
    };

    std::ostream& operator<<(std::ostream& os, const struct gocpp_id_0& value)
    {
        return value.PrintTo(os);
    }


    // Maximum number of key/elem pairs a bucket can hold.
    // Maximum average load of a bucket that triggers growth is bucketCnt*13/16 (about 80% full)
    // Because of minimum alignment rules, bucketCnt is known to be at least 8.
    // Represent as loadFactorNum/loadFactorDen, to allow integer math.
    // Maximum key or elem size to keep inline (instead of mallocing per element).
    // Must fit in a uint8.
    // Fast versions cannot handle big elems - the cutoff size for
    // fast versions in cmd/compile/internal/gc/walk.go must be at most this elem.
    // data offset should be the size of the bmap struct, but needs to be
    // aligned correctly. For amd64p32 this means 64-bit alignment
    // even though pointers are 32 bit.
    // Possible tophash values. We reserve a few possibilities for special marks.
    // Each bucket (including its overflow buckets, if any) will have either all or none of its
    // entries in the evacuated* states (except during the evacuate() method, which only happens
    // during map writes and thus no one else can observe the map during that time).
    // flags
    // sentinel bucket ID for iterator checks
    // isEmpty reports whether the given tophash array entry represents an empty bucket entry.
    bool isEmpty(uint8_t x)
    {
        return x <= emptyOne;
    }

    // A header for a Go map.
    
    template<typename T> requires gocpp::GoStruct<T>
    hmap::operator T()
    {
        T result;
        result.count = this->count;
        result.flags = this->flags;
        result.B = this->B;
        result.noverflow = this->noverflow;
        result.hash0 = this->hash0;
        result.buckets = this->buckets;
        result.oldbuckets = this->oldbuckets;
        result.nevacuate = this->nevacuate;
        result.extra = this->extra;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool hmap::operator==(const T& ref) const
    {
        if (count != ref.count) return false;
        if (flags != ref.flags) return false;
        if (B != ref.B) return false;
        if (noverflow != ref.noverflow) return false;
        if (hash0 != ref.hash0) return false;
        if (buckets != ref.buckets) return false;
        if (oldbuckets != ref.oldbuckets) return false;
        if (nevacuate != ref.nevacuate) return false;
        if (extra != ref.extra) return false;
        return true;
    }

    std::ostream& hmap::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << count;
        os << " " << flags;
        os << " " << B;
        os << " " << noverflow;
        os << " " << hash0;
        os << " " << buckets;
        os << " " << oldbuckets;
        os << " " << nevacuate;
        os << " " << extra;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct hmap& value)
    {
        return value.PrintTo(os);
    }

    // mapextra holds fields that are not present on all maps.
    
    template<typename T> requires gocpp::GoStruct<T>
    mapextra::operator T()
    {
        T result;
        result.overflow = this->overflow;
        result.oldoverflow = this->oldoverflow;
        result.nextOverflow = this->nextOverflow;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool mapextra::operator==(const T& ref) const
    {
        if (overflow != ref.overflow) return false;
        if (oldoverflow != ref.oldoverflow) return false;
        if (nextOverflow != ref.nextOverflow) return false;
        return true;
    }

    std::ostream& mapextra::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << overflow;
        os << " " << oldoverflow;
        os << " " << nextOverflow;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct mapextra& value)
    {
        return value.PrintTo(os);
    }

    // A bucket for a Go map.
    
    template<typename T> requires gocpp::GoStruct<T>
    bmap::operator T()
    {
        T result;
        result.tophash = this->tophash;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool bmap::operator==(const T& ref) const
    {
        if (tophash != ref.tophash) return false;
        return true;
    }

    std::ostream& bmap::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << tophash;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct bmap& value)
    {
        return value.PrintTo(os);
    }

    // A hash iteration structure.
    // If you modify hiter, also change cmd/compile/internal/reflectdata/reflect.go
    // and reflect/value.go to match the layout of this structure.
    
    template<typename T> requires gocpp::GoStruct<T>
    hiter::operator T()
    {
        T result;
        result.key = this->key;
        result.elem = this->elem;
        result.t = this->t;
        result.h = this->h;
        result.buckets = this->buckets;
        result.bptr = this->bptr;
        result.overflow = this->overflow;
        result.oldoverflow = this->oldoverflow;
        result.startBucket = this->startBucket;
        result.offset = this->offset;
        result.wrapped = this->wrapped;
        result.B = this->B;
        result.i = this->i;
        result.bucket = this->bucket;
        result.checkBucket = this->checkBucket;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool hiter::operator==(const T& ref) const
    {
        if (key != ref.key) return false;
        if (elem != ref.elem) return false;
        if (t != ref.t) return false;
        if (h != ref.h) return false;
        if (buckets != ref.buckets) return false;
        if (bptr != ref.bptr) return false;
        if (overflow != ref.overflow) return false;
        if (oldoverflow != ref.oldoverflow) return false;
        if (startBucket != ref.startBucket) return false;
        if (offset != ref.offset) return false;
        if (wrapped != ref.wrapped) return false;
        if (B != ref.B) return false;
        if (i != ref.i) return false;
        if (bucket != ref.bucket) return false;
        if (checkBucket != ref.checkBucket) return false;
        return true;
    }

    std::ostream& hiter::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << key;
        os << " " << elem;
        os << " " << t;
        os << " " << h;
        os << " " << buckets;
        os << " " << bptr;
        os << " " << overflow;
        os << " " << oldoverflow;
        os << " " << startBucket;
        os << " " << offset;
        os << " " << wrapped;
        os << " " << B;
        os << " " << i;
        os << " " << bucket;
        os << " " << checkBucket;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct hiter& value)
    {
        return value.PrintTo(os);
    }

    // bucketShift returns 1<<b, optimized for code generation.
    uintptr_t bucketShift(uint8_t b)
    {
        return uintptr_t(1) << (b & (goarch::PtrSize * 8 - 1));
    }

    // bucketMask returns 1<<b - 1, optimized for code generation.
    uintptr_t bucketMask(uint8_t b)
    {
        return bucketShift(b) - 1;
    }

    // tophash calculates the tophash value for hash.
    uint8_t tophash(uintptr_t hash)
    {
        auto top = uint8_t(hash >> (goarch::PtrSize * 8 - 8));
        if(top < minTopHash)
        {
            top += minTopHash;
        }
        return top;
    }

    bool evacuated(struct bmap* b)
    {
        auto h = b->tophash[0];
        return h > emptyOne && h < minTopHash;
    }

    struct bmap* rec::overflow(struct bmap* b, golang::runtime::maptype* t)
    {
        return *(bmap**)(add(unsafe::Pointer(b), uintptr_t(t->BucketSize) - goarch::PtrSize));
    }

    void rec::setoverflow(struct bmap* b, golang::runtime::maptype* t, struct bmap* ovf)
    {
        *(bmap**)(add(unsafe::Pointer(b), uintptr_t(t->BucketSize) - goarch::PtrSize)) = ovf;
    }

    unsafe::Pointer rec::keys(struct bmap* b)
    {
        return add(unsafe::Pointer(b), dataOffset);
    }

    // incrnoverflow increments h.noverflow.
    // noverflow counts the number of overflow buckets.
    // This is used to trigger same-size map growth.
    // See also tooManyOverflowBuckets.
    // To keep hmap small, noverflow is a uint16.
    // When there are few buckets, noverflow is an exact count.
    // When there are many buckets, noverflow is an approximate count.
    void rec::incrnoverflow(struct hmap* h)
    {
        if(h->B < 16)
        {
            h->noverflow++;
            return;
        }
        auto mask = (uint32_t(1) << (h->B - 15)) - 1;
        if(uint32_t(rand()) & mask == 0)
        {
            h->noverflow++;
        }
    }

    struct bmap* rec::newoverflow(struct hmap* h, golang::runtime::maptype* t, struct bmap* b)
    {
        bmap* ovf = {};
        if(h->extra != nullptr && h->extra->nextOverflow != nullptr)
        {
            ovf = h->extra->nextOverflow;
            if(rec::overflow(gocpp::recv(ovf), t) == nullptr)
            {
                h->extra->nextOverflow = (bmap*)(add(unsafe::Pointer(ovf), uintptr_t(t->BucketSize)));
            }
            else
            {
                rec::setoverflow(gocpp::recv(ovf), t, nullptr);
                h->extra->nextOverflow = nullptr;
            }
        }
        else
        {
            ovf = (bmap*)(newobject(t->Bucket));
        }
        rec::incrnoverflow(gocpp::recv(h));
        if(t->Bucket->PtrBytes == 0)
        {
            rec::createOverflow(gocpp::recv(h));
            *h->extra->overflow = append(*h->extra->overflow, ovf);
        }
        rec::setoverflow(gocpp::recv(b), t, ovf);
        return ovf;
    }

    void rec::createOverflow(struct hmap* h)
    {
        if(h->extra == nullptr)
        {
            h->extra = new(mapextra);
        }
        if(h->extra->overflow == nullptr)
        {
            h->extra->overflow = new(gocpp::Tag<gocpp::slice<bmap*>>());
        }
    }

    struct hmap* makemap64(golang::runtime::maptype* t, int64_t hint, struct hmap* h)
    {
        if(int64_t(int(hint)) != hint)
        {
            hint = 0;
        }
        return makemap(t, int(hint), h);
    }

    // makemap_small implements Go map creation for make(map[k]v) and
    // make(map[k]v, hint) when hint is known to be at most bucketCnt
    // at compile time and the map needs to be allocated on the heap.
    struct hmap* makemap_small()
    {
        auto h = new(hmap);
        h->hash0 = uint32_t(rand());
        return h;
    }

    // makemap implements Go map creation for make(map[k]v, hint).
    // If the compiler has determined that the map or the first bucket
    // can be created on the stack, h and/or bucket may be non-nil.
    // If h != nil, the map can be created directly in h.
    // If h.buckets != nil, bucket pointed to can be used as the first bucket.
    struct hmap* makemap(golang::runtime::maptype* t, int hint, struct hmap* h)
    {
        auto [mem, overflow] = math::MulUintptr(uintptr_t(hint), t->Bucket->Size_);
        if(overflow || mem > maxAlloc)
        {
            hint = 0;
        }
        if(h == nullptr)
        {
            h = new(hmap);
        }
        h->hash0 = uint32_t(rand());
        auto B = uint8_t(0);
        for(; overLoadFactor(hint, B); )
        {
            B++;
        }
        h->B = B;
        if(h->B != 0)
        {
            bmap* nextOverflow = {};
            std::tie(h->buckets, nextOverflow) = makeBucketArray(t, h->B, nullptr);
            if(nextOverflow != nullptr)
            {
                h->extra = new(mapextra);
                h->extra->nextOverflow = nextOverflow;
            }
        }
        return h;
    }

    // makeBucketArray initializes a backing array for map buckets.
    // 1<<b is the minimum number of buckets to allocate.
    // dirtyalloc should either be nil or a bucket array previously
    // allocated by makeBucketArray with the same t and b parameters.
    // If dirtyalloc is nil a new backing array will be alloced and
    // otherwise dirtyalloc will be cleared and reused as backing array.
    std::tuple<unsafe::Pointer, struct bmap*> makeBucketArray(golang::runtime::maptype* t, uint8_t b, unsafe::Pointer dirtyalloc)
    {
        unsafe::Pointer buckets;
        struct bmap* nextOverflow;
        auto base = bucketShift(b);
        auto nbuckets = base;
        if(b >= 4)
        {
            nbuckets += bucketShift(b - 4);
            auto sz = t->Bucket->Size_ * nbuckets;
            auto up = roundupsize(sz, t->Bucket->PtrBytes == 0);
            if(up != sz)
            {
                nbuckets = up / t->Bucket->Size_;
            }
        }
        if(dirtyalloc == nullptr)
        {
            buckets = newarray(t->Bucket, int(nbuckets));
        }
        else
        {
            buckets = dirtyalloc;
            auto size = t->Bucket->Size_ * nbuckets;
            if(t->Bucket->PtrBytes != 0)
            {
                memclrHasPointers(buckets, size);
            }
            else
            {
                memclrNoHeapPointers(buckets, size);
            }
        }
        if(base != nbuckets)
        {
            nextOverflow = (bmap*)(add(buckets, base * uintptr_t(t->BucketSize)));
            auto last = (bmap*)(add(buckets, (nbuckets - 1) * uintptr_t(t->BucketSize)));
            rec::setoverflow(gocpp::recv(last), t, (bmap*)(buckets));
        }
        return {buckets, nextOverflow};
    }

    // mapaccess1 returns a pointer to h[key].  Never returns nil, instead
    // it will return a reference to the zero object for the elem type if
    // the key is not in the map.
    // NOTE: The returned pointer may keep the whole map live, so don't
    // hold onto it for very long.
    unsafe::Pointer mapaccess1(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key)
    {
        if(raceenabled && h != nullptr)
        {
            auto callerpc = getcallerpc();
            auto pc = abi::FuncPCABIInternal(mapaccess1);
            racereadpc(unsafe::Pointer(h), callerpc, pc);
            raceReadObjectPC(t->Key, key, callerpc, pc);
        }
        if(msanenabled && h != nullptr)
        {
            msanread(key, t->Key->Size_);
        }
        if(asanenabled && h != nullptr)
        {
            asanread(key, t->Key->Size_);
        }
        if(h == nullptr || h->count == 0)
        {
            if(auto err = mapKeyError(t, key); err != nullptr)
            {
                gocpp::panic(err);
            }
            return unsafe::Pointer(& zeroVal[0]);
        }
        if(h->flags & hashWriting != 0)
        {
            fatal("concurrent map read and map write"s);
        }
        auto hash = rec::Hasher(gocpp::recv(t), key, uintptr_t(h->hash0));
        auto m = bucketMask(h->B);
        auto b = (bmap*)(add(h->buckets, (hash & m) * uintptr_t(t->BucketSize)));
        if(auto c = h->oldbuckets; c != nullptr)
        {
            if(! rec::sameSizeGrow(gocpp::recv(h)))
            {
                m >>= 1;
            }
            auto oldb = (bmap*)(add(c, (hash & m) * uintptr_t(t->BucketSize)));
            if(! evacuated(oldb))
            {
                b = oldb;
            }
        }
        auto top = tophash(hash);
        bucketloop:
        for(; b != nullptr; b = rec::overflow(gocpp::recv(b), t))
        {
            for(auto i = uintptr_t(0); i < bucketCnt; i++)
            {
                if(b->tophash[i] != top)
                {
                    if(b->tophash[i] == emptyRest)
                    {
                        goto bucketloop_break;
                    }
                    continue;
                }
                auto k = add(unsafe::Pointer(b), dataOffset + i * uintptr_t(t->KeySize));
                if(rec::IndirectKey(gocpp::recv(t)))
                {
                    k = *((unsafe::Pointer*)(k));
                }
                if(rec::Equal(gocpp::recv(t->Key), key, k))
                {
                    auto e = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + i * uintptr_t(t->ValueSize));
                    if(rec::IndirectElem(gocpp::recv(t)))
                    {
                        e = *((unsafe::Pointer*)(e));
                    }
                    return e;
                }
            }
            if(false) {
            bucketloop_continue:
                continue;
            bucketloop_break:
                break;
            }
        }
        return unsafe::Pointer(& zeroVal[0]);
    }

    std::tuple<unsafe::Pointer, bool> mapaccess2(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key)
    {
        if(raceenabled && h != nullptr)
        {
            auto callerpc = getcallerpc();
            auto pc = abi::FuncPCABIInternal(mapaccess2);
            racereadpc(unsafe::Pointer(h), callerpc, pc);
            raceReadObjectPC(t->Key, key, callerpc, pc);
        }
        if(msanenabled && h != nullptr)
        {
            msanread(key, t->Key->Size_);
        }
        if(asanenabled && h != nullptr)
        {
            asanread(key, t->Key->Size_);
        }
        if(h == nullptr || h->count == 0)
        {
            if(auto err = mapKeyError(t, key); err != nullptr)
            {
                gocpp::panic(err);
            }
            return {unsafe::Pointer(& zeroVal[0]), false};
        }
        if(h->flags & hashWriting != 0)
        {
            fatal("concurrent map read and map write"s);
        }
        auto hash = rec::Hasher(gocpp::recv(t), key, uintptr_t(h->hash0));
        auto m = bucketMask(h->B);
        auto b = (bmap*)(add(h->buckets, (hash & m) * uintptr_t(t->BucketSize)));
        if(auto c = h->oldbuckets; c != nullptr)
        {
            if(! rec::sameSizeGrow(gocpp::recv(h)))
            {
                m >>= 1;
            }
            auto oldb = (bmap*)(add(c, (hash & m) * uintptr_t(t->BucketSize)));
            if(! evacuated(oldb))
            {
                b = oldb;
            }
        }
        auto top = tophash(hash);
        bucketloop:
        for(; b != nullptr; b = rec::overflow(gocpp::recv(b), t))
        {
            for(auto i = uintptr_t(0); i < bucketCnt; i++)
            {
                if(b->tophash[i] != top)
                {
                    if(b->tophash[i] == emptyRest)
                    {
                        goto bucketloop_break;
                    }
                    continue;
                }
                auto k = add(unsafe::Pointer(b), dataOffset + i * uintptr_t(t->KeySize));
                if(rec::IndirectKey(gocpp::recv(t)))
                {
                    k = *((unsafe::Pointer*)(k));
                }
                if(rec::Equal(gocpp::recv(t->Key), key, k))
                {
                    auto e = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + i * uintptr_t(t->ValueSize));
                    if(rec::IndirectElem(gocpp::recv(t)))
                    {
                        e = *((unsafe::Pointer*)(e));
                    }
                    return {e, true};
                }
            }
            if(false) {
            bucketloop_continue:
                continue;
            bucketloop_break:
                break;
            }
        }
        return {unsafe::Pointer(& zeroVal[0]), false};
    }

    // returns both key and elem. Used by map iterator.
    std::tuple<unsafe::Pointer, unsafe::Pointer> mapaccessK(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key)
    {
        if(h == nullptr || h->count == 0)
        {
            return {nullptr, nullptr};
        }
        auto hash = rec::Hasher(gocpp::recv(t), key, uintptr_t(h->hash0));
        auto m = bucketMask(h->B);
        auto b = (bmap*)(add(h->buckets, (hash & m) * uintptr_t(t->BucketSize)));
        if(auto c = h->oldbuckets; c != nullptr)
        {
            if(! rec::sameSizeGrow(gocpp::recv(h)))
            {
                m >>= 1;
            }
            auto oldb = (bmap*)(add(c, (hash & m) * uintptr_t(t->BucketSize)));
            if(! evacuated(oldb))
            {
                b = oldb;
            }
        }
        auto top = tophash(hash);
        bucketloop:
        for(; b != nullptr; b = rec::overflow(gocpp::recv(b), t))
        {
            for(auto i = uintptr_t(0); i < bucketCnt; i++)
            {
                if(b->tophash[i] != top)
                {
                    if(b->tophash[i] == emptyRest)
                    {
                        goto bucketloop_break;
                    }
                    continue;
                }
                auto k = add(unsafe::Pointer(b), dataOffset + i * uintptr_t(t->KeySize));
                if(rec::IndirectKey(gocpp::recv(t)))
                {
                    k = *((unsafe::Pointer*)(k));
                }
                if(rec::Equal(gocpp::recv(t->Key), key, k))
                {
                    auto e = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + i * uintptr_t(t->ValueSize));
                    if(rec::IndirectElem(gocpp::recv(t)))
                    {
                        e = *((unsafe::Pointer*)(e));
                    }
                    return {k, e};
                }
            }
            if(false) {
            bucketloop_continue:
                continue;
            bucketloop_break:
                break;
            }
        }
        return {nullptr, nullptr};
    }

    unsafe::Pointer mapaccess1_fat(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key, unsafe::Pointer zero)
    {
        auto e = mapaccess1(t, h, key);
        if(e == unsafe::Pointer(& zeroVal[0]))
        {
            return zero;
        }
        return e;
    }

    std::tuple<unsafe::Pointer, bool> mapaccess2_fat(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key, unsafe::Pointer zero)
    {
        auto e = mapaccess1(t, h, key);
        if(e == unsafe::Pointer(& zeroVal[0]))
        {
            return {zero, false};
        }
        return {e, true};
    }

    // Like mapaccess, but allocates a slot for the key if it is not present in the map.
    unsafe::Pointer mapassign(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key)
    {
        if(h == nullptr)
        {
            gocpp::panic(plainError("assignment to entry in nil map"s));
        }
        if(raceenabled)
        {
            auto callerpc = getcallerpc();
            auto pc = abi::FuncPCABIInternal(mapassign);
            racewritepc(unsafe::Pointer(h), callerpc, pc);
            raceReadObjectPC(t->Key, key, callerpc, pc);
        }
        if(msanenabled)
        {
            msanread(key, t->Key->Size_);
        }
        if(asanenabled)
        {
            asanread(key, t->Key->Size_);
        }
        if(h->flags & hashWriting != 0)
        {
            fatal("concurrent map writes"s);
        }
        auto hash = rec::Hasher(gocpp::recv(t), key, uintptr_t(h->hash0));
        h->flags ^= hashWriting;
        if(h->buckets == nullptr)
        {
            h->buckets = newobject(t->Bucket);
        }
        again:
        auto bucket = hash & bucketMask(h->B);
        if(rec::growing(gocpp::recv(h)))
        {
            growWork(t, h, bucket);
        }
        auto b = (bmap*)(add(h->buckets, bucket * uintptr_t(t->BucketSize)));
        auto top = tophash(hash);
        uint8_t* inserti = {};
        unsafe::Pointer insertk = {};
        unsafe::Pointer elem = {};
        bucketloop:
        for(; ; )
        {
            for(auto i = uintptr_t(0); i < bucketCnt; i++)
            {
                if(b->tophash[i] != top)
                {
                    if(isEmpty(b->tophash[i]) && inserti == nullptr)
                    {
                        inserti = & b->tophash[i];
                        insertk = add(unsafe::Pointer(b), dataOffset + i * uintptr_t(t->KeySize));
                        elem = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + i * uintptr_t(t->ValueSize));
                    }
                    if(b->tophash[i] == emptyRest)
                    {
                        goto bucketloop_break;
                    }
                    continue;
                }
                auto k = add(unsafe::Pointer(b), dataOffset + i * uintptr_t(t->KeySize));
                if(rec::IndirectKey(gocpp::recv(t)))
                {
                    k = *((unsafe::Pointer*)(k));
                }
                if(! rec::Equal(gocpp::recv(t->Key), key, k))
                {
                    continue;
                }
                if(rec::NeedKeyUpdate(gocpp::recv(t)))
                {
                    typedmemmove(t->Key, k, key);
                }
                elem = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + i * uintptr_t(t->ValueSize));
                goto done;
            }
            auto ovf = rec::overflow(gocpp::recv(b), t);
            if(ovf == nullptr)
            {
                break;
            }
            b = ovf;
            if(false) {
            bucketloop_continue:
                continue;
            bucketloop_break:
                break;
            }
        }
        if(! rec::growing(gocpp::recv(h)) && (overLoadFactor(h->count + 1, h->B) || tooManyOverflowBuckets(h->noverflow, h->B)))
        {
            hashGrow(t, h);
            goto again;
        }
        if(inserti == nullptr)
        {
            auto newb = rec::newoverflow(gocpp::recv(h), t, b);
            inserti = & newb->tophash[0];
            insertk = add(unsafe::Pointer(newb), dataOffset);
            elem = add(insertk, bucketCnt * uintptr_t(t->KeySize));
        }
        if(rec::IndirectKey(gocpp::recv(t)))
        {
            auto kmem = newobject(t->Key);
            *(unsafe::Pointer*)(insertk) = kmem;
            insertk = kmem;
        }
        if(rec::IndirectElem(gocpp::recv(t)))
        {
            auto vmem = newobject(t->Elem);
            *(unsafe::Pointer*)(elem) = vmem;
        }
        typedmemmove(t->Key, insertk, key);
        *inserti = top;
        h->count++;
        done:
        if(h->flags & hashWriting == 0)
        {
            fatal("concurrent map writes"s);
        }
        h->flags &^= hashWriting;
        if(rec::IndirectElem(gocpp::recv(t)))
        {
            elem = *((unsafe::Pointer*)(elem));
        }
        return elem;
    }

    void mapdelete(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key)
    {
        if(raceenabled && h != nullptr)
        {
            auto callerpc = getcallerpc();
            auto pc = abi::FuncPCABIInternal(mapdelete);
            racewritepc(unsafe::Pointer(h), callerpc, pc);
            raceReadObjectPC(t->Key, key, callerpc, pc);
        }
        if(msanenabled && h != nullptr)
        {
            msanread(key, t->Key->Size_);
        }
        if(asanenabled && h != nullptr)
        {
            asanread(key, t->Key->Size_);
        }
        if(h == nullptr || h->count == 0)
        {
            if(auto err = mapKeyError(t, key); err != nullptr)
            {
                gocpp::panic(err);
            }
            return;
        }
        if(h->flags & hashWriting != 0)
        {
            fatal("concurrent map writes"s);
        }
        auto hash = rec::Hasher(gocpp::recv(t), key, uintptr_t(h->hash0));
        h->flags ^= hashWriting;
        auto bucket = hash & bucketMask(h->B);
        if(rec::growing(gocpp::recv(h)))
        {
            growWork(t, h, bucket);
        }
        auto b = (bmap*)(add(h->buckets, bucket * uintptr_t(t->BucketSize)));
        auto bOrig = b;
        auto top = tophash(hash);
        search:
        for(; b != nullptr; b = rec::overflow(gocpp::recv(b), t))
        {
            for(auto i = uintptr_t(0); i < bucketCnt; i++)
            {
                if(b->tophash[i] != top)
                {
                    if(b->tophash[i] == emptyRest)
                    {
                        goto search_break;
                    }
                    continue;
                }
                auto k = add(unsafe::Pointer(b), dataOffset + i * uintptr_t(t->KeySize));
                auto k2 = k;
                if(rec::IndirectKey(gocpp::recv(t)))
                {
                    k2 = *((unsafe::Pointer*)(k2));
                }
                if(! rec::Equal(gocpp::recv(t->Key), key, k2))
                {
                    continue;
                }
                if(rec::IndirectKey(gocpp::recv(t)))
                {
                    *(unsafe::Pointer*)(k) = nullptr;
                }
                else
                if(t->Key->PtrBytes != 0)
                {
                    memclrHasPointers(k, t->Key->Size_);
                }
                auto e = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + i * uintptr_t(t->ValueSize));
                if(rec::IndirectElem(gocpp::recv(t)))
                {
                    *(unsafe::Pointer*)(e) = nullptr;
                }
                else
                if(t->Elem->PtrBytes != 0)
                {
                    memclrHasPointers(e, t->Elem->Size_);
                }
                else
                {
                    memclrNoHeapPointers(e, t->Elem->Size_);
                }
                b->tophash[i] = emptyOne;
                if(i == bucketCnt - 1)
                {
                    if(rec::overflow(gocpp::recv(b), t) != nullptr && rec::overflow(gocpp::recv(b), t)->tophash[0] != emptyRest)
                    {
                        goto notLast;
                    }
                }
                else
                {
                    if(b->tophash[i + 1] != emptyRest)
                    {
                        goto notLast;
                    }
                }
                for(; ; )
                {
                    b->tophash[i] = emptyRest;
                    if(i == 0)
                    {
                        if(b == bOrig)
                        {
                            break;
                        }
                        auto c = b;
                        for(b = bOrig; rec::overflow(gocpp::recv(b), t) != c; b = rec::overflow(gocpp::recv(b), t))
                        {
                        }
                        i = bucketCnt - 1;
                    }
                    else
                    {
                        i--;
                    }
                    if(b->tophash[i] != emptyOne)
                    {
                        break;
                    }
                }
                notLast:
                h->count--;
                if(h->count == 0)
                {
                    h->hash0 = uint32_t(rand());
                }
                goto search_break;
            }
            if(false) {
            search_continue:
                continue;
            search_break:
                break;
            }
        }
        if(h->flags & hashWriting == 0)
        {
            fatal("concurrent map writes"s);
        }
        h->flags &^= hashWriting;
    }

    // mapiterinit initializes the hiter struct used for ranging over maps.
    // The hiter struct pointed to by 'it' is allocated on the stack
    // by the compilers order pass or on the heap by reflect_mapiterinit.
    // Both need to have zeroed hiter since the struct contains pointers.
    void mapiterinit(golang::runtime::maptype* t, struct hmap* h, struct hiter* it)
    {
        if(raceenabled && h != nullptr)
        {
            auto callerpc = getcallerpc();
            racereadpc(unsafe::Pointer(h), callerpc, abi::FuncPCABIInternal(mapiterinit));
        }
        it->t = t;
        if(h == nullptr || h->count == 0)
        {
            return;
        }
        if(gocpp::Sizeof<hiter>() / goarch::PtrSize != 12)
        {
            go_throw("hash_iter size incorrect"s);
        }
        it->h = h;
        it->B = h->B;
        it->buckets = h->buckets;
        if(t->Bucket->PtrBytes == 0)
        {
            rec::createOverflow(gocpp::recv(h));
            it->overflow = h->extra->overflow;
            it->oldoverflow = h->extra->oldoverflow;
        }
        auto r = uintptr_t(rand());
        it->startBucket = r & bucketMask(h->B);
        it->offset = uint8_t((r >> h->B) & (bucketCnt - 1));
        it->bucket = it->startBucket;
        if(auto old = h->flags; old & (iterator | oldIterator) != iterator | oldIterator)
        {
            atomic::Or8(& h->flags, iterator | oldIterator);
        }
        mapiternext(it);
    }

    void mapiternext(struct hiter* it)
    {
        auto h = it->h;
        if(raceenabled)
        {
            auto callerpc = getcallerpc();
            racereadpc(unsafe::Pointer(h), callerpc, abi::FuncPCABIInternal(mapiternext));
        }
        if(h->flags & hashWriting != 0)
        {
            fatal("concurrent map iteration and map write"s);
        }
        auto t = it->t;
        auto bucket = it->bucket;
        auto b = it->bptr;
        auto i = it->i;
        auto checkBucket = it->checkBucket;
        next:
        if(b == nullptr)
        {
            if(bucket == it->startBucket && it->wrapped)
            {
                it->key = nullptr;
                it->elem = nullptr;
                return;
            }
            if(rec::growing(gocpp::recv(h)) && it->B == h->B)
            {
                auto oldbucket = bucket & rec::oldbucketmask(gocpp::recv(it->h));
                b = (bmap*)(add(h->oldbuckets, oldbucket * uintptr_t(t->BucketSize)));
                if(! evacuated(b))
                {
                    checkBucket = bucket;
                }
                else
                {
                    b = (bmap*)(add(it->buckets, bucket * uintptr_t(t->BucketSize)));
                    checkBucket = noCheck;
                }
            }
            else
            {
                b = (bmap*)(add(it->buckets, bucket * uintptr_t(t->BucketSize)));
                checkBucket = noCheck;
            }
            bucket++;
            if(bucket == bucketShift(it->B))
            {
                bucket = 0;
                it->wrapped = true;
            }
            i = 0;
        }
        for(; i < bucketCnt; i++)
        {
            auto offi = (i + it->offset) & (bucketCnt - 1);
            if(isEmpty(b->tophash[offi]) || b->tophash[offi] == evacuatedEmpty)
            {
                continue;
            }
            auto k = add(unsafe::Pointer(b), dataOffset + uintptr_t(offi) * uintptr_t(t->KeySize));
            if(rec::IndirectKey(gocpp::recv(t)))
            {
                k = *((unsafe::Pointer*)(k));
            }
            auto e = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + uintptr_t(offi) * uintptr_t(t->ValueSize));
            if(checkBucket != noCheck && ! rec::sameSizeGrow(gocpp::recv(h)))
            {
                if(rec::ReflexiveKey(gocpp::recv(t)) || rec::Equal(gocpp::recv(t->Key), k, k))
                {
                    auto hash = rec::Hasher(gocpp::recv(t), k, uintptr_t(h->hash0));
                    if(hash & bucketMask(it->B) != checkBucket)
                    {
                        continue;
                    }
                }
                else
                {
                    if((checkBucket >> (it->B - 1)) != uintptr_t(b->tophash[offi] & 1))
                    {
                        continue;
                    }
                }
            }
            if((b->tophash[offi] != evacuatedX && b->tophash[offi] != evacuatedY) || ! (rec::ReflexiveKey(gocpp::recv(t)) || rec::Equal(gocpp::recv(t->Key), k, k)))
            {
                it->key = k;
                if(rec::IndirectElem(gocpp::recv(t)))
                {
                    e = *((unsafe::Pointer*)(e));
                }
                it->elem = e;
            }
            else
            {
                auto [rk, re] = mapaccessK(t, h, k);
                if(rk == nullptr)
                {
                    continue;
                }
                it->key = rk;
                it->elem = re;
            }
            it->bucket = bucket;
            if(it->bptr != b)
            {
                it->bptr = b;
            }
            it->i = i + 1;
            it->checkBucket = checkBucket;
            return;
        }
        b = rec::overflow(gocpp::recv(b), t);
        i = 0;
        goto next;
    }

    // mapclear deletes all keys from a map.
    void mapclear(golang::runtime::maptype* t, struct hmap* h)
    {
        if(raceenabled && h != nullptr)
        {
            auto callerpc = getcallerpc();
            auto pc = abi::FuncPCABIInternal(mapclear);
            racewritepc(unsafe::Pointer(h), callerpc, pc);
        }
        if(h == nullptr || h->count == 0)
        {
            return;
        }
        if(h->flags & hashWriting != 0)
        {
            fatal("concurrent map writes"s);
        }
        h->flags ^= hashWriting;
        auto markBucketsEmpty = [=](unsafe::Pointer bucket, uintptr_t mask) mutable -> void
        {
            for(auto i = uintptr_t(0); i <= mask; i++)
            {
                auto b = (bmap*)(add(bucket, i * uintptr_t(t->BucketSize)));
                for(; b != nullptr; b = rec::overflow(gocpp::recv(b), t))
                {
                    for(auto i = uintptr_t(0); i < bucketCnt; i++)
                    {
                        b->tophash[i] = emptyRest;
                    }
                }
            }
        };
        markBucketsEmpty(h->buckets, bucketMask(h->B));
        if(auto oldBuckets = h->oldbuckets; oldBuckets != nullptr)
        {
            markBucketsEmpty(oldBuckets, rec::oldbucketmask(gocpp::recv(h)));
        }
        h->flags &^= sameSizeGrow;
        h->oldbuckets = nullptr;
        h->nevacuate = 0;
        h->noverflow = 0;
        h->count = 0;
        h->hash0 = uint32_t(rand());
        if(h->extra != nullptr)
        {
            *h->extra = mapextra {};
        }
        auto [gocpp_id_1, nextOverflow] = makeBucketArray(t, h->B, h->buckets);
        if(nextOverflow != nullptr)
        {
            h->extra->nextOverflow = nextOverflow;
        }
        if(h->flags & hashWriting == 0)
        {
            fatal("concurrent map writes"s);
        }
        h->flags &^= hashWriting;
    }

    void hashGrow(golang::runtime::maptype* t, struct hmap* h)
    {
        auto bigger = uint8_t(1);
        if(! overLoadFactor(h->count + 1, h->B))
        {
            bigger = 0;
            h->flags |= sameSizeGrow;
        }
        auto oldbuckets = h->buckets;
        auto [newbuckets, nextOverflow] = makeBucketArray(t, h->B + bigger, nullptr);
        auto flags = h->flags &^ (iterator | oldIterator);
        if(h->flags & iterator != 0)
        {
            flags |= oldIterator;
        }
        h->B += bigger;
        h->flags = flags;
        h->oldbuckets = oldbuckets;
        h->buckets = newbuckets;
        h->nevacuate = 0;
        h->noverflow = 0;
        if(h->extra != nullptr && h->extra->overflow != nullptr)
        {
            if(h->extra->oldoverflow != nullptr)
            {
                go_throw("oldoverflow is not nil"s);
            }
            h->extra->oldoverflow = h->extra->overflow;
            h->extra->overflow = nullptr;
        }
        if(nextOverflow != nullptr)
        {
            if(h->extra == nullptr)
            {
                h->extra = new(mapextra);
            }
            h->extra->nextOverflow = nextOverflow;
        }
    }

    // overLoadFactor reports whether count items placed in 1<<B buckets is over loadFactor.
    bool overLoadFactor(int count, uint8_t B)
    {
        return count > bucketCnt && uintptr_t(count) > loadFactorNum * (bucketShift(B) / loadFactorDen);
    }

    // tooManyOverflowBuckets reports whether noverflow buckets is too many for a map with 1<<B buckets.
    // Note that most of these overflow buckets must be in sparse use;
    // if use was dense, then we'd have already triggered regular map growth.
    bool tooManyOverflowBuckets(uint16_t noverflow, uint8_t B)
    {
        if(B > 15)
        {
            B = 15;
        }
        return noverflow >= (uint16_t(1) << (B & 15));
    }

    // growing reports whether h is growing. The growth may be to the same size or bigger.
    bool rec::growing(struct hmap* h)
    {
        return h->oldbuckets != nullptr;
    }

    // sameSizeGrow reports whether the current growth is to a map of the same size.
    bool rec::sameSizeGrow(struct hmap* h)
    {
        return h->flags & sameSizeGrow != 0;
    }

    // noldbuckets calculates the number of buckets prior to the current map growth.
    uintptr_t rec::noldbuckets(struct hmap* h)
    {
        auto oldB = h->B;
        if(! rec::sameSizeGrow(gocpp::recv(h)))
        {
            oldB--;
        }
        return bucketShift(oldB);
    }

    // oldbucketmask provides a mask that can be applied to calculate n % noldbuckets().
    uintptr_t rec::oldbucketmask(struct hmap* h)
    {
        return rec::noldbuckets(gocpp::recv(h)) - 1;
    }

    void growWork(golang::runtime::maptype* t, struct hmap* h, uintptr_t bucket)
    {
        evacuate(t, h, bucket & rec::oldbucketmask(gocpp::recv(h)));
        if(rec::growing(gocpp::recv(h)))
        {
            evacuate(t, h, h->nevacuate);
        }
    }

    bool bucketEvacuated(golang::runtime::maptype* t, struct hmap* h, uintptr_t bucket)
    {
        auto b = (bmap*)(add(h->oldbuckets, bucket * uintptr_t(t->BucketSize)));
        return evacuated(b);
    }

    // evacDst is an evacuation destination.
    
    template<typename T> requires gocpp::GoStruct<T>
    evacDst::operator T()
    {
        T result;
        result.b = this->b;
        result.i = this->i;
        result.k = this->k;
        result.e = this->e;
        return result;
    }

    template<typename T> requires gocpp::GoStruct<T>
    bool evacDst::operator==(const T& ref) const
    {
        if (b != ref.b) return false;
        if (i != ref.i) return false;
        if (k != ref.k) return false;
        if (e != ref.e) return false;
        return true;
    }

    std::ostream& evacDst::PrintTo(std::ostream& os) const
    {
        os << '{';
        os << "" << b;
        os << " " << i;
        os << " " << k;
        os << " " << e;
        os << '}';
        return os;
    }

    std::ostream& operator<<(std::ostream& os, const struct evacDst& value)
    {
        return value.PrintTo(os);
    }

    void evacuate(golang::runtime::maptype* t, struct hmap* h, uintptr_t oldbucket)
    {
        auto b = (bmap*)(add(h->oldbuckets, oldbucket * uintptr_t(t->BucketSize)));
        auto newbit = rec::noldbuckets(gocpp::recv(h));
        if(! evacuated(b))
        {
            // xy contains the x and y (low and high) evacuation destinations.
            gocpp::array<evacDst, 2> xy = {};
            auto x = & xy[0];
            x->b = (bmap*)(add(h->buckets, oldbucket * uintptr_t(t->BucketSize)));
            x->k = add(unsafe::Pointer(x->b), dataOffset);
            x->e = add(x->k, bucketCnt * uintptr_t(t->KeySize));
            if(! rec::sameSizeGrow(gocpp::recv(h)))
            {
                auto y = & xy[1];
                y->b = (bmap*)(add(h->buckets, (oldbucket + newbit) * uintptr_t(t->BucketSize)));
                y->k = add(unsafe::Pointer(y->b), dataOffset);
                y->e = add(y->k, bucketCnt * uintptr_t(t->KeySize));
            }
            for(; b != nullptr; b = rec::overflow(gocpp::recv(b), t))
            {
                auto k = add(unsafe::Pointer(b), dataOffset);
                auto e = add(k, bucketCnt * uintptr_t(t->KeySize));
                for(auto i = 0; i < bucketCnt; std::tie(i, k, e) = std::tuple{i + 1, add(k, uintptr_t(t->KeySize)), add(e, uintptr_t(t->ValueSize))})
                {
                    auto top = b->tophash[i];
                    if(isEmpty(top))
                    {
                        b->tophash[i] = evacuatedEmpty;
                        continue;
                    }
                    if(top < minTopHash)
                    {
                        go_throw("bad map state"s);
                    }
                    auto k2 = k;
                    if(rec::IndirectKey(gocpp::recv(t)))
                    {
                        k2 = *((unsafe::Pointer*)(k2));
                    }
                    uint8_t useY = {};
                    if(! rec::sameSizeGrow(gocpp::recv(h)))
                    {
                        auto hash = rec::Hasher(gocpp::recv(t), k2, uintptr_t(h->hash0));
                        if(h->flags & iterator != 0 && ! rec::ReflexiveKey(gocpp::recv(t)) && ! rec::Equal(gocpp::recv(t->Key), k2, k2))
                        {
                            useY = top & 1;
                            top = tophash(hash);
                        }
                        else
                        {
                            if(hash & newbit != 0)
                            {
                                useY = 1;
                            }
                        }
                    }
                    if(evacuatedX + 1 != evacuatedY || evacuatedX ^ 1 != evacuatedY)
                    {
                        go_throw("bad evacuatedN"s);
                    }
                    b->tophash[i] = evacuatedX + useY;
                    auto dst = & xy[useY];
                    if(dst->i == bucketCnt)
                    {
                        dst->b = rec::newoverflow(gocpp::recv(h), t, dst->b);
                        dst->i = 0;
                        dst->k = add(unsafe::Pointer(dst->b), dataOffset);
                        dst->e = add(dst->k, bucketCnt * uintptr_t(t->KeySize));
                    }
                    dst->b->tophash[dst->i & (bucketCnt - 1)] = top;
                    if(rec::IndirectKey(gocpp::recv(t)))
                    {
                        *(unsafe::Pointer*)(dst->k) = k2;
                    }
                    else
                    {
                        typedmemmove(t->Key, dst->k, k);
                    }
                    if(rec::IndirectElem(gocpp::recv(t)))
                    {
                        *(unsafe::Pointer*)(dst->e) = *(unsafe::Pointer*)(e);
                    }
                    else
                    {
                        typedmemmove(t->Elem, dst->e, e);
                    }
                    dst->i++;
                    dst->k = add(dst->k, uintptr_t(t->KeySize));
                    dst->e = add(dst->e, uintptr_t(t->ValueSize));
                }
            }
            if(h->flags & oldIterator == 0 && t->Bucket->PtrBytes != 0)
            {
                auto b = add(h->oldbuckets, oldbucket * uintptr_t(t->BucketSize));
                auto ptr = add(b, dataOffset);
                auto n = uintptr_t(t->BucketSize) - dataOffset;
                memclrHasPointers(ptr, n);
            }
        }
        if(oldbucket == h->nevacuate)
        {
            advanceEvacuationMark(h, t, newbit);
        }
    }

    void advanceEvacuationMark(struct hmap* h, golang::runtime::maptype* t, uintptr_t newbit)
    {
        h->nevacuate++;
        auto stop = h->nevacuate + 1024;
        if(stop > newbit)
        {
            stop = newbit;
        }
        for(; h->nevacuate != stop && bucketEvacuated(t, h, h->nevacuate); )
        {
            h->nevacuate++;
        }
        if(h->nevacuate == newbit)
        {
            h->oldbuckets = nullptr;
            if(h->extra != nullptr)
            {
                h->extra->oldoverflow = nullptr;
            }
            h->flags &^= sameSizeGrow;
        }
    }

    //go:linkname reflect_makemap reflect.makemap
    struct hmap* reflect_makemap(golang::runtime::maptype* t, int cap)
    {
        if(t->Key->Equal == nullptr)
        {
            go_throw("runtime.reflect_makemap: unsupported map key type"s);
        }
        if(t->Key->Size_ > maxKeySize && (! rec::IndirectKey(gocpp::recv(t)) || t->KeySize != uint8_t(goarch::PtrSize)) || t->Key->Size_ <= maxKeySize && (rec::IndirectKey(gocpp::recv(t)) || t->KeySize != uint8_t(t->Key->Size_)))
        {
            go_throw("key size wrong"s);
        }
        if(t->Elem->Size_ > maxElemSize && (! rec::IndirectElem(gocpp::recv(t)) || t->ValueSize != uint8_t(goarch::PtrSize)) || t->Elem->Size_ <= maxElemSize && (rec::IndirectElem(gocpp::recv(t)) || t->ValueSize != uint8_t(t->Elem->Size_)))
        {
            go_throw("elem size wrong"s);
        }
        if(t->Key->Align_ > bucketCnt)
        {
            go_throw("key align too big"s);
        }
        if(t->Elem->Align_ > bucketCnt)
        {
            go_throw("elem align too big"s);
        }
        if(t->Key->Size_ % uintptr_t(t->Key->Align_) != 0)
        {
            go_throw("key size not a multiple of key align"s);
        }
        if(t->Elem->Size_ % uintptr_t(t->Elem->Align_) != 0)
        {
            go_throw("elem size not a multiple of elem align"s);
        }
        if(bucketCnt < 8)
        {
            go_throw("bucketsize too small for proper alignment"s);
        }
        if(dataOffset % uintptr_t(t->Key->Align_) != 0)
        {
            go_throw("need padding in bucket (key)"s);
        }
        if(dataOffset % uintptr_t(t->Elem->Align_) != 0)
        {
            go_throw("need padding in bucket (elem)"s);
        }
        return makemap(t, cap, nullptr);
    }

    //go:linkname reflect_mapaccess reflect.mapaccess
    unsafe::Pointer reflect_mapaccess(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key)
    {
        auto [elem, ok] = mapaccess2(t, h, key);
        if(! ok)
        {
            elem = nullptr;
        }
        return elem;
    }

    //go:linkname reflect_mapaccess_faststr reflect.mapaccess_faststr
    unsafe::Pointer reflect_mapaccess_faststr(golang::runtime::maptype* t, struct hmap* h, std::string key)
    {
        auto [elem, ok] = mapaccess2_faststr(t, h, key);
        if(! ok)
        {
            elem = nullptr;
        }
        return elem;
    }

    //go:linkname reflect_mapassign reflect.mapassign0
    void reflect_mapassign(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key, unsafe::Pointer elem)
    {
        auto p = mapassign(t, h, key);
        typedmemmove(t->Elem, p, elem);
    }

    //go:linkname reflect_mapassign_faststr reflect.mapassign_faststr0
    void reflect_mapassign_faststr(golang::runtime::maptype* t, struct hmap* h, std::string key, unsafe::Pointer elem)
    {
        auto p = mapassign_faststr(t, h, key);
        typedmemmove(t->Elem, p, elem);
    }

    //go:linkname reflect_mapdelete reflect.mapdelete
    void reflect_mapdelete(golang::runtime::maptype* t, struct hmap* h, unsafe::Pointer key)
    {
        mapdelete(t, h, key);
    }

    //go:linkname reflect_mapdelete_faststr reflect.mapdelete_faststr
    void reflect_mapdelete_faststr(golang::runtime::maptype* t, struct hmap* h, std::string key)
    {
        mapdelete_faststr(t, h, key);
    }

    //go:linkname reflect_mapiterinit reflect.mapiterinit
    void reflect_mapiterinit(golang::runtime::maptype* t, struct hmap* h, struct hiter* it)
    {
        mapiterinit(t, h, it);
    }

    //go:linkname reflect_mapiternext reflect.mapiternext
    void reflect_mapiternext(struct hiter* it)
    {
        mapiternext(it);
    }

    //go:linkname reflect_mapiterkey reflect.mapiterkey
    unsafe::Pointer reflect_mapiterkey(struct hiter* it)
    {
        return it->key;
    }

    //go:linkname reflect_mapiterelem reflect.mapiterelem
    unsafe::Pointer reflect_mapiterelem(struct hiter* it)
    {
        return it->elem;
    }

    //go:linkname reflect_maplen reflect.maplen
    int reflect_maplen(struct hmap* h)
    {
        if(h == nullptr)
        {
            return 0;
        }
        if(raceenabled)
        {
            auto callerpc = getcallerpc();
            racereadpc(unsafe::Pointer(h), callerpc, abi::FuncPCABIInternal(reflect_maplen));
        }
        return h->count;
    }

    //go:linkname reflect_mapclear reflect.mapclear
    void reflect_mapclear(golang::runtime::maptype* t, struct hmap* h)
    {
        mapclear(t, h);
    }

    //go:linkname reflectlite_maplen internal/reflectlite.maplen
    int reflectlite_maplen(struct hmap* h)
    {
        if(h == nullptr)
        {
            return 0;
        }
        if(raceenabled)
        {
            auto callerpc = getcallerpc();
            racereadpc(unsafe::Pointer(h), callerpc, abi::FuncPCABIInternal(reflect_maplen));
        }
        return h->count;
    }

    gocpp::array<unsigned char, abi::ZeroValSize> zeroVal;
    // mapinitnoop is a no-op function known the Go linker; if a given global
    // map (of the right size) is determined to be dead, the linker will
    // rewrite the relocation (from the package init func) from the outlined
    // map init function to this symbol. Defined in assembly so as to avoid
    // complications with instrumentation (coverage, etc).
    void mapinitnoop()
    /* convertBlockStmt, nil block */;

    // mapclone for implementing maps.Clone
    //
    //go:linkname mapclone maps.clone
    go_any mapclone(go_any m)
    {
        auto e = efaceOf(& m);
        e->data = unsafe::Pointer(mapclone2((runtime::maptype*)(unsafe::Pointer(e->_type)), (hmap*)(e->data)));
        return m;
    }

    // moveToBmap moves a bucket from src to dst. It returns the destination bucket or new destination bucket if it overflows
    // and the pos that the next key/value will be written, if pos == bucketCnt means needs to written in overflow bucket.
    std::tuple<struct bmap*, int> moveToBmap(golang::runtime::maptype* t, struct hmap* h, struct bmap* dst, int pos, struct bmap* src)
    {
        for(auto i = 0; i < bucketCnt; i++)
        {
            if(isEmpty(src->tophash[i]))
            {
                continue;
            }
            for(; pos < bucketCnt; pos++)
            {
                if(isEmpty(dst->tophash[pos]))
                {
                    break;
                }
            }
            if(pos == bucketCnt)
            {
                dst = rec::newoverflow(gocpp::recv(h), t, dst);
                pos = 0;
            }
            auto srcK = add(unsafe::Pointer(src), dataOffset + uintptr_t(i) * uintptr_t(t->KeySize));
            auto srcEle = add(unsafe::Pointer(src), dataOffset + bucketCnt * uintptr_t(t->KeySize) + uintptr_t(i) * uintptr_t(t->ValueSize));
            auto dstK = add(unsafe::Pointer(dst), dataOffset + uintptr_t(pos) * uintptr_t(t->KeySize));
            auto dstEle = add(unsafe::Pointer(dst), dataOffset + bucketCnt * uintptr_t(t->KeySize) + uintptr_t(pos) * uintptr_t(t->ValueSize));
            dst->tophash[pos] = src->tophash[i];
            if(rec::IndirectKey(gocpp::recv(t)))
            {
                srcK = *(unsafe::Pointer*)(srcK);
                if(rec::NeedKeyUpdate(gocpp::recv(t)))
                {
                    auto kStore = newobject(t->Key);
                    typedmemmove(t->Key, kStore, srcK);
                    srcK = kStore;
                }
                *(unsafe::Pointer*)(dstK) = srcK;
            }
            else
            {
                typedmemmove(t->Key, dstK, srcK);
            }
            if(rec::IndirectElem(gocpp::recv(t)))
            {
                srcEle = *(unsafe::Pointer*)(srcEle);
                auto eStore = newobject(t->Elem);
                typedmemmove(t->Elem, eStore, srcEle);
                *(unsafe::Pointer*)(dstEle) = eStore;
            }
            else
            {
                typedmemmove(t->Elem, dstEle, srcEle);
            }
            pos++;
            h->count++;
        }
        return {dst, pos};
    }

    struct hmap* mapclone2(golang::runtime::maptype* t, struct hmap* src)
    {
        auto dst = makemap(t, src->count, nullptr);
        dst->hash0 = src->hash0;
        dst->nevacuate = 0;
        if(src->count == 0)
        {
            return dst;
        }
        if(src->flags & hashWriting != 0)
        {
            fatal("concurrent map clone and map write"s);
        }
        if(src->B == 0 && ! (rec::IndirectKey(gocpp::recv(t)) && rec::NeedKeyUpdate(gocpp::recv(t))) && ! rec::IndirectElem(gocpp::recv(t)))
        {
            dst->buckets = newobject(t->Bucket);
            dst->count = src->count;
            typedmemmove(t->Bucket, dst->buckets, src->buckets);
            return dst;
        }
        if(dst->B == 0)
        {
            dst->buckets = newobject(t->Bucket);
        }
        auto dstArraySize = int(bucketShift(dst->B));
        auto srcArraySize = int(bucketShift(src->B));
        for(auto i = 0; i < dstArraySize; i++)
        {
            auto dstBmap = (bmap*)(add(dst->buckets, uintptr_t(i * int(t->BucketSize))));
            auto pos = 0;
            for(auto j = 0; j < srcArraySize; j += dstArraySize)
            {
                auto srcBmap = (bmap*)(add(src->buckets, uintptr_t((i + j) * int(t->BucketSize))));
                for(; srcBmap != nullptr; )
                {
                    std::tie(dstBmap, pos) = moveToBmap(t, dst, dstBmap, pos, srcBmap);
                    srcBmap = rec::overflow(gocpp::recv(srcBmap), t);
                }
            }
        }
        if(src->oldbuckets == nullptr)
        {
            return dst;
        }
        auto oldB = src->B;
        auto srcOldbuckets = src->oldbuckets;
        if(! rec::sameSizeGrow(gocpp::recv(src)))
        {
            oldB--;
        }
        auto oldSrcArraySize = int(bucketShift(oldB));
        for(auto i = 0; i < oldSrcArraySize; i++)
        {
            auto srcBmap = (bmap*)(add(srcOldbuckets, uintptr_t(i * int(t->BucketSize))));
            if(evacuated(srcBmap))
            {
                continue;
            }
            if(oldB >= dst->B)
            {
                auto dstBmap = (bmap*)(add(dst->buckets, (uintptr_t(i) & bucketMask(dst->B)) * uintptr_t(t->BucketSize)));
                for(; rec::overflow(gocpp::recv(dstBmap), t) != nullptr; )
                {
                    dstBmap = rec::overflow(gocpp::recv(dstBmap), t);
                }
                auto pos = 0;
                for(; srcBmap != nullptr; )
                {
                    std::tie(dstBmap, pos) = moveToBmap(t, dst, dstBmap, pos, srcBmap);
                    srcBmap = rec::overflow(gocpp::recv(srcBmap), t);
                }
                continue;
            }
            for(; srcBmap != nullptr; )
            {
                for(auto i = uintptr_t(0); i < bucketCnt; i++)
                {
                    if(isEmpty(srcBmap->tophash[i]))
                    {
                        continue;
                    }
                    if(src->flags & hashWriting != 0)
                    {
                        fatal("concurrent map clone and map write"s);
                    }
                    auto srcK = add(unsafe::Pointer(srcBmap), dataOffset + i * uintptr_t(t->KeySize));
                    if(rec::IndirectKey(gocpp::recv(t)))
                    {
                        srcK = *((unsafe::Pointer*)(srcK));
                    }
                    auto srcEle = add(unsafe::Pointer(srcBmap), dataOffset + bucketCnt * uintptr_t(t->KeySize) + i * uintptr_t(t->ValueSize));
                    if(rec::IndirectElem(gocpp::recv(t)))
                    {
                        srcEle = *((unsafe::Pointer*)(srcEle));
                    }
                    auto dstEle = mapassign(t, dst, srcK);
                    typedmemmove(t->Elem, dstEle, srcEle);
                }
                srcBmap = rec::overflow(gocpp::recv(srcBmap), t);
            }
        }
        return dst;
    }

    // keys for implementing maps.keys
    //
    //go:linkname keys maps.keys
    void keys(go_any m, unsafe::Pointer p)
    {
        auto e = efaceOf(& m);
        auto t = (runtime::maptype*)(unsafe::Pointer(e->_type));
        auto h = (hmap*)(e->data);
        if(h == nullptr || h->count == 0)
        {
            return;
        }
        auto s = (slice*)(p);
        auto r = int(rand());
        auto offset = uint8_t((r >> h->B) & (bucketCnt - 1));
        if(h->B == 0)
        {
            copyKeys(t, h, (bmap*)(h->buckets), s, offset);
            return;
        }
        auto arraySize = int(bucketShift(h->B));
        auto buckets = h->buckets;
        for(auto i = 0; i < arraySize; i++)
        {
            auto bucket = (i + r) & (arraySize - 1);
            auto b = (bmap*)(add(buckets, uintptr_t(bucket) * uintptr_t(t->BucketSize)));
            copyKeys(t, h, b, s, offset);
        }
        if(rec::growing(gocpp::recv(h)))
        {
            auto oldArraySize = int(rec::noldbuckets(gocpp::recv(h)));
            for(auto i = 0; i < oldArraySize; i++)
            {
                auto bucket = (i + r) & (oldArraySize - 1);
                auto b = (bmap*)(add(h->oldbuckets, uintptr_t(bucket) * uintptr_t(t->BucketSize)));
                if(evacuated(b))
                {
                    continue;
                }
                copyKeys(t, h, b, s, offset);
            }
        }
        return;
    }

    void copyKeys(golang::runtime::maptype* t, struct hmap* h, struct bmap* b, struct slice* s, uint8_t offset)
    {
        for(; b != nullptr; )
        {
            for(auto i = uintptr_t(0); i < bucketCnt; i++)
            {
                auto offi = (i + uintptr_t(offset)) & (bucketCnt - 1);
                if(isEmpty(b->tophash[offi]))
                {
                    continue;
                }
                if(h->flags & hashWriting != 0)
                {
                    fatal("concurrent map read and map write"s);
                }
                auto k = add(unsafe::Pointer(b), dataOffset + offi * uintptr_t(t->KeySize));
                if(rec::IndirectKey(gocpp::recv(t)))
                {
                    k = *((unsafe::Pointer*)(k));
                }
                if(s->len >= s->cap)
                {
                    fatal("concurrent map read and map write"s);
                }
                typedmemmove(t->Key, add(s->array, uintptr_t(s->len) * uintptr_t(rec::Size(gocpp::recv(t->Key)))), k);
                s->len++;
            }
            b = rec::overflow(gocpp::recv(b), t);
        }
    }

    // values for implementing maps.values
    //
    //go:linkname values maps.values
    void values(go_any m, unsafe::Pointer p)
    {
        auto e = efaceOf(& m);
        auto t = (runtime::maptype*)(unsafe::Pointer(e->_type));
        auto h = (hmap*)(e->data);
        if(h == nullptr || h->count == 0)
        {
            return;
        }
        auto s = (slice*)(p);
        auto r = int(rand());
        auto offset = uint8_t((r >> h->B) & (bucketCnt - 1));
        if(h->B == 0)
        {
            copyValues(t, h, (bmap*)(h->buckets), s, offset);
            return;
        }
        auto arraySize = int(bucketShift(h->B));
        auto buckets = h->buckets;
        for(auto i = 0; i < arraySize; i++)
        {
            auto bucket = (i + r) & (arraySize - 1);
            auto b = (bmap*)(add(buckets, uintptr_t(bucket) * uintptr_t(t->BucketSize)));
            copyValues(t, h, b, s, offset);
        }
        if(rec::growing(gocpp::recv(h)))
        {
            auto oldArraySize = int(rec::noldbuckets(gocpp::recv(h)));
            for(auto i = 0; i < oldArraySize; i++)
            {
                auto bucket = (i + r) & (oldArraySize - 1);
                auto b = (bmap*)(add(h->oldbuckets, uintptr_t(bucket) * uintptr_t(t->BucketSize)));
                if(evacuated(b))
                {
                    continue;
                }
                copyValues(t, h, b, s, offset);
            }
        }
        return;
    }

    void copyValues(golang::runtime::maptype* t, struct hmap* h, struct bmap* b, struct slice* s, uint8_t offset)
    {
        for(; b != nullptr; )
        {
            for(auto i = uintptr_t(0); i < bucketCnt; i++)
            {
                auto offi = (i + uintptr_t(offset)) & (bucketCnt - 1);
                if(isEmpty(b->tophash[offi]))
                {
                    continue;
                }
                if(h->flags & hashWriting != 0)
                {
                    fatal("concurrent map read and map write"s);
                }
                auto ele = add(unsafe::Pointer(b), dataOffset + bucketCnt * uintptr_t(t->KeySize) + offi * uintptr_t(t->ValueSize));
                if(rec::IndirectElem(gocpp::recv(t)))
                {
                    ele = *((unsafe::Pointer*)(ele));
                }
                if(s->len >= s->cap)
                {
                    fatal("concurrent map read and map write"s);
                }
                typedmemmove(t->Elem, add(s->array, uintptr_t(s->len) * uintptr_t(rec::Size(gocpp::recv(t->Elem)))), ele);
                s->len++;
            }
            b = rec::overflow(gocpp::recv(b), t);
        }
    }

}

